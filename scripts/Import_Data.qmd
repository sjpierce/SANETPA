---
title: Import and Manage SANE Training Program Data
subtitle: | 
          | CSTAT Case: C1788
          | Clients: Rebecca Campbell, Autumn Ashley, & Katherine Dontje
author: 
  - name: Steven J. Pierce
    orcid: 0000-0002-0679-3019
    email: pierces1@msu.edu
    affil-id: 1 
affiliations: 
  - id: 1 
    name: Michigan State University
    department: Center for Statistical Training and Consulting
    url: "[https://cstat.msu.edu](https://cstat.msu.edu)"
bibliography: references.bib          # File holds BibTeX data for references
csl: apa.csl                          # File controls citation & reference list format
params:                               # Default values for parameters
  SourceDir: "scripts/"               # Relative path to folder holding this file
  SourceFile: "Import_Data.qmd"       # Name of this script file
  LogFile: "Import_Data_Draft.pdf"   # Default name of rendered output file
format: 
  pdf:                                # Settings for PDF output
    output-file: "Import_Data_Draft.pdf" # Default output file name 
    output-ext: "pdf"                 # Default file name extension
    documentclass: scrartcl           # LaTeX document type
    papersize: letter
    geometry:                         # Control page margins
      - top=1in
      - bottom=1in
      - left=1in
      - right=1in
    number-sections: true           # Auto-number each section
    toc: true                       # Include table of contents (TOC)
    toc-depth: 3                    # Number of layers in TOC
    colorlinks: true
    template-partials: 
      - title.tex   # Controls author affiliation formatting
    include-in-header:
      - file: compact-title.tex    # Controls spacing around title. 
      - text: |
          \usepackage{fancyhdr}
          \usepackage[noblocks]{authblk}
          \renewcommand*{\Authsep}{, }
          \renewcommand*{\Authand}{, }
          \renewcommand*{\Authands}{, }
          \renewcommand\Affilfont{\small}
          \usepackage[yyyymmdd,hhmmss]{datetime}    %% for currenttime command
          \usepackage{lastpage}                     %% For pageref command
          \usepackage{fontspec}
          \defaultfontfeatures{Ligatures=TeX}
          \usepackage[font={small}, margin=1cm, skip=2pt]{caption}
          \usepackage{url}
          \usepackage{floatrow}                     %% For controlling float placement
          \floatsetup[table]{capposition=top}       %% Puts table caption at top.
          \floatsetup[longtable]{margins=centering} %% Centers longtable tables
          \floatplacement{figure}{!ht}              %% Control placement of figures
          \floatplacement{table}{!ht}               %% Control placement of tables
          \usepackage[labelfont=bf, textfont=bf]{caption}  %% For bolded table/figure captions
          \usepackage{placeins}                     %% For FloatBarrier command
          \usepackage{booktabs}                     %% Used by kableExtra
          \usepackage{longtable}                    %% Used by kableExtra
          \usepackage{array}                        %% Used by kableExtra
          \usepackage{multirow}                     %% Used by kableExtra
          \usepackage{wrapfig}                      %% Used by kableExtra
          \usepackage{colortbl}                     %% Used by kableExtra
          \usepackage{pdflscape}                    %% Used by kableExtra
          \usepackage{tabu}                         %% Used by kableExtra
          \usepackage[normalem]{ulem}               %% Used by kableExtra
          \usepackage{makecell}                     %% Used by kableExtra
          \usepackage{xcolor}                       %% Used by kableExtra
          \usepackage{dcolumn}                      %% Used by kableExtra
          \usepackage{threeparttable}               %% Used by kableExtra
          \usepackage{threeparttablex}              %% Used by kableExtra
          \usepackage{amsmath}                      %% for equation support. 
          \usepackage{titling}      
          \usepackage{verbatim}                     %% For comment command
          \pretitle{\begin{center}\LARGE\bfseries\sffamily}
          \posttitle{\end{center}}
          \pagestyle{fancy}
          \lhead{SANETPA Import Data}
          \chead{\includegraphics[height=0.85cm]{../graphics/Combomark-Horiz_Pantone-567.eps}}
          \rhead{\today\ \currenttime}
          \cfoot{ }
          \fancyfoot[R]{\thepage\ of \pageref*{LastPage}}
          \renewcommand{\headrulewidth}{0.4pt}
          \renewcommand{\footrulewidth}{0.4pt}
          \fancypagestyle{plain}{\pagestyle{fancy}}
          \newcommand*\tocentryformat[1]{{\sffamily#1}}  %% Fix TOC font style
          \RedeclareSectionCommands                      %% Fix TOC font style
            [
              tocentryformat=\tocentryformat,
              tocpagenumberformat=\tocentryformat
            ]
            {section,subsection,subsubsection,paragraph,subparagraph}
execute:                              # Default Quarto chunk execution options
  eval: true
  echo: fenced                        # Show the code in the output file
  output: true
  warning: true
  error: true
  include: true
knitr:                                # Default R knitr package chunk options
  opts_chunk: 
    message: true
    cfsize: "footnotesize"  
---

\lfoot{\texttt{\small \detokenize{`r params$LogFile`}}}

\FloatBarrier

# Purpose
This file is part of a research compendium [@Pierce-RN8756] associated with a 
study about a sexual assault nurse examiner training program [@Dontje-RN8757]. 
It imports data from from an SPSS data file provided by the investigators, does
some data cleaning and management, then saves out an R data file that will be 
used by other scripts in this compendium. 

\FloatBarrier

# Setup
This section documents some setup tasks that are useful to the statistician on 
the team. Most readers of this document will probably want skip directly to 
@sec-Data-Mgt.

\FloatBarrier

## Define Global Options
Global R chunk options are defined in the YAML header but local chunk options
will over-ride global options. We can temporarily disable an individual chunk by
inserting `#| eval: false` on a line at the top of the chunk. The method for
creating a `cfsize` option that controls font size in code chunks and their text
output is based on an answer to a question posted on
[stackoverflow.com](https://stackoverflow.com/a/46526740).

``` {r}
#| label: global-options

# Create a custom chunk hook/option for controlling font size in chunk & output.
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$cfsize != "normalsize", 
         paste0("\n \\", options$cfsize,"\n\n", x, "\n\n \\normalsize"), 
         x)
  })
```

\FloatBarrier

## Load Packages
R packages usually add new functions to the base R software, allowing you to do 
more things. Here, we load the specific R packages required for this script to 
work.

```{r}
#| label: load-packages
library(devtools)       # for session_info()
library(here)           # for here(), i_am(), makes code more portable.
library(rmarkdown)      # for pandoc_version()
library(knitr)          # for kable()
library(dplyr)          # for %>%, filter(), group_by(), mutate(), rename(), etc.
library(tidyverse)      # for map_dfr(), map_chr(), rowid_to_column()
library(haven)          # for read_SPSS()
library(labelled)       # for var_label()
options(kableExtra.latex.load_packages = FALSE)
library(kableExtra)     # for kable_styling(), add_header_above(), 
                        # column_spec(), row_spec() etc. 
library(kableExtra)     # for kable_styling 
library(piercer)        # for git_report(), which_latex()
library(quarto)         # for quarto_version()
library(SANETPA)        # for version info 
```

\FloatBarrier

## Declare Path
This next chunk declares the path to this script relative to the project-level 
root directory. If the file is not in the right location under the project root
you'll get a warning message. This helps ensure relative paths are all working 
as expected. The chunk below uses the `SourceDir` and `SourceFile` parameters 
set in the YAML header. 

``` {r}
#| label: declare-path

# Declare path to this script relative to the project root directory.
here::i_am(path = paste0(params$SourceDir, params$SourceFile))
```

\FloatBarrier

# Data Management {#sec-Data-Mgt}

\FloatBarrier

## Read SPSS Data into `Applicants_Raw` Dataset {#sec-Read-Data}
The raw data provided by the investigators is in an SPSS data file. This section 
imports it into an R data frame/tibble. The raw data is de-identified to 
preserve participant privacy and protect confidentiality. 

The `ID` variable in the data has no intrinsic meaning and could only be linked
to actual participant names via the key retained by the principal investigators.
Per email communication that accompanied delivery of the data, it has missing 
data because "The ids were not generated until the end of application 1- so they 
would have had to get through all of the questions for part a first" (A. Ashley, 
personal communication, May 18, 2025). 

:::{.callout-note}
I recevied an updated data file called `All_group_1_2025-06-03.sav` that fixed
some inaccurate data values detected by a previous iteration of the descriptive
analyses. It is now in my local repository and replaced the previous data file.
It includes all applicants (even those who were ineligible). The date in the
file name is when I received the file.
:::

@tbl-raw-data-file shows meta-data about the raw data file we will import.

```{r}
#| label: tbl-raw-data-file
#| tbl-cap: "Meta-Data About Raw Data File"

# Store path to raw data file. 
RawFile <- here("scripts/extdata/All_group_1_2025-06-03.sav")

file.info(RawFile, extra_cols = FALSE) %>% 
  rownames_to_column() %>% 
  mutate(rowname = basename(rowname)) %>% 
  select(-isdir, -mode) %>% 
  kable(, format = "latex", booktabs = TRUE, 
        col.names = c("File Name", "Size (Bytes)", "Modified", 
                      "Last Status Change", "Last Accessed")) %>% 
  kable_styling() %>% 
  column_spec(column = 3:5, width = "2cm")
```

Next, we actually read that SPSS file into a data frame called `Applicants_Raw`. 
That will be an intermediate form of the data because we may need to do some 
data management before it is ready for use in descriptive and inferential 
analyses. 

```{r}
#| label: import-data

Applicants_Raw <- read_spss(RawFile) 
```

The imported `Applicants_Raw` data frame has `r nrow(Applicants_Raw)` rows and 
`r ncol(Applicants_Raw)` variables. @tbl-Applicants-Raw shows a list of the 
variable positions, names, classes, and labels prior to any data management.

``` {r}
#| label: tbl-Applicants-Raw
#| tbl-cap: "Applicants_Raw: Variable Names and Classes."

ApplicantsVars <- list(Applicants_Raw) %>% 
  map_dfr(~ tibble(Name = names(.x), 
                   Class = map_chr(.x, all_classes),
                   Label = var_label(.x))) %>% 
  rowid_to_column(., "Position")

kable(ApplicantsVars, format = "latex", booktabs = TRUE, longtable = TRUE) %>%
  kable_styling(font_size = 7, latex_options = c("repeat_header")) %>% 
  column_spec(column = 3, width = "3cm") %>% 
  column_spec(column = 4, width = "6.5cm")
```

:::{.callout-tip}
Both `finisheddidac` and `Didactic_Status` are binary variables coding whether 
a person completed the didactic training. The crosstab outputs below show that  
the difference between them is that `finisheddidac` has no missing data (`NA`), 
but a substantial number of applicants have missing `Didactic_Status` paired
with `finisheddidac = 0`. All applicants with `finisheddidac = 1` had 
`Didactic_Status = 1`. 

```{r}
#| label: xtab-finisheddidac-Didactic-Status

xtabs(~finisheddidac + Didactic_Status, addNA = TRUE, 
      data = Applicants_Raw) %>% 
  addmargins()
```

We can also see that only applicants who were not enrolled have missing values 
(`NA`) on `Didactic_Status`. 

```{r}
#| label: xtab-Enrolled-Didactic-Status

xtabs(~Enrolled + Didactic_Status, addNA = TRUE, 
      data = Applicants_Raw) %>% 
  addmargins()
```

We will retain both `finisheddidac` and `Didactic_Status` because each may be 
useful depending on the summary desired.
:::

\FloatBarrier

## Create `Applicants` Dataset
This section creates the `Applicants` data frame from an updated version of the 
`Applicants_Raw` data frame. These changes prepare the data for the planned 
analyses by applying more consistent and convenient naming conventions, updating 
value labels, converting categorical variables to factors, and so on. 

:::{.callout-tip}
The expected uses for the `Applicants` data are:

* Serve as the source dataset from which other required datasets are derived. 
* Compute eligibility rate and associated confidence interval. 

:::

In the raw data, `stg_reached` was coded into 7 ordered categories to get the 
most granular set of categories we thought we might need. Below we replace the 
imported value labels for those stages with more concise labels. We also rename 
that variable to `Stage_Raw`, then use it to create the `Stage_Reached` variable 
by recoding `Stage_Raw` = 1 to missing values (ineligible applicants will be 
excluded from modeling) and then renumering remaining stages after collapsing 
two stages together because only one participant started the clinical skills 
training without finishing it (`Stage_Raw` = 6). For that stage, the stopping 
rate would be really close to 0 for the transition between starting and
finishing clinical training. That could cause a separation issue (estimation
could break down due to insufficient outcome variability at that threshold).
Treating that case as having stopped at finishing the didactic training 
(`Stage_Raw` = 5; `Stage_Reached` = 4) should avoid that problem.

```{r}
#| label: create-value-labels

# Labels for binary variables
Binary_Labels <- c(No = 0, Yes = 1)

# Create vectors of value labels for reverse-coded NPQ items.
reversed_NPQ_value_labels <- c(`Very Often` = 1, Often = 2, Sometimes = 3, 
                               Rarely = 4, Never = 5)

# More concise labels for the raw stages. 
Stage_Raw_value_labels <- c(`Applied` = 1, `Eligible` = 2, `Enrolled` = 3, 
                            `Started DT` = 4, `Finished DT` = 5, 
                            `Started CSW` = 6, `Finished CSW` = 7)

# Final stages to be modeled. 
Stage_Reached_value_labels <- c(`Eligible` = 1, `Enrolled` = 2, 
                                `Started DT` = 3, `Finished DT` = 4, 
                                `Finished CSW` = 5)
```

```{r}
#| label: create-Applicants

Applicants <- Applicants_Raw %>% 
  rename(Education = educ_dem_num,
         License = license_num,
         Setting = practicset_dem_num,
         Employ_Status = employment_dem_num,
         Employ_Nurse = employednurse_dem_num,
         Nurse_Years = nursexperience_years,
         Recruited_How = recruitment_num,
         Prior_SANE = prevSANEtrain_num,
         Trained1_Year = trained1year_num,
         Trained2_Year = trained2year,
         Disability = Disability_status,
         Sex = sex_dem_num,
         Pronoun = pronoun_dem_num,
         Age = age_num,
         Race_Ethnicity = race_ethnicity_num,
         Income = income_dem_num,
         LGBTQ = LGBTQ_num,
         NPQ_1 = npq1,
         NPQ_2 = npq2,
         NPQ_3 = npq3, 
         NPQ_4 = npq4, 
         NPQ_5 = npq5, 
         NPQ_6 = npq6, 
         NPQ_7 = npq7, 
         NPQ_8 = npq8, 
         NPQ_9 = npq9, 
         NPQ_10 = npq10, 
         NPQ_11 = npq11, 
         NPQ_12 = npq12,
         NPQ_13 = npq13,
         NPQ_14 = npq14, 
         NPQ_15 = npq15, 
         NPQ_16 = npq16, 
         NPQ_17 = npq17, 
         NPQ_18 = npq18, 
         NPQ_19 = npq19, 
         NPQ_20 = npq20, 
         NPQ_21 = npq21,
         NPQ_22 = npq22, 
         NPQ_23 = npq23, 
         NPQ_24 = npq24, 
         NPQ_25 = npq25, 
         NPQ_26 = npq26, 
         NPQ_27 = npq27, 
         NPQ_28 = npq28, 
         NPQ_29 = npq29, 
         NPQ_30 = npq30, 
         NPQ_1_r = npq1r, 
         NPQ_4_r = npq4r, 
         NPQ_15_r = npq15r,
         NPQ_17_r = npq17r,
         NPQ_29_r = npq29r,
         Plan_After_Training = PlansFollowingTraining_Num,
         Train_Goal_Fac_Bar_1 = train_goal_fac_bar_1_numeric,
         Train_Goal_Fac_Bar_2 = train_goal_fac_bar_2_numeric,
         Train_Goal_Fac_Bar_3 = train_goal_fac_bar_3_numeric,
         Train_Goal_Fac_Bar_4 = train_goal_fac_bar_4_numeric,
         Train_Goal_Fac_Bar_5 = train_goal_fac_bar_5_numeric,
         Train_Goal_Fac_Bar_6 = train_goal_fac_bar_6_numeric,
         Train_Goal_Fac_Bar_7 = train_goal_fac_bar_7_numeric,
         Train_Goal_Fac_Bar_8 = train_goal_fac_bar_8_numeric,
         Train_Goal_Fac_Bar_9 = train_goal_fac_bar_9_numeric,
         Train_Goal_Fac_Bar_10 = train_goal_fac_bar_10_numeric,
         Tech_Basic_1 = techbasic1_numeric,
         Tech_Basic_2 = techbasic2_numeric,
         Tech_Basic_3 = techbasic3_numeric,
         Tech_Feel_1 = techfeel1_numeric,
         Tech_Feel_2 = techfeel2_numeric,
         Tech_Feel_3 = techfeel3_numeric,
         Tech_Feel_4 = techfeel4_numeric,
         Tech_Feel_5 = techfeel5_numeric,
         ProQOL_CS = CS,
         ProQOL_BO = BO,
         ProQOL_STS = STS,
         CSW_EvalDate = CSWEvalDate,
         CSW_Sat_1 = cswsat1_numeric,
         CSW_Sat_2 = cswsat2_numeric,
         CSW_Sat_3 = cswsat3_numeric,
         CSW_Sat_4 = cswsat4_numeric,
         CSW_Sat_5 = cswsat5_numeric,
         CSW_Sat_6 = cswsat6_numeric,
         CSW_Sat_7 = cswsat7_numeric,
         Finished_CSW = finishedCSW,
         Finished_Didactic = finisheddidac,
         Completed_Didactic_NotCSW = completediddnotcsw,
         CSW_Incomplete = incompleteCSW,
         Didactic_Sat_1 = didacticsat1_num,
         Didactic_Sat_2 = didacticsat2_num,
         Didactic_Sat_3 = didacticsat3_num,
         Didactic_Sat_4 = didacticsat4_num,
         Didactic_Sat_5 = didacticsat5_num,
         Didactic_Sat_6 = didacticsat6_num,
         Didactic_Sat_7 = didacticsat7_num,
         Didactic_EvalDate = DIDEvalDate,
         Didactic_SDate = Didactic_Start,
         Didactic_EDate = Didactic_End,
         Attrited = prog_attrited,
         Exit_Date = exit_date,
         Stage_Raw = stg_reached,
         Started_Mod_1 = Mod1_started,
         Finished_Mod_1 = Mod1_finished,
         Started_Mod_2 = Mod2_started,
         Finished_Mod_2 = Mod2_finished,
         Started_Mod_3 = Mod3_started,
         Finished_Mod_3 = Mod3_finished,
         Started_Mod_4 = Mod4_started,
         Finished_Mod_4 = Mod4_finished,
         Started_Mod_5 = Mod5_started,
         Finished_Mod_5 = Mod5_finished,
         Started_Mod_6 = Mod6_started,
         Finished_Mod_6 = Mod6_finished,
         Started_Mod_7 = Mod7_started,
         Finished_Mod_7 = Mod7_finished,
         Started_Mod_8 = Mod8_started,
         Finished_Mod_8 = Mod8_finished,
         Started_Mod_9 = Mod9_started,
         Finished_Mod_9 = Mod9_finished,
         Started_Mod_10 = Mod10_started,
         Finished_Mod_10 = Mod10_finished,
         Started_Mod_11 = Mod11_started,
         Finished_Mod_11 = Mod11_finished,
         Started_Mod_12 = Mod12_started,
         Finished_Mod_12 = Mod12_finished,
         Mod_1_SDate = Mod1Start,
         Mod_2_SDate = Mod2Start,
         Mod_3_SDate = Mod3Start,
         Mod_4_SDate = Mod4Start,
         Mod_5_SDate = Mod5Start,
         Mod_6_SDate = Mod6Start,
         Mod_7_SDate = Mod7Start,
         Mod_8_SDate = Mod8Start,
         Mod_9_SDate = Mod9Start,
         Mod_10_SDate = Mod10Start,
         Mod_11_SDate = Mod11Start,
         Mod_12_SDate = Mod12Start) %>% 
  # Recode Stage_Raw into final set of stages to be modeled.
  mutate(Stage_Reached = case_when(Stage_Raw == 2 ~ 1,
                                   Stage_Raw == 3 ~ 2,
                                   Stage_Raw == 4 ~ 3,
                                   Stage_Raw == 5 ~ 4,
                                   Stage_Raw == 6 ~ 4,
                                   Stage_Raw == 7 ~ 5,
                                   .default = NA)) %>% 
  set_variable_labels(ID = "Applicant ID (may be blank if application was incomplete)",
                      NPQ_1_r = "I am happy. (reverse coded)", 
                      NPQ_4_r = "I feel connected to others. (reverse coded)", 
                      NPQ_15_r = "I have beliefs that sustain me. (reverse coded)",
                      NPQ_17_r = "I am the person I always wanted to be. (reverse coded)",
                      NPQ_29_r = "I am a very caring person. (reverse coded)",
                      Stage_Raw = "Stage Reached by Participant (Raw Values)",
                      Stage_Reached = "Maximum Stage Reached by Participant (Recoded)") %>% 
  set_value_labels(NPQ_1_r = reversed_NPQ_value_labels, 
                   NPQ_4_r = reversed_NPQ_value_labels, 
                   NPQ_15_r = reversed_NPQ_value_labels,
                   NPQ_17_r = reversed_NPQ_value_labels,
                   NPQ_29_r = reversed_NPQ_value_labels,
                   Stage_Raw = Stage_Raw_value_labels,
                   Stage_Reached = Stage_Reached_value_labels,
                   Eligible = Binary_Labels)
```

The imported `Applicants` data frame has `r nrow(Applicants)` rows and 
`r ncol(Applicants)` variables. @tbl-Applicants shows a list of the 
variable positions, names, classes, and labels.

``` {r}
#| label: tbl-Applicants
#| tbl-cap: "Applicants: Updated Variable Names and Classes."

ApplicantsVars <- list(Applicants) %>% 
  map_dfr(~ tibble(Name = names(.x), 
                   Class = map_chr(.x, all_classes),
                   Label = var_label(.x))) %>% 
  rowid_to_column(., "Position")

kable(ApplicantsVars, format = "latex", booktabs = TRUE, longtable = TRUE) %>%
  kable_styling(font_size = 7, latex_options = c("repeat_header")) %>% 
  column_spec(column = 3, width = "3cm") %>% 
  column_spec(column = 4, width = "6.5cm")
```

\FloatBarrier

## Create `Eligible_Applicants` Dataset
The study's focus is on examining attrition among eligible applicants. The 
research team believes that the recruitment materials were sufficiently clear 
about the program's eligibility criteria, so while it will be useful to report 
an eligibility rate, they have no substantive interest examining predictors of 
ineligibilty. 

For modeling purposes, we need to subset the data to create an 
`Eligible_Applicants` dataset. 

```{r}
#| label: create-Eligible-Applicants

Eligible_Applicants <- Applicants %>% 
  filter(Stage_Raw >= 2)
```

## Create Person-Threshold Dataset
This study will use a stopping-ratio model, which is also called a backward 
continuation-ratio model [@Liu-RN8772] or a stage model [@Fullerton-RN8774]. To 
run the planned model, we first reorganize the data from one row per person to
one row per person per threshold attempted [@Cole-RN8770; @Fullerton-RN8774]. 
That reorganization allows us to use standard logistic regression modeling
software to fit the model and flexibly choose whether predictor effects are
parallel (constrained to equality across thresholds), or non-parallel
(unconstrained and allowed to vary across thresholds) by either omitting or
including interaction terms.

@fig-Stages shows the final set of stages and thresholds between them at which
attrition from the training program could occur. The arrows associated with each
threshold are labeled according to how the outcome variable is coded on the
corresponding person-threshold record, depending on whether the person
stopped participating at the current stage or moved on to the next stage.

```{dot}
//| label: fig-Stages
//| fig-cap: Stages, Thresholds (T1-T4), and Stopping Ratios (SR1-SR4) in the 
//|          SANE Training Program. CSW, clinical skills workshop; DT, didactic 
//|          training.
//| fig-width: 6
//| fig-height: 3

digraph StagesModeled {

graph [rankdir="LR"];

node [shape = "box", style= "filled", fillcolor = "Gray90", fontsize = "7"];
A1 [label = "Attrited 1\nNot Enrolled\nSR1"]
A2 [label = "Attrited 2\nBefore DT\nSR2"]
A3 [label = "Attrited 3\nDuring DT\nSR3"]
A4 [label = "Attrited 4\nBefore CSW\nSR4"]

S1 [label = "Stage 1\nEligible"]
S2 [label = "Stage 2\nEnrolled"]
S3 [label = "Stage 3\nStarted DT"]
S4 [label = "Stage 4\nFinished DT"]
S5 [label = "Stage 5\nFinished CSW"]

edge [fontsize = "7"];

S1 -> A1 [label = "T1\nAttrit = 1"]
S2 -> A2 [label = "T2\nAttrit = 1"]
S3 -> A3 [label = "T3\nAttrit = 1"]
S4 -> A4 [label = "T4\nAttrit = 1"]

S1 -> S2 [label = "Attrit = 0"]
S2 -> S3 [label = "Attrit = 0"]
S3 -> S4 [label = "Attrit = 0"]
S4 -> S5 [label = "Attrit = 0"]
}
```

To create the person-threshold dataset `Thresholds`, we first create a data 
frame for each distinct threshold by filtering the `Eligible_Applicants` data by 
`Stage_Reached`, add a binary outcome variable called `Attrit` coded 1 
for people who attrited at that threshold and 0 for people who did not, then 
vertically stack the threshold-specific datasets (`T1` to `T4`). 

```{r}
#| label: create-T1

T1 <- Eligible_Applicants %>% 
  filter(Stage_Reached >= 1) %>% 
  mutate(Threshold = 1, 
         Attrit = if_else(Stage_Reached == Threshold, true = 1, false = 0))
```

```{r}
#| label: create-T2

T2 <- Eligible_Applicants %>% 
  filter(Stage_Reached >= 2) %>% 
  mutate(Threshold = 2, 
         Attrit = if_else(Stage_Reached == Threshold, true = 1, false = 0))
```

```{r}
#| label: create-T3

T3 <- Eligible_Applicants %>% 
  filter(Stage_Reached >= 3) %>% 
  mutate(Threshold = 3, 
         Attrit = if_else(Stage_Reached == Threshold, true = 1, false = 0))
```

```{r}
#| label: create-T4

T4 <- Eligible_Applicants %>% 
  filter(Stage_Reached >= 4) %>% 
  mutate(Threshold = 4, 
         Attrit = if_else(Stage_Reached == Threshold, true = 1, false = 0))
```

```{r}
#| label: create-value-labels-2

# Create vectors of value labels for reverse-coded NPQ items.
Threshold_Labels <- c("T1 (Eligible/Enrolled)",
                      "T2 (Enrolled/Started DT)",
                      "T3 (Started DT/Finished DT)",
                      "T4 (Finished DT/Finished CSW)")
```

```{r}
#| label: create-Thresholds

Thresholds <- bind_rows(T1, T2, T3, T4) %>% 
  relocate(ID, Threshold, Attrit) %>% 
  set_value_labels(Threshold = Threshold_Labels, 
                   Attrit = Binary_Labels)
```

@tbl-Dataset-Size shows the sizes of datasets created above in terms of number 
rows and columns, with additional computed columns showing how many records 
stopped from proceeding to the next stage of case selection and how many 
continued. This allowed me to double-check that the sizes each made sense. For 
the `Applicants` row, the stopped cases are the ineligible applicants, while for 
`Eligible_Applicants`, the stopped cases are those that did not enroll. Datasets 
`T1` to `T4` each have one row per person, with the stopped cases being those that 
attrited at the specified threshold. The `Thresholds` dataset contains one row 
per person per threshold encountered because it combined the rows of `T1` to 
`T4`, with the stopped cases being all the rows that indicated attrition 
occurred. 

```{r}
#| label: tbl-Dataset-Size
#| tbl-cap: Dataset Sizes

tibble(DataFrame = c("Applicants", "Eligible_Applicants", "T1", "T2", "T3", 
                     "T4", "Thresholds"),
       N_Rows = c(nrow(Applicants), nrow(Eligible_Applicants), nrow(T1), 
                  nrow(T2), nrow(T3), nrow(T4), nrow(Thresholds)),
       N_Cols = c(ncol(Applicants), ncol(Eligible_Applicants), ncol(T1), 
                  ncol(T2), ncol(T3), ncol(T4), ncol(Thresholds)),
       Stopped = c(sum(is.na(Applicants$Stage_Reached)),
                   sum(Eligible_Applicants$Stage_Reached < 2),
                   sum(T1$Attrit), sum(T2$Attrit), sum(T3$Attrit), 
                   sum(T4$Attrit), sum(Thresholds$Attrit))) %>% 
  mutate(Continued = N_Rows - Stopped) %>% 
  kable(format = "latex", booktabs = TRUE) %>% 
  kable_styling()
```

\FloatBarrier

# Save Data

``` {r}
#| label: create-save-what

# Character vector of object names that will be saved.
save_what <- c("Applicants", "Eligible_Applicants", "Thresholds")
```

``` {r}
#| label: save-data

# Store path to data file. 
DataFile <- here("data/Imported_SANETP_Data.RData")

save(list = save_what, file=DataFile)
```

@tbl-imported-data-file shows meta-data about the data file we just saved.

```{r}
#| label: tbl-imported-data-file
#| tbl-cap: "Meta-Data About the Imported Data File Saved Out"

file.info(DataFile, extra_cols = FALSE) %>% 
  rownames_to_column() %>% 
  mutate(rowname = basename(rowname)) %>% 
  select(-isdir, -mode) %>% 
  kable(, format = "latex", booktabs = TRUE, 
        col.names = c("File Name", "Size (Bytes)", "Modified", 
                      "Last Status Change", "Last Accessed")) %>% 
  kable_styling() %>% 
  column_spec(column = 3:5, width = "2cm")
```

::: {.callout-tip}
The imported data file can be loaded into R by copying the following code chunk 
into a script, setting the chunk option `eval: true`, and running the chunk. 
That will overwrite any objects already in memory that have the same names as 
the objects being loaded.

``` {r}
#| label: load-data
#| eval: false

load(file=here("data/Imported_SANETP_Data.RData"))
```
:::

\FloatBarrier

# References
::: {#refs}
:::

\FloatBarrier

# Software Information
This section documents information that is important for reproducibility. Most
users will not need to read it. It is primarily here for use by the statistician 
on the team if we need to troubleshoot reproducibility issues because someone 
else is unable to get the same results from the same code. Start by checking for 
differences in package versions. 

We used [R](https://www.r-project.org/) as our main computing environment and
[Quarto](https://quarto.org/) scripts to enhance reproducibility. We used
[RStudio](www.rstudio.org) as the editor to interface with R and Quarto.

- Software chain:
  **qmd file > RStudio > Quarto > R > knitr > md file > Pandoc > tex file > TinyTeX > PDF file**.
- Source file: \texttt{\detokenize{`r params$SourceFile`}} 
- Output file: \texttt{\detokenize{`r params$LogFile`}} 
- [Quarto `r quarto_version()`](https://quarto.org/) runs `*.qmd` files through 
  [R](https://www.r-project.org/) and [knitr](https://yihui.org/knitr/) to 
  produce `*.md` markdown files.
- [Pandoc `r rmarkdown::pandoc_version()`](https://pandoc.org) converts markdown 
  files (`*.md`) to other formats, including LaTeX (`*.tex`) and HTML (`*.html`) 
  among others.
- [TinyTeX](https://yihui.org/tinytex/) compiles LaTeX files (`*.tex`) into PDF 
  files. It should be viable to use [MiKTeX](https://miktex.org) or another 
  LaTeX distribution instead. 

\FloatBarrier

## Versions
This document was generated using the following computational environment and 
dependencies:

```{r}
#| label: show-version
#| echo: true

# Check and report whether we used TinyTex or other LaTeX software. 
which_latex()

# Get R and R package version numbers in use.
devtools::session_info()
```

\FloatBarrier

## Git Details
The current Git commit details and status are:

``` {r}
#| label: git-details
#| echo: true

git_report()
```

This is useful because it tells us exactly which commit in the Git history 
we would need to be using to make sure we are running the exact same code. 
Sometimes another person is not using the most current code, or has changed the 
code in some way since it was last committed.  

::: {.callout-tip}
Untracked files are files located in the repository that Git has not been told 
to entirely ignore, but have also not been committed into the version history. 

Unstaged changes to files indicate that some of the contents have been modified 
since the last time the file was committed to Git. In production runs, we want 
the Git output to not show any unstaged changes to key files!
::: 
