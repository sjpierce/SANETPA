---
title: Import and Manage SANE Training Program Data
subtitle: | 
          | CSTAT Case: C1788
          | Clients: Rebecca Campbell, Autumn Ashley, & Katherine Dontje
author: 
  - name: Steven J. Pierce
    orcid: 0000-0002-0679-3019
    email: pierces1@msu.edu
    affil-id: 1 
affiliations: 
  - id: 1 
    name: Michigan State University
    department: Center for Statistical Training and Consulting
    url: "[https://cstat.msu.edu](https://cstat.msu.edu)"
bibliography: references.bib          # File holds BibTeX data for references
csl: apa.csl                          # File controls citation & reference list format
params:                               # Default values for parameters
  SourceDir: "scripts/"               # Relative path to folder holding this file
  SourceFile: "Import_Data.qmd"       # Name of this script file
  LogFile: "Import_Data_Draft.pdf"   # Default name of rendered output file
format: 
  pdf:                                # Settings for PDF output
    output-file: "Import_Data_Draft.pdf" # Default output file name 
    output-ext: "pdf"                 # Default file name extension
    documentclass: scrartcl           # LaTeX document type
    papersize: letter
    geometry:                         # Control page margins
      - top=1in
      - bottom=1in
      - left=1in
      - right=1in
    number-sections: true           # Auto-number each section
    toc: true                       # Include table of contents (TOC)
    toc-depth: 3                    # Number of layers in TOC
    colorlinks: true
    template-partials: 
      - title.tex   # Controls author affiliation formatting
    include-in-header:
      - file: compact-title.tex    # Controls spacing around title. 
      - text: |
          \usepackage{fancyhdr}
          \usepackage[noblocks]{authblk}
          \renewcommand*{\Authsep}{, }
          \renewcommand*{\Authand}{, }
          \renewcommand*{\Authands}{, }
          \renewcommand\Affilfont{\small}
          \usepackage[yyyymmdd,hhmmss]{datetime}    %% for currenttime command
          \usepackage{lastpage}                     %% For pageref command
          \usepackage{fontspec}
          \defaultfontfeatures{Ligatures=TeX}
          \usepackage[font={small}, margin=1cm, skip=2pt]{caption}
          \usepackage{url}
          \usepackage{floatrow}                     %% For controlling float placement
          \floatsetup[table]{capposition=top}       %% Puts table caption at top.
          \floatsetup[longtable]{margins=centering} %% Centers longtable tables
          \floatplacement{figure}{!ht}              %% Control placement of figures
          \floatplacement{table}{!ht}               %% Control placement of tables
          \usepackage[labelfont=bf, textfont=bf]{caption}  %% For bolded table/figure captions
          \usepackage{placeins}                     %% For FloatBarrier command
          \usepackage{booktabs}                     %% Used by kableExtra
          \usepackage{longtable}                    %% Used by kableExtra
          \usepackage{array}                        %% Used by kableExtra
          \usepackage{multirow}                     %% Used by kableExtra
          \usepackage{wrapfig}                      %% Used by kableExtra
          \usepackage{colortbl}                     %% Used by kableExtra
          \usepackage{pdflscape}                    %% Used by kableExtra
          \usepackage{tabu}                         %% Used by kableExtra
          \usepackage[normalem]{ulem}               %% Used by kableExtra
          \usepackage{makecell}                     %% Used by kableExtra
          \usepackage{xcolor}                       %% Used by kableExtra
          \usepackage{dcolumn}                      %% Used by kableExtra
          \usepackage{threeparttable}               %% Used by kableExtra
          \usepackage{threeparttablex}              %% Used by kableExtra
          \usepackage{amsmath}                      %% for equation support. 
          \usepackage{titling}      
          \usepackage{verbatim}                     %% For comment command
          \pretitle{\begin{center}\LARGE\bfseries\sffamily}
          \posttitle{\end{center}}
          \pagestyle{fancy}
          \lhead{SANETPA Import Data}
          \chead{\includegraphics[height=0.85cm]{../graphics/Combomark-Horiz_Pantone-567.pdf}}
          \rhead{\today\ \currenttime}
          \cfoot{ }
          \fancyfoot[R]{\thepage\ of \pageref*{LastPage}}
          \renewcommand{\headrulewidth}{0.4pt}
          \renewcommand{\footrulewidth}{0.4pt}
          \fancypagestyle{plain}{\pagestyle{fancy}}
          \newcommand*\tocentryformat[1]{{\sffamily#1}}  %% Fix TOC font style
          \RedeclareSectionCommands                      %% Fix TOC font style
            [
              tocentryformat=\tocentryformat,
              tocpagenumberformat=\tocentryformat
            ]
            {section,subsection,subsubsection,paragraph,subparagraph}
execute:                              # Default Quarto chunk execution options
  eval: true
  echo: fenced                        # Show the code in the output file
  output: true
  warning: true
  error: true
  include: true
knitr:                                # Default R knitr package chunk options
  opts_chunk: 
    message: true
    cfsize: "tiny"  
---

\lfoot{\texttt{\small \detokenize{`r params$LogFile`}}}

\FloatBarrier

# Purpose
This file is part of a research compendium [@Pierce-RN8756] associated with a 
study about a sexual assault nurse examiner training program [@Dontje-RN8757]. 
It imports data from from an SPSS data file provided by the investigators, does
some data cleaning and management, then saves out an R data file that will be 
used by other scripts in this compendium. 

\FloatBarrier

# Setup
This section documents some setup tasks that are useful to the statistician on 
the team. Most readers of this document will probably want skip directly to 
@sec-Data-Mgt.

\FloatBarrier

## Define Global Options
Global R chunk options are defined in the YAML header but local chunk options
will over-ride global options. We can temporarily disable an individual chunk by
inserting `#| eval: false` on a line at the top of the chunk. The method for
creating a `cfsize` option that controls font size in code chunks and their text
output is based on an answer to a question posted on
[stackoverflow.com](https://stackoverflow.com/a/46526740).

``` {r}
#| label: global-options

# Create a custom chunk hook/option for controlling font size in chunk & output.
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$cfsize != "normalsize", 
         paste0("\n \\", options$cfsize,"\n\n", x, "\n\n \\normalsize"), 
         x)
  })
```

\FloatBarrier

## Load Packages
R packages usually add new functions to the base R software, allowing you to do 
more things. Here, we load the specific R packages required for this script to 
work.

```{r}
#| label: load-packages
library(devtools)       # for session_info()
library(here)           # for here(), i_am(), makes code more portable.
library(rmarkdown)      # for pandoc_version()
library(knitr)          # for kable()
library(dplyr)          # for %>%, filter(), group_by(), mutate(), rename(), etc.
library(tidyverse)      # for map_dfr(), map_chr(), rowid_to_column(), 
                        # rownames_to_column()
library(haven)          # for read_SPSS()
library(labelled)       # for var_label()
options(kableExtra.latex.load_packages = FALSE)
library(kableExtra)     # for kable_styling(), add_header_above(), 
                        # column_spec(), row_spec() etc. 
library(kableExtra)     # for kable_styling 
library(piercer)        # for cvv_missingness(), file_details(), git_report(), 
                        # var_missingness(), which_latex()
library(quarto)         # for quarto_version()
library(SANETPA)        # for version info 
```

\FloatBarrier

## Declare Path
This next chunk declares the path to this script relative to the project-level 
root directory. If the file is not in the right location under the project root
you'll get a warning message. This helps ensure relative paths are all working 
as expected. The chunk below uses the `SourceDir` and `SourceFile` parameters 
set in the YAML header. 

``` {r}
#| label: declare-path

# Declare path to this script relative to the project root directory.
here::i_am(path = paste0(params$SourceDir, params$SourceFile))
```

\FloatBarrier

# Data Management {#sec-Data-Mgt}

\FloatBarrier

## Read SPSS Data into `Applicants_Raw` Dataset {#sec-Read-Data}
The raw data provided by the investigators is in an SPSS data file. This section 
imports it into an R data frame/tibble. The raw data is de-identified to 
preserve participant privacy and protect confidentiality. 

The `ID` variable in the data has no intrinsic meaning and could only be linked
to actual participant names via the key retained by the principal investigators.
Per email communication that accompanied delivery of the data, it has missing 
data because "The ids were not generated until the end of application 1- so they 
would have had to get through all of the questions for part a first" (A. Ashley, 
personal communication, May 18, 2025). 

:::{.callout-note}
I recevied an updated data file called `All_group_1_2025-06-03.sav` that fixed
some inaccurate data values detected by a previous iteration of the descriptive
analyses. It is now in my local repository and replaced the previous data file.
It includes all applicants (even those who were ineligible). The date in the
file name is when I received the file.
:::

@tbl-raw-data-file shows meta-data about the raw data file we will import.

```{r}
#| label: tbl-raw-data-file
#| tbl-cap: "Meta-Data About Raw Data File"

# Store path to raw data file. 
RawFile <- here("scripts/extdata/All_group_1_2025-06-03.sav")

file_details(RawFile) %>% 
  kable(, format = "latex", booktabs = TRUE, 
        col.names = c("File Name", "Size", "Last Modified")) %>% 
  kable_styling()
```

Next, we actually read that SPSS file into a data frame called `Applicants_Raw`. 
That will be an intermediate form of the data because we need to do some data 
management before it is ready for use in descriptive and inferential analyses. 

```{r}
#| label: import-data

Applicants_Raw <- read_spss(RawFile) 
```

The imported `Applicants_Raw` data frame has `r nrow(Applicants_Raw)` rows and 
`r ncol(Applicants_Raw)` variables. @tbl-Applicants-Raw shows a list of the 
variable positions, names, classes, and labels prior to any data management.

``` {r}
#| label: tbl-Applicants-Raw
#| tbl-cap: "Applicants_Raw: Variable Names and Classes."

ApplicantsVars <- list(Applicants_Raw) %>% 
  map_dfr(~ tibble(Name = names(.x), 
                   Class = map_chr(.x, all_classes),
                   Label = var_label(.x))) %>% 
  rowid_to_column(., "Position")

kable(ApplicantsVars, format = "latex", booktabs = TRUE, longtable = TRUE) %>%
  kable_styling(font_size = 7, latex_options = c("repeat_header")) %>% 
  column_spec(column = 3, width = "3cm") %>% 
  column_spec(column = 4, width = "6.5cm")
```

## Check Data for Problems

:::{.callout-tip}
Both `finisheddidac` and `Didactic_Status` are binary variables coding whether 
a person completed the didactic training. The crosstab outputs below show that  
the difference between them is that `finisheddidac` has no missing data (`NA`), 
but a substantial number of applicants have missing `Didactic_Status` paired
with `finisheddidac = 0`. All applicants with `finisheddidac = 1` had 
`Didactic_Status = 1`. 

```{r}
#| label: xtab-finisheddidac-Didactic-Status

xtabs(~finisheddidac + Didactic_Status, addNA = TRUE, 
      data = Applicants_Raw) %>% 
  addmargins()
```

We can also see that only applicants who were not enrolled have missing values 
(`NA`) on `Didactic_Status`. 

```{r}
#| label: xtab-Enrolled-Didactic-Status

xtabs(~Enrolled + Didactic_Status, addNA = TRUE, 
      data = Applicants_Raw) %>% 
  addmargins()
```

We will retain both `finisheddidac` and `Didactic_Status` because each may be 
useful depending on the summary desired.
:::

@tbl-prog-attrited shows the value labels associated with the `prog_attrited` 
variable. While it is a binary indicator variable (as expected), the coding is 
reversed compared to what I expected given the variable name. Assigning 0 = 
completed program and 1 = attrited without completing program would make more 
sense. We will fix that later after renaming the variable to `Attrited`. 

```{r}
#| label: tbl-prog-attrited
#| tbl-cap: Original Value Labels for prog_attrited in Applicants_Raw Data

Applicants_Raw %>% 
  select(prog_attrited) %>% 
  get_value_labels() %>% 
  stack() %>% 
  rename(Variable = ind,
         Value = values) %>% 
  rownames_to_column(var = "Label") %>% 
  relocate(Variable, Value) %>% 
  kable(format = "latex") %>% 
  kable_styling()
```
               
\FloatBarrier

## Create Applicants Dataset
This section creates the `Applicants` data frame from an updated version of the 
`Applicants_Raw` data frame. These changes prepare the data for the planned 
analyses by applying more consistent and convenient naming conventions, updating 
value labels, converting categorical variables to factors, and so on. 

:::{.callout-tip}
The expected uses for the `Applicants` data are:

* Serve as the root source from which other required datasets are derived. 
* Compute eligibility rate and associated confidence interval. 

:::

The research team believes that the recruitment materials were sufficiently
clear about the program's eligibility criteria, so while it will be useful to
report an eligibility rate, they have no substantive interest examining
predictors of ineligibility. 

The chunk below defines some value labels we will use when creating the 
`Applicants` dataset from `Applicants_Raw`. 

```{r}
#| label: create-value-labels

# Labels for binary variables
Binary_Labels <- c(No = 0, Yes = 1)

# Create vectors of value labels for reverse-coded NPQ items.
reversed_NPQ_value_labels <- c(`Very Often` = 1, Often = 2, Sometimes = 3, 
                               Rarely = 4, Never = 5)

# More concise labels for the raw stages. 
Stage_Raw_value_labels <- c(`Applied` = 1, `Eligible` = 2, `Enrolled` = 3, 
                            `Started DT` = 4, `Finished DT` = 5, 
                            `Started CSW` = 6, `Finished CSW` = 7)

# Final stages to be modeled. 
Stage_Reached_value_labels <- c(`Enrolled` = 1, `Started DT` = 2, 
                                `Finished DT` = 3, `Finished CSW` = 4)

# Final settings to be modeled
Setting_Labels <- c("Urban" = 1, "Rural/Tribal" = 2, "Suburban" = 3)

# Training barriers value labels
Barriers_Labels <-  c(`strongly disagree` = 1, `somewhat disagree` = 2, 
                      `neither agree nor disagree` = 3, `somewhat agree` = 4, 
                      `strongly agree` = 5)

# Reversed training barriers value labels
Barriers_Reversed_Labels <-  c(`strongly agree` = 1, `somewhat agree` = 2, 
                               `neither agree nor disagree` = 3, 
                               `somewhat disagree` = 4, `strongly disagree` = 5)
```

In the raw data, `stg_reached` was coded into 7 ordered categories to get the 
most granular set of categories we thought we might need. Below we replace the 
imported value labels for those stages with more concise labels. We also rename 
that variable to `Stage_Raw`, then use it to create the `Stage_Reached` variable 
by recoding as shown in @tbl-stage-recode. 

```{r}
#| label: tbl-stage-recode
#| tbl-cap: Recoding from Stage_Raw to Stage_Reached

tibble(Raw_Value = 1:7,
       Reached_Value = c(NA, NA, 1, 2, 3, 3, 4)) %>% 
  set_value_labels(Raw_Value = Stage_Raw_value_labels,
                   Reached_Value = Stage_Reached_value_labels) %>% 
  mutate(Raw_Label = as_factor(Raw_Value),
         Reached_Label = as_factor(Reached_Value)) %>% 
  select(Raw_Value, Raw_Label, Reached_Value, Reached_Label) %>% 
  kable(format = "latex", booktabs = TRUE) %>% 
  kable_styling() %>% 
  add_header_above(header = c("Stage_Raw" = 2, "Stage_Reached" = 2))
```

Only one participant started the clinical skills training without
finishing it (`Stage_Raw` = 6). For that stage, the stopping rate would be
really close to 0 for the transition between starting and finishing clinical
training. That could cause a separation issue (estimation could break down due
to insufficient outcome variability at that threshold). Treating that case as
having stopped at finishing the didactic training should avoid that problem.

::: {.callout-important}
The raw `practicset_dem_num` variable was coded into 4 categories (Urban, Rural,
Suburban, Tribal) but initial descriptive analyses revealed that there are too 
few observations to use Tribal as a separate category. The study investigators 
decided that omitting the small number of participants who practice in nursing 
Tribal settings was inappropriate. Feedback from project stakeholders led them 
to combine Rural and Tribal categories because those categories represent
settings most similar in size. However, we must acknowledge in our paper that
this glosses over important cultural differences between Rural and Tribal
settings. It is an imperfect way to include data from those participants, but we
have no better option.
:::

We want to use measures of the extent to which personal and professional demands 
on participants' time are a barrier to participation in the training program.
We considered using the following three items from the training application 
form:

* `train_goal_fac_bar_5_numeric`: I have time in my schedule to focus on this 
  course. 
* `train_goal_fac_bar_8_numeric`: I have a lot of work responsibilities.
* `train_goal_fac_bar_10_numeric`: I have a lot of family obligations right now. 

These ordinal Likert-response items are coded (1, strongly disagree; 2, somewhat 
disagree; 3, neither agree or disagree; 4, somewhat agree; and 5, strongly 
agree). We wanted to create an unweighted sum of the items such that large 
values indicate high external demands on the participant's time, so we reversed 
the coding of `train_goal_fac_bar_5_numeric` to (1, strongly agree; 2, somewhat 
agree; 3, neither agree or disagree; 4, somewhat disagree; and 5, strongly 
disagree) for that to make sense. The `Descriptive_Analyses.qmd` script examined 
the 3 items and the led us to decide to only use the latter two. See the output 
from that script for why we excluded the first of those items. This script will 
create copies of the latter two items with shorter names that reflect potential 
barriers to participation posed by work responsibilities (`Barrier_WR`) and 
family obligations (`Barrier_FO`) for use in modeling. 

```{r}
#| label: create-Applicants

Applicants <- Applicants_Raw %>% 
  rename(Education = educ_dem_num,
         License = license_num,
         Employ_Status = employment_dem_num,
         Employ_Nurse = employednurse_dem_num,
         Nurse_Years = nursexperience_years,
         Recruited_How = recruitment_num,
         Prior_SANE = prevSANEtrain_num,
         Trained1_Year = trained1year_num,
         Trained2_Year = trained2year,
         Disability = Disability_status,
         Sex = sex_dem_num,
         Pronoun = pronoun_dem_num,
         Age = age_num,
         Race_Ethnicity = race_ethnicity_num,
         Income = income_dem_num,
         LGBTQ = LGBTQ_num,
         NPQ_1 = npq1,
         NPQ_2 = npq2,
         NPQ_3 = npq3, 
         NPQ_4 = npq4, 
         NPQ_5 = npq5, 
         NPQ_6 = npq6, 
         NPQ_7 = npq7, 
         NPQ_8 = npq8, 
         NPQ_9 = npq9, 
         NPQ_10 = npq10, 
         NPQ_11 = npq11, 
         NPQ_12 = npq12,
         NPQ_13 = npq13,
         NPQ_14 = npq14, 
         NPQ_15 = npq15, 
         NPQ_16 = npq16, 
         NPQ_17 = npq17, 
         NPQ_18 = npq18, 
         NPQ_19 = npq19, 
         NPQ_20 = npq20, 
         NPQ_21 = npq21,
         NPQ_22 = npq22, 
         NPQ_23 = npq23, 
         NPQ_24 = npq24, 
         NPQ_25 = npq25, 
         NPQ_26 = npq26, 
         NPQ_27 = npq27, 
         NPQ_28 = npq28, 
         NPQ_29 = npq29, 
         NPQ_30 = npq30, 
         NPQ_1_r = npq1r, 
         NPQ_4_r = npq4r, 
         NPQ_15_r = npq15r,
         NPQ_17_r = npq17r,
         NPQ_29_r = npq29r,
         Plan_After_Training = PlansFollowingTraining_Num,
         Train_Goal_Fac_Bar_1 = train_goal_fac_bar_1_numeric,
         Train_Goal_Fac_Bar_2 = train_goal_fac_bar_2_numeric,
         Train_Goal_Fac_Bar_3 = train_goal_fac_bar_3_numeric,
         Train_Goal_Fac_Bar_4 = train_goal_fac_bar_4_numeric,
         Train_Goal_Fac_Bar_5 = train_goal_fac_bar_5_numeric,
         Train_Goal_Fac_Bar_6 = train_goal_fac_bar_6_numeric,
         Train_Goal_Fac_Bar_7 = train_goal_fac_bar_7_numeric,
         Train_Goal_Fac_Bar_8 = train_goal_fac_bar_8_numeric,
         Train_Goal_Fac_Bar_9 = train_goal_fac_bar_9_numeric,
         Train_Goal_Fac_Bar_10 = train_goal_fac_bar_10_numeric,
         Tech_Basic_1 = techbasic1_numeric,
         Tech_Basic_2 = techbasic2_numeric,
         Tech_Basic_3 = techbasic3_numeric,
         Tech_Feel_1 = techfeel1_numeric,
         Tech_Feel_2 = techfeel2_numeric,
         Tech_Feel_3 = techfeel3_numeric,
         Tech_Feel_4 = techfeel4_numeric,
         Tech_Feel_5 = techfeel5_numeric,
         ProQOL_CS = CS,
         ProQOL_BO = BO,
         ProQOL_STS = STS,
         CSW_EvalDate = CSWEvalDate,
         CSW_Sat_1 = cswsat1_numeric,
         CSW_Sat_2 = cswsat2_numeric,
         CSW_Sat_3 = cswsat3_numeric,
         CSW_Sat_4 = cswsat4_numeric,
         CSW_Sat_5 = cswsat5_numeric,
         CSW_Sat_6 = cswsat6_numeric,
         CSW_Sat_7 = cswsat7_numeric,
         Finished_CSW = finishedCSW,
         Finished_Didactic = finisheddidac,
         Completed_Didactic_NotCSW = completediddnotcsw,
         CSW_Incomplete = incompleteCSW,
         Didactic_Sat_1 = didacticsat1_num,
         Didactic_Sat_2 = didacticsat2_num,
         Didactic_Sat_3 = didacticsat3_num,
         Didactic_Sat_4 = didacticsat4_num,
         Didactic_Sat_5 = didacticsat5_num,
         Didactic_Sat_6 = didacticsat6_num,
         Didactic_Sat_7 = didacticsat7_num,
         Didactic_EvalDate = DIDEvalDate,
         Didactic_SDate = Didactic_Start,
         Didactic_EDate = Didactic_End,
         Attrited = prog_attrited,
         Exit_Date = exit_date,
         Stage_Raw = stg_reached,
         Started_Mod_1 = Mod1_started,
         Finished_Mod_1 = Mod1_finished,
         Started_Mod_2 = Mod2_started,
         Finished_Mod_2 = Mod2_finished,
         Started_Mod_3 = Mod3_started,
         Finished_Mod_3 = Mod3_finished,
         Started_Mod_4 = Mod4_started,
         Finished_Mod_4 = Mod4_finished,
         Started_Mod_5 = Mod5_started,
         Finished_Mod_5 = Mod5_finished,
         Started_Mod_6 = Mod6_started,
         Finished_Mod_6 = Mod6_finished,
         Started_Mod_7 = Mod7_started,
         Finished_Mod_7 = Mod7_finished,
         Started_Mod_8 = Mod8_started,
         Finished_Mod_8 = Mod8_finished,
         Started_Mod_9 = Mod9_started,
         Finished_Mod_9 = Mod9_finished,
         Started_Mod_10 = Mod10_started,
         Finished_Mod_10 = Mod10_finished,
         Started_Mod_11 = Mod11_started,
         Finished_Mod_11 = Mod11_finished,
         Started_Mod_12 = Mod12_started,
         Finished_Mod_12 = Mod12_finished,
         Mod_1_SDate = Mod1Start,
         Mod_2_SDate = Mod2Start,
         Mod_3_SDate = Mod3Start,
         Mod_4_SDate = Mod4Start,
         Mod_5_SDate = Mod5Start,
         Mod_6_SDate = Mod6Start,
         Mod_7_SDate = Mod7Start,
         Mod_8_SDate = Mod8Start,
         Mod_9_SDate = Mod9Start,
         Mod_10_SDate = Mod10Start,
         Mod_11_SDate = Mod11Start,
         Mod_12_SDate = Mod12Start) %>% 
  # Recode Stage_Raw into final set of stages to be modeled.
  mutate(Stage_Reached = case_when(Stage_Raw == 2 ~ 1,
                                   Stage_Raw == 3 ~ 1,
                                   Stage_Raw == 4 ~ 2,
                                   Stage_Raw == 5 ~ 3,
                                   Stage_Raw == 6 ~ 3,
                                   Stage_Raw == 7 ~ 4,
                                   .default = NA)) %>% 
  # Recode Attrited to reverse coding the bianry indicator. 
  mutate(Attrited = 1 - Attrited) %>% 
  # Recode practicset_dem_num into Setting, combining Rural & Tribal categories.
  mutate(Setting = if_else(practicset_dem_num %in% c(2,4), 
                           true = 2, 
                           false = practicset_dem_num)) %>% 
  # Reverse code an item, then compute a sum score for a new scale. 
  mutate(Train_Goal_Fac_Bar_5R = 6 - Train_Goal_Fac_Bar_5) %>% 
  rowwise() %>% 
  mutate(Barrier_WR = Train_Goal_Fac_Bar_8,
         Barrier_FO = Train_Goal_Fac_Bar_10) %>% 
  ungroup() %>% 
  # Set variable and value labels. 
  set_variable_labels(ID = "Applicant ID (may be blank if application was incomplete)",
                      NPQ_1_r = "I am happy. (reverse coded)", 
                      NPQ_4_r = "I feel connected to others. (reverse coded)", 
                      NPQ_15_r = "I have beliefs that sustain me. (reverse coded)",
                      NPQ_17_r = "I am the person I always wanted to be. (reverse coded)",
                      NPQ_29_r = "I am a very caring person. (reverse coded)",
                      Stage_Raw = "Stage Reached by Participant (Raw Values)",
                      Stage_Reached = "Maximum Stage Reached by Participant (Recoded)",
                      Setting = "How would you describe the primary setting you practice nursing in? (recoded)",
                      Train_Goal_Fac_Bar_5R = "I have time in my schedule to focus on this course",
                      Barrier_WR = "I have a lot of work responsibilities.",
                      Barrier_FO = "I have a lot of family obligations right now.") %>% 
  set_value_labels(NPQ_1_r = reversed_NPQ_value_labels, 
                   NPQ_4_r = reversed_NPQ_value_labels, 
                   NPQ_15_r = reversed_NPQ_value_labels,
                   NPQ_17_r = reversed_NPQ_value_labels,
                   NPQ_29_r = reversed_NPQ_value_labels,
                   Stage_Raw = Stage_Raw_value_labels,
                   Stage_Reached = Stage_Reached_value_labels,
                   Eligible = Binary_Labels,
                   Enrolled = Binary_Labels,
                   Attrited = Binary_Labels,
                   Started_Mod_1 = Binary_Labels,
                   Started_Mod_2 = Binary_Labels,
                   Started_Mod_3 = Binary_Labels,
                   Started_Mod_4 = Binary_Labels,
                   Started_Mod_5 = Binary_Labels,
                   Started_Mod_6 = Binary_Labels,
                   Started_Mod_7 = Binary_Labels,
                   Started_Mod_8 = Binary_Labels,
                   Started_Mod_9 = Binary_Labels,
                   Started_Mod_10 = Binary_Labels,
                   Started_Mod_11 = Binary_Labels,
                   Started_Mod_12 = Binary_Labels,
                   Finished_Mod_1 = Binary_Labels,
                   Finished_Mod_2 = Binary_Labels,
                   Finished_Mod_3 = Binary_Labels,
                   Finished_Mod_4 = Binary_Labels,
                   Finished_Mod_5 = Binary_Labels,
                   Finished_Mod_6 = Binary_Labels,
                   Finished_Mod_7 = Binary_Labels,
                   Finished_Mod_8 = Binary_Labels,
                   Finished_Mod_9 = Binary_Labels,
                   Finished_Mod_10 = Binary_Labels,
                   Finished_Mod_11 = Binary_Labels,
                   Finished_Mod_12 = Binary_Labels,
                   Setting = Setting_Labels,
                   Train_Goal_Fac_Bar_5R = Barriers_Reversed_Labels,
                   Barrier_WR = Barriers_Labels,
                   Barrier_FO = Barriers_Labels)
```

The imported `Applicants` data frame has `r nrow(Applicants)` rows and 
`r ncol(Applicants)` variables. @tbl-Applicants shows a list of the 
variable positions, names, classes, and labels.

``` {r}
#| label: tbl-Applicants
#| tbl-cap: "Applicants: Updated Variable Names and Classes."

ApplicantsVars <- list(Applicants) %>% 
  map_dfr(~ tibble(Name = names(.x), 
                   Class = map_chr(.x, all_classes),
                   Label = var_label(.x))) %>% 
  rowid_to_column(., "Position")

kable(ApplicantsVars, format = "latex", booktabs = TRUE, longtable = TRUE) %>%
  kable_styling(font_size = 7, latex_options = c("repeat_header")) %>% 
  column_spec(column = 3, width = "3cm") %>% 
  column_spec(column = 4, width = "6.5cm")
```

\FloatBarrier

## Create Eligible Applicants Datasets
For research question RQ1, we need to compare eligible applicants who enrolled 
versus did not enroll. Subsetting the `Applicants` dataset to create an 
`Eligible_Applicants` dataset representing the intended population relevant to 
that research question will simplify analyses later.  

:::{.callout-tip}
The expected uses for the `Eligible_Applicants` data are:

* Compute enrollment rate and associated confidence interval. 
* Conduct simple inferential analyses comparing eligible vs enrolled applicants 
  to answer RQ1.
* Serve as the source from which the `Enrolled_Applicants` dataset is derived. 

:::

```{r}
#| label: create-Eligible-Applicants

Eligible_Applicants <- Applicants %>% 
  filter(Stage_Raw >= 2) 
```

Next we need to assess whether these eligible applicants all have complete data
on the variables to be used in our RQ1 analyses.
@tbl-Eligible-Applicants-cvv-missingness shows an overview of missingness 
with respect to cases, variables, and values. 

```{r}
#| label: tbl-Eligible-Applicants-cvv-missingness
#| tbl-cap: Cases, Variables, and Values Missingness for RQ1 Among Eligible 
#|          Applicants

 Eligible_Applicants %>% 
  select(ID, Enrolled, Education, License, Setting, Employ_Status, Employ_Nurse, 
         Nurse_Years, Prior_SANE, Motivation_PersonalConn, Motivation_NeedSANE, 
         Barrier_FO, Barrier_WR, ProQOL_BO, ProQOL_CS, ProQOL_STS) %>% 
  cvv_missingness() %>% 
  kable(format = "latex", booktabs = TRUE, digits = 1,
        col.names = c("Subset", rep(c("Count", "Percent"), times = 3))) %>% 
  kable_styling() %>% 
  add_header_above(header = c(" ", "Cases" = 2, "Variables" = 2, "Values" = 2))
```

We can see that only a few eligible applicants have any missing data on the
variables we want to use in the models. @tbl-Eligible-Applicants-var-missingness
shows variable-specific rates of missingness.

```{r}
#| label: tbl-Eligible-Applicants-var-missingness
#| tbl-cap: Variable-Specific Missingness for RQ1 Among Eligible Applicants

 Eligible_Applicants %>% 
  select(ID, Enrolled, Education, License, Setting, Employ_Status, Employ_Nurse, 
         Nurse_Years, Prior_SANE, Motivation_PersonalConn, Motivation_NeedSANE, 
         Barrier_FO, Barrier_WR, ProQOL_BO, ProQOL_CS, ProQOL_STS) %>% 
  var_missingness() %>% 
  kable(format = "latex", booktabs = TRUE, digits = 1, 
        col.names = c("Position", "Name", "N_Total", "N", "%", "N", "%")) %>% 
  kable_styling() %>% 
  add_header_above(header = c(" " = 3, "Valid Values" = 2, "Missing Values" = 2))
```

\FloatBarrier

## Create Enrolled Applicants Datasets
This section creates the `Enrolled_Applicants` data frame from the
`Eligible_Applicants` data frame. We need this dataset because some analyses
focus only on enrolled applicants. Feedback from key stakeholders indicates that
our audience likely will think of attrition as dropping out the program after
enrollment, rather than as the broader concept of dropping out of the pipeline 
that starts at application to the program.

:::{.callout-tip}
The expected uses for the `Enrolled_Applicants` data are:

* Stopping-ratio modeling to answering RQ2 and RQ3.
* Descriptive analyses to answer RQ4. 

:::

```{r}
#| label: create-Enrolled-Applicants

Enrolled_Applicants <- Eligible_Applicants %>% 
  filter(Stage_Raw >= 3) 
```

Next, we need to assess whether these enrolled applicants all have complete data 
on the variables to be used in our RQ2 and RQ3 analyses. 
@tbl-Enrolled-Applicants-cvv-missingness shows an overview of missingness 
with respect to cases, variables, and values. 

```{r}
#| label: tbl-Enrolled-Applicants-cvv-missingness
#| tbl-cap: Cases, Variables, and Values Missingness for RQ2 & RQ3 Among 
#|          Enrolled Applicants

Enrolled_Applicants %>% 
  select(ID, Stage_Reached, Barrier_FO, Barrier_WR, ProQOL_BO, ProQOL_CS, 
         ProQOL_STS, Motivation_NeedSANE, Motivation_PersonalConn, Setting) %>% 
  cvv_missingness() %>% 
  kable(format = "latex", booktabs = TRUE, digits = 1,
        col.names = c("Subset", rep(c("Count", "Percent"), times = 3))) %>% 
  kable_styling() %>% 
  add_header_above(header = c(" ", "Cases" = 2, "Variables" = 2, "Values" = 2))
```

We can see that only a few eligible applicants have any missing data on the
variables we want to use in the models. @tbl-Enrolled-Applicants-var-missingness
shows variable-specific rates of missingness.

```{r}
#| label: tbl-Enrolled-Applicants-var-missingness
#| tbl-cap: Variable-Specific Missingness for RQ2 & RQ3 Among Enrolled 
#|          Applicants

Enrolled_Applicants %>% 
  select(ID, Stage_Reached, Barrier_FO, Barrier_WR, ProQOL_BO, ProQOL_CS, 
         ProQOL_STS, Motivation_NeedSANE, Motivation_PersonalConn, Setting) %>% 
  var_missingness() %>% 
  kable(format = "latex", booktabs = TRUE, digits = 1, 
        col.names = c("Position", "Name", "N_Total", "N", "%", "N", "%")) %>% 
  kable_styling() %>% 
  add_header_above(header = c(" " = 3, "Valid Values" = 2, "Missing Values" = 2))
```

The missing data are all ProQOL scale scores and it appears that a handful of 
people simply did not complete the entire instrument. The rate of missingness 
is small enough that it should be ignorable and listwise deletion will perform
adequately. Therefore, below we create `Eligible_Applicants_CD` to include only
those eligible applicants who have complete (non-missing) data on the variables
that will be used in the stopping ratio model. Along the way, we create 
mean-centered versions of the continuous predictors that can be identified by 
a `C` prefix on the variable name`. 

```{r}
#| label: create-Enrolled-Applicants-CD

Enrolled_Applicants_CD <- Enrolled_Applicants %>% 
  # Retain cases with no missing data on variables to be used in models. 
  filter(if_all(c(ID, Stage_Reached, Barrier_FO, Barrier_WR, ProQOL_BO, 
                  ProQOL_CS, ProQOL_STS, Motivation_NeedSANE, 
                  Motivation_PersonalConn, Setting), ~ !is.na(.x))) %>% 
  # Create mean-centered versions of continuous predictors. 
  mutate(CBarrier_FO = Barrier_FO - mean(Barrier_FO), 
         CBarrier_WR = Barrier_WR - mean(Barrier_WR),
         CProQOL_BO = ProQOL_BO - mean(ProQOL_BO),
         CProQOL_CS = ProQOL_CS - mean(ProQOL_CS),
         CProQOL_STS = ProQOL_STS - mean(ProQOL_STS))
```

\FloatBarrier

## Create Started DT Subset of Enrolled Applicants
When answering the part of RQ2 pertaining to specific training modules, we need 
to narrow our focus to the subset of `Enrolled_Applicants_CD` containing only 
enrolled applicants with `Stage_Reached` $\ge 2$ (those who started the didactic 
training). Thus, below we create that additional dataset and call it 
`StartedDT_Applicants`. 

```{r}
#| label: create-StartedDT-Applicants

StartedDT_Applicants <- Enrolled_Applicants_CD %>% 
  filter(Stage_Reached >= 2)
```

\FloatBarrier

## Create Thresholds Dataset
This study will use a stopping-ratio model, which is also called a forward 
continuation-ratio model or a stage model [@Fullerton-RN8774; @Liu-RN8772]. To 
run the planned model, we first reorganize the data from one row per person to
one row per person per threshold attempted [@Cole-RN8770; @Fullerton-RN8774]. 
That reorganization allows us to use standard logistic regression modeling
software to fit the model and flexibly choose whether predictor effects are
parallel (constrained to equality across thresholds), or non-parallel
(unconstrained and allowed to vary across thresholds) by either omitting or
including interaction terms.

@fig-Stages shows the final set of stages and thresholds between them at which
attrition from the training program could occur. The arrows associated with each
threshold are labeled according to how the outcome variable is coded on the
corresponding person-threshold record, depending on whether the person
stopped participating at the current stage or moved on to the next stage.

```{dot}
//| label: fig-Stages
//| fig-cap: Stages, Thresholds (T1-T3), and Stopping Ratios (SR1-SR3) in the 
//|          SANE Training Program. CSW, clinical skills workshop; DT, didactic 
//|          training.
//| fig-width: 5
//| fig-height: 2.5

digraph StagesModeled {

graph [rankdir="LR"];

node [shape = "box", style= "filled", fillcolor = "Gray90", fontsize = "7"];
A1 [label = "Attrited\nBefore DT\nSR1"]
A2 [label = "Attrited\nDuring DT\nSR2"]
A3 [label = "Attrited\nBefore/During CSW\nSR3"]

S1 [label = "Stage 1\nEnrolled"]
S2 [label = "Stage 2\nStarted DT"]
S3 [label = "Stage 3\nFinished DT"]
S4 [label = "Stage 4\nFinished CSW"]

edge [fontsize = "7", arrowsize = 0.5];

S1 -> A1 [label = "T1\nAttrit = 1"]
S2 -> A2 [label = "T2\nAttrit = 1"]
S3 -> A3 [label = "T3\nAttrit = 1"]

S1 -> S2 [label = "Attrit = 0"]
S2 -> S3 [label = "Attrit = 0"]
S3 -> S4 [label = "Attrit = 0"]

}
```

To create the person-threshold dataset `Thresholds`, we first create a data 
frame for each distinct threshold by filtering the `Enrolled_Applicants_CD` data by 
`Stage_Reached`, add a binary outcome variable called `Attrit` coded 1 
for people who attrited at that threshold and 0 for people who did not, then 
vertically stack the threshold-specific datasets (`T1` to `T3`). Along the way, 
we create factor versions of the categorical variables that can be identified by 
the `.` suffix on the variable name. 

```{r}
#| label: create-T1

T1 <- Enrolled_Applicants_CD %>% 
  select(ID, Stage_Reached, Barrier_FO, Barrier_WR, ProQOL_BO, ProQOL_CS, 
         ProQOL_STS, CBarrier_FO, CBarrier_WR, CProQOL_BO, CProQOL_CS, 
         CProQOL_STS, Motivation_NeedSANE, Motivation_PersonalConn, Setting) %>% 
  filter(Stage_Reached >= 1) %>% 
  mutate(Threshold = 1, 
         Attrit = if_else(Stage_Reached == Threshold, true = 1, false = 0))
```

```{r}
#| label: create-T2

T2 <- Enrolled_Applicants_CD %>% 
  select(ID, Stage_Reached, Barrier_FO, Barrier_WR, ProQOL_BO, ProQOL_CS, 
         ProQOL_STS, CBarrier_FO, CBarrier_WR, CProQOL_BO, CProQOL_CS, 
         CProQOL_STS, Motivation_NeedSANE, Motivation_PersonalConn, Setting) %>% 
  filter(Stage_Reached >= 2) %>% 
  mutate(Threshold = 2, 
         Attrit = if_else(Stage_Reached == Threshold, true = 1, false = 0))
```

```{r}
#| label: create-T3

T3 <- Enrolled_Applicants_CD %>% 
  select(ID, Stage_Reached, Barrier_FO, Barrier_WR, ProQOL_BO, ProQOL_CS, 
         ProQOL_STS, CBarrier_FO, CBarrier_WR, CProQOL_BO, CProQOL_CS, 
         CProQOL_STS, Motivation_NeedSANE, Motivation_PersonalConn, Setting) %>% 
  filter(Stage_Reached >= 3) %>% 
  mutate(Threshold = 3, 
         Attrit = if_else(Stage_Reached == Threshold, true = 1, false = 0))
```

```{r}
#| label: create-value-labels-2

Threshold_Labels <- c("T1 Before DT" = 1,
                      "T2 During DT" = 2,
                      "T3 Before/During CSW" = 3)
```

```{r}
#| label: create-Thresholds

Thresholds <- bind_rows(T1, T2, T3) %>% 
  relocate(ID, Threshold, Attrit) %>% 
  # Convert categorical predictors to factors with a "." variable name suffix
  mutate(Threshold. = factor(Threshold),
         Setting. = as_factor(Setting),
         Motivation_NeedSANE. = as_factor(Motivation_NeedSANE),
         Motivation_PersonalConn. = as_factor(Motivation_PersonalConn)) %>% 
  set_value_labels(Threshold = Threshold_Labels, 
                   Attrit = Binary_Labels)
```

@tbl-Dataset-Size shows the sizes of datasets created above in terms of number 
rows and columns, with additional computed columns showing how many records 
stopped from proceeding to the next stage of case selection and how many 
continued. This allowed me to double-check that the sizes each made sense. For 
the `Applicants` row, the stopped cases are the ineligible applicants, while for 
`Eligible_Applicants` the stopped cases are those that did not enroll. For 
`Enrolled_Applicants`, the stopped cases are those who lacked complete data on 
variables required for modeling. For `Enrolled_Applicants_CD`, stopped cases 
were those who did not start didactic training. `T1` to `T3` each 
have one row per person, with the stopped cases being those that attrited at the 
specified threshold. The `Thresholds` dataset contains one row per person per 
threshold encountered because it combined the rows of `T1` to `T3`, with the 
stopped cases being all the rows that indicated attrition occurred.

```{r}
#| label: tbl-Dataset-Size
#| tbl-cap: Dataset Sizes

tibble(DataFrame = c("Applicants", "Eligible_Applicants", 
                     "Enrolled_Applicants", "Enrolled_Applicants_CD", 
                     "T1", "T2", "T3", "Thresholds"),
       N_Rows = c(nrow(Applicants), nrow(Eligible_Applicants), 
                  nrow(Enrolled_Applicants), nrow(Enrolled_Applicants_CD), 
                  nrow(T1), nrow(T2), nrow(T3), nrow(Thresholds)),
       N_Cols = c(ncol(Applicants), ncol(Eligible_Applicants), 
                  ncol(Enrolled_Applicants), ncol(Enrolled_Applicants_CD), 
                  ncol(T1), ncol(T2), ncol(T3), ncol(Thresholds)),
       Stopped = c(sum(Applicants$Stage_Raw == 1),        
                   sum(Eligible_Applicants$Stage_Raw == 2), 
                   sum(is.na(Enrolled_Applicants$ProQOL_BO)), 
                   sum(Enrolled_Applicants_CD$Stage_Raw == 3),  
                   sum(T1$Attrit), sum(T2$Attrit), sum(T3$Attrit), 
                   sum(Thresholds$Attrit))) %>% 
  mutate(Continued = N_Rows - Stopped) %>% 
  kable(format = "latex", booktabs = TRUE) %>% 
  kable_styling()
```

\FloatBarrier

# Save Data

``` {r}
#| label: create-save-what

# Character vector of object names that will be saved.
save_what <- c("Applicants", "Eligible_Applicants", "Enrolled_Applicants", 
               "Enrolled_Applicants_CD", "StartedDT_Applicants", "Thresholds")
```

``` {r}
#| label: save-data

# Store path to data file. 
DataFile <- here("data/Imported_SANETP_Data.RData")

save(list = save_what, file=DataFile)
```

@tbl-imported-data-file shows meta-data about the data file we just saved.

```{r}
#| label: tbl-imported-data-file
#| tbl-cap: "Meta-Data About the Imported Data File Saved Out"

file_details(DataFile) %>% 
  kable(, format = "latex", booktabs = TRUE, 
        col.names = c("File Name", "Size", "Last Modified")) %>% 
  kable_styling() 
```

::: {.callout-tip}
The imported data file can be loaded into R by copying the following code chunk 
into a script, setting the chunk option `eval: true`, and running the chunk. 
That will overwrite any objects already in memory that have the same names as 
the objects being loaded.

``` {r}
#| label: load-data
#| eval: false

load(file=here("data/Imported_SANETP_Data.RData"))
```
:::

\FloatBarrier

# References
::: {#refs}
:::

\FloatBarrier

# Software Information
This section documents information that is important for reproducibility. Most
users will not need to read it. It is primarily here for use by the statistician 
on the team if we need to troubleshoot reproducibility issues because someone 
else is unable to get the same results from the same code. Start by checking for 
differences in package versions. 

We used [R](https://www.r-project.org/) as our main computing environment and
[Quarto](https://quarto.org/) scripts to enhance reproducibility. We used
[RStudio](www.rstudio.org) as the editor to interface with R and Quarto.

- Software chain:
  **qmd file > RStudio > Quarto > R > knitr > md file > Pandoc > tex file > TinyTeX > PDF file**.
- Source file: \texttt{\detokenize{`r params$SourceFile`}} 
- Output file: \texttt{\detokenize{`r params$LogFile`}} 
- [Quarto `r quarto_version()`](https://quarto.org/) runs `*.qmd` files through 
  [R](https://www.r-project.org/) and [knitr](https://yihui.org/knitr/) to 
  produce `*.md` markdown files.
- [Pandoc `r rmarkdown::pandoc_version()`](https://pandoc.org) converts markdown 
  files (`*.md`) to other formats, including LaTeX (`*.tex`) and HTML (`*.html`) 
  among others.
- [TinyTeX](https://yihui.org/tinytex/) compiles LaTeX files (`*.tex`) into PDF 
  files. It should be viable to use [MiKTeX](https://miktex.org) or another 
  LaTeX distribution instead. 

\FloatBarrier

## Versions
This document was generated using the following computational environment and 
dependencies:

```{r}
#| label: show-version
#| echo: true

# Check and report whether we used TinyTex or other LaTeX software. 
which_latex()

# Get R and R package version numbers in use.
devtools::session_info()
```

\FloatBarrier

## Git Details
The current Git commit details and status are:

``` {r}
#| label: git-details
#| echo: true

git_report()
```

This is useful because it tells us exactly which commit in the Git history 
we would need to be using to make sure we are running the exact same code. 
Sometimes another person is not using the most current code, or has changed the 
code in some way since it was last committed.  

::: {.callout-tip}
* Untracked files are files located in the repository that Git has not been told 
  to entirely ignore, but have also not been committed into the version history. 
* Unstaged changes to files indicate that some of the contents have been 
  modified since the last time the file was committed to Git. In production 
  runs, we want the Git output to not show any unstaged changes to key files!
  
::: 
