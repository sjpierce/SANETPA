---
title: Descriptive Analyses for SANE Training Program Data
subtitle: | 
          | CSTAT Case: C1788
          | Clients: Rebecca Campbell, Autumn Ashley, & Katherine Dontje
author: 
  - name: Steven J. Pierce
    orcid: 0000-0002-0679-3019
    email: pierces1@msu.edu
    affil-id: 1 
affiliations: 
  - id: 1 
    name: Michigan State University
    department: Center for Statistical Training and Consulting
    url: "[https://cstat.msu.edu](https://cstat.msu.edu)"
bibliography: references.bib          # File holds BibTeX data for references
csl: apa.csl                          # File controls citation & reference list format
params:                               # Default values for parameters
  SourceDir: "scripts/"               # Relative path to folder holding this file
  SourceFile: "Descriptive_Analyses.qmd"    # Name of this script file
  LogFile: "Descriptive_Analyses_Draft.pdf" # Default name of rendered output file
format: 
  pdf:                                # Settings for PDF output
    output-file: "Descriptive_Analyses_Draft.pdf" # Default output file name 
    output-ext: "pdf"                 # Default file name extension
    documentclass: scrartcl           # LaTeX document type
    papersize: letter
    geometry:                         # Control page margins
      - top=1in
      - bottom=1in
      - left=1in
      - right=1in
    number-sections: true           # Auto-number each section
    toc: true                       # Include table of contents (TOC)
    toc-depth: 3                    # Number of layers in TOC
    colorlinks: true
    template-partials: 
      - title.tex   # Controls author affiliation formatting
    include-in-header:
      - file: compact-title.tex    # Controls spacing around title. 
      - text: |
          \usepackage{fancyhdr}
          \usepackage[noblocks]{authblk}
          \renewcommand*{\Authsep}{, }
          \renewcommand*{\Authand}{, }
          \renewcommand*{\Authands}{, }
          \renewcommand\Affilfont{\small}
          \usepackage[yyyymmdd,hhmmss]{datetime}    %% for currenttime command
          \usepackage{lastpage}                     %% For pageref command
          \usepackage{fontspec}
          \defaultfontfeatures{Ligatures=TeX}
          \usepackage[font={small}, margin=1cm, skip=2pt]{caption}
          \usepackage{url}
          \usepackage{floatrow}                     %% For controlling float placement
          \floatsetup[table]{capposition=top}       %% Puts table caption at top.
          \floatsetup[longtable]{margins=centering} %% Centers longtable tables
          \floatplacement{figure}{!ht}              %% Control placement of figures
          \floatplacement{table}{!ht}               %% Control placement of tables
          \usepackage[labelfont=bf, textfont=bf]{caption}  %% For bolded table/figure captions
          \usepackage{placeins}                     %% For FloatBarrier command
          \usepackage{booktabs}                     %% Used by kableExtra
          \usepackage{longtable}                    %% Used by kableExtra
          \usepackage{array}                        %% Used by kableExtra
          \usepackage{multirow}                     %% Used by kableExtra
          \usepackage{wrapfig}                      %% Used by kableExtra
          \usepackage{colortbl}                     %% Used by kableExtra
          \usepackage{pdflscape}                    %% Used by kableExtra
          \usepackage{tabu}                         %% Used by kableExtra
          \usepackage[normalem]{ulem}               %% Used by kableExtra
          \usepackage{makecell}                     %% Used by kableExtra
          \usepackage{xcolor}                       %% Used by kableExtra
          \usepackage{dcolumn}                      %% Used by kableExtra
          \usepackage{threeparttable}               %% Used by kableExtra
          \usepackage{threeparttablex}              %% Used by kableExtra
          \usepackage{amsmath}                      %% for equation support. 
          \usepackage{titling}      
          \usepackage{verbatim}                     %% For comment command
          \pretitle{\begin{center}\LARGE\bfseries\sffamily}
          \posttitle{\end{center}}
          \pagestyle{fancy}
          \lhead{SANETPA Descriptive Analyses}
          \chead{\includegraphics[height=0.85cm]{../graphics/Combomark-Horiz_Pantone-567.eps}}
          \rhead{\today\ \currenttime}
          \cfoot{ }
          \fancyfoot[R]{\thepage\ of \pageref*{LastPage}}
          \renewcommand{\headrulewidth}{0.4pt}
          \renewcommand{\footrulewidth}{0.4pt}
          \fancypagestyle{plain}{\pagestyle{fancy}}
          \newcommand*\tocentryformat[1]{{\sffamily#1}}  %% Fix TOC font style
          \RedeclareSectionCommands                      %% Fix TOC font style
            [
              tocentryformat=\tocentryformat,
              tocpagenumberformat=\tocentryformat
            ]
            {section,subsection,subsubsection,paragraph,subparagraph}
execute:                              # Default Quarto chunk execution options
  eval: true
  echo: fenced                        # Show the code in the output file
  output: true
  warning: true
  error: true
  include: true
knitr:                                # Default R knitr package chunk options
  opts_chunk: 
    message: true
    cfsize: "footnotesize"  
---

\lfoot{\texttt{\small \detokenize{`r params$LogFile`}}}

\FloatBarrier

# Purpose
This file is part of a research compendium [@Pierce-RN8756] associated with a 
study about a sexual assault nurse examiner training program [@Dontje-RN8757]. 
It contains results from descriptive analyses. 

\FloatBarrier

# Setup
This section documents some setup tasks that are useful to the statistician on 
the team. Most readers of this document will probably want skip directly to 
@sec-Read-Data.

\FloatBarrier

## Define Global Options
Global R chunk options are defined in the YAML header but local chunk options
will over-ride global options. We can temporarily disable an individual chunk by
inserting `#| eval: false` on a line at the top of the chunk. The method for
creating a `cfsize` option that controls font size in code chunks and their text
output is based on an answer to a question posted on
[stackoverflow.com](https://stackoverflow.com/a/46526740).

``` {r}
#| label: global-options

# Create a custom chunk hook/option for controlling font size in chunk & output.
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$cfsize != "normalsize", 
         paste0("\n \\", options$cfsize,"\n\n", x, "\n\n \\normalsize"), 
         x)
  })
```

\FloatBarrier

## Load Packages
R packages usually add new functions to the base R software, allowing you to do 
more things. Here, we load the specific R packages required for this script to 
work.

```{r}
#| label: load-packages
library(devtools)       # for session_info()
library(here)           # for here(), i_am(), makes code more portable.
library(rmarkdown)      # for pandoc_version()
library(knitr)          # for kable()
library(dplyr)          # for %>%, filter(), group_by(), mutate(), rename(), etc.
library(tidyverse)      # for map_dfr(), map_chr(), rowid_to_column(), etc.
library(haven)          # for as_factor()
library(labelled)       # for var_label()
options(kableExtra.latex.load_packages = FALSE)
library(kableExtra)     # for kable_styling(), add_header_above(), 
                        # column_spec(), row_spec() etc. 
library(piercer)        # for git_report(), which_latex()
library(PropCIs)        # for scoreci()
library(psych)          # for alpha()
library(quarto)         # for quarto_version()
library(SANETPA)        # for version info 
```

\FloatBarrier

## Declare Path
This next chunk declares the path to this script relative to the project-level 
root directory. If the file is not in the right location under the project root
you'll get a warning message. This helps ensure relative paths are all working 
as expected. The chunk below uses the `SourceDir` and `SourceFile` parameters 
set in the YAML header. 

``` {r}
#| label: declare-path

# Declare path to this script relative to the project root directory.
here::i_am(path = paste0(params$SourceDir, params$SourceFile))
```

\FloatBarrier

# Read Data {#sec-Read-Data}
We start be reading in the datafile, which contains the following datasets:

* `Applicants`. This is a person-level data file containing one row for every 
  applicant, regardless of eligibility status., 
* `Eligible_Applicants`. This is a person-level file containing one row for 
  every person who both applied and was eligible for the program. It omits 
   those who were ineligible. 
* `Thresholds`. This is a person-threshold level file with one row per threshold 
  encountered by each eligible applicant. 

``` {r}
#| label: load-data
#| eval: true

# Store path to data file. 
DataFile <- here("data/Imported_SANETP_Data.RData")

load(file = DataFile)
```

@tbl-imported-data-file shows meta-data about the data file we just loaded and
@tbl-datasets shows the sizes of the datasets it contains. 

```{r}
#| label: tbl-imported-data-file
#| tbl-cap: "Meta-Data About the Data File Loaded"

file.info(DataFile, extra_cols = FALSE) %>% 
  rownames_to_column() %>% 
  mutate(rowname = basename(rowname)) %>% 
  select(-isdir, -mode) %>% 
  kable(, format = "latex", booktabs = TRUE, 
        col.names = c("File Name", "Size (Bytes)", "Modified", 
                      "Last Status Change", "Last Accessed")) %>% 
  kable_styling() %>% 
  column_spec(column = 3:5, width = "2cm")
```


```{r}
#| label: tbl-datasets
#| tbl-cap: "Sizes of the Datasets"

data.frame(Dataset = c("Applicants", "Eligible_Applicants", "Thresholds"),
           N_Rows = c(nrow(Applicants), nrow(Eligible_Applicants), 
                      nrow(Thresholds)),
           N_Cols = c(ncol(Applicants), ncol(Eligible_Applicants), 
                      ncol(Thresholds))) %>% 
  kable(, format = "latex", booktabs = TRUE, 
        col.names = c("Dataset", "N Rows", "N Columns")) %>% 
  kable_styling() 
```

\FloatBarrier

# Summaries of Applicants Data
There are `r nrow(Applicants)` rows in the `Applicants` dataset. The first thing
we need to examine is the distribution for a few key variables.
@tbl-Stage-Raw-Eligible shows the crosstabulation of the raw stage variable by
the eligibility status.

```{r}
#| label: tbl-Stage-Raw-Eligible
#| tbl-cap: Stage_Raw by Eligible Contingency Table

# Footnote text. 
FN <- "CSW, clinical skills workshop; DT, didactic training."

xtabs(~as_factor(Stage_Raw) + Eligible, addNA = TRUE, 
      data = Applicants) %>% 
  addmargins() %>% 
  kable(format = "latex", booktabs = TRUE, 
        col.names = c("Stage_Raw", "No", "Yes", "Sum")) %>% 
  kable_styling() %>% 
  add_header_above(header = c(" ", "Eligible" = 2, " ")) %>% 
  column_spec(column = 4, italic = TRUE) %>% 
  row_spec(row = 8, italic = TRUE) %>% 
  footnote(kable_input = ., general = FN, footnote_as_chunk = TRUE, 
           threeparttable = TRUE)
```

:::{.callout-tip}
* People who exited at the Applied stage should all be coded as ineligible. 
* People in the remaining stages should all be coded as eligible. 
* Cell count for Applied/Yes should be 0. Positive values there may be a result 
  of inaccurate data entry (we previously detected and fixed 4 cases with this 
  check). 

:::

The next thing to examine is the eligibility rate (see @tbl-Eligible-Rate). 

```{r}
#| label: tbl-Eligible-Rate
#| tbl-cap: Eligibility Rate Among All Applicants

FN <- paste("We used a Wilson score interval for the 95% confidence interval.")

ER <- mean(Applicants$Eligible)
ERCI <- scoreci(x = sum(Applicants$Eligible), n = nrow(Applicants), 
                conf.level = 0.95)

data.frame(No = sum(1 - Applicants$Eligible),
           Yes = sum(Applicants$Eligible),
           Total = nrow(Applicants),
           Rate = mean(Applicants$Eligible),
           LL = ERCI$conf.int[1],
           UL = ERCI$conf.int[2]) %>% 
  kable(format = "latex", booktabs = TRUE, digits = c(0, 0, 0, 2, 2, 2), 
        format.args = list(nsmall = c(0, 0, 0, 2, 2, 2))) %>% 
  kable_styling() %>% 
  add_header_above(header = c("Eligible (N)" = 3, " ", "95% CI" = 2)) %>% 
  footnote(kable_input = ., general = FN, footnote_as_chunk = TRUE, 
           threeparttable = TRUE)
```

@tbl-Time-Demands-Eligible shows the joint distribution of the `Barrier_TD` 
scale score and the `Eligible` indicator. This allows us to demonstrate that 
all eligible applicants have observed scale scores in the expected range and all 
ineligible applicants have missing values. 

```{r}
#| label: tbl-Time-Demands-Eligible
#| tbl-cap: Barrier_TD by Eligible Contingency Table

# Footnote text. 
FN <- paste("The range of possible values for Barrier_TD is [3, 15].",
            "NA, not available (missing data).")

xtabs(~Barrier_TD + Eligible, addNA = TRUE, data = Applicants) %>% 
  addmargins() %>% 
  kable(format = "latex", booktabs = TRUE, 
        col.names = c("Barrier_TD", "No", "Yes", "Sum")) %>% 
  kable_styling() %>% 
  add_header_above(header = c(" ", "Eligible" = 2, " ")) %>% 
  column_spec(column = 4, italic = TRUE) %>% 
  row_spec(row = 8, italic = TRUE) %>% 
  footnote(kable_input = ., general = FN, footnote_as_chunk = TRUE, 
           threeparttable = TRUE)
```

\FloatBarrier

# Summaries of Eligible Applicants Data
There are `r nrow(Eligible_Applicants)` rows in the `Eligible_Applicants` 
dataset. 

\FloatBarrier

## Outcome Distribution
`Stage_Reached` is the stage variable we will use for modeling purposes. 
@tbl-Stage-Reached-all shows the frequency distribution for the stage reached 
among all eligible applicants (before listwise deletion), while @
tbl-Stage-Reached-cd shows it after removing those with incomplete data on the 
variables to be included in the model (after listwise deletion). 

```{r}
#| label: tbl-Stage-Reached-all
#| tbl-cap: Stage_Reached Frequency Distribution Among Eligible Applicants 
#|          (Before Listwise Deletion)

# Footnote text. 
FN <- paste("Denominator for percents is the frequency sum.", 
      "CSW, clinical skills workshop; DT, didactic training.")

xtabs(~as_factor(Stage_Reached), addNA = TRUE, 
      data = Eligible_Applicants) %>% 
  addmargins() %>% 
  as.data.frame() %>% 
  rename(Stage_Reached = as_factor.Stage_Reached.) %>% 
  mutate(Percent = 100*Freq/nrow(Eligible_Applicants),
         Cumulative = if_else(Stage_Reached == "Sum", 
                              true = 100, 
                              false = cumsum(Percent))) %>% 
  kable(format = "latex", booktabs = TRUE, digits = 1,
        col.names = c("Stage_Reached", "Freq", "%", "Cumulative %")) %>% 
  kable_styling() %>% 
  row_spec(row = 6, italic = TRUE) %>% 
  footnote(kable_input = ., general = FN, footnote_as_chunk = TRUE, 
           threeparttable = TRUE)
```

```{r}
#| label: tbl-Stage-Reached-cd
#| tbl-cap: Stage_Reached Frequency Distribution Among Eligible Applicants 
#|          (After Listwise Deletion)

# Footnote text. 
FN <- paste("Denominator for percents is the frequency sum.", 
      "CSW, clinical skills workshop; DT, didactic training.")

xtabs(~as_factor(Stage_Reached), addNA = TRUE, 
      data = Eligible_Applicants_CD) %>% 
  addmargins() %>% 
  as.data.frame() %>% 
  rename(Stage_Reached = as_factor.Stage_Reached.) %>% 
  mutate(Percent = 100*Freq/nrow(Eligible_Applicants_CD),
         Cumulative = if_else(Stage_Reached == "Sum", 
                              true = 100, 
                              false = cumsum(Percent))) %>% 
  kable(format = "latex", booktabs = TRUE, digits = 1,
        col.names = c("Stage_Reached", "Freq", "%", "Cumulative %")) %>% 
  kable_styling() %>% 
  row_spec(row = 6, italic = TRUE) %>% 
  footnote(kable_input = ., general = FN, footnote_as_chunk = TRUE, 
           threeparttable = TRUE)
```

\FloatBarrier

## Reliability: Barrier Time Demands
We need a measure of the extent to which competing personal and professional
demands on participants' time are a barrier to completing the training program.
The program staff believe that this construct (`Barrier_TD`) is likely to be a
major driver of attrition from the program. Similarly, external stakeholders
familiar with forensic nursing emphasized competing demands on time/bandwidth as
a likely factor in attrition. Therefore, it is a high priority to have some 
measure of `Barrier_TD` in our models. The challenge is operationalizing it. 

There are three items from the training application form that are good 
candidates for inclusion in the scale. 

* `Train_Goal_Fac_Bar_5R`: I have time in my schedule to focus on this course.  
* `Train_Goal_Fac_Bar_8`: I have a lot of work responsibilities.
* `Train_Goal_Fac_Bar_10`: I have a lot of family obligations right now. 

These ordinal Likert-response items are all coded such that low values indicate 
few barrier time demands and high values mean more barrier time demands. 

::: {.callout-tip}
We use the data for all eligible applicants (before listwise deletion) in this 
section. It does not make any meaningful difference if we run the same analyses 
on the subset of eligible applicants with complete data on the variables to be 
used in modeling. 
::: 

### Item Distributions
The frequency distributions for each of those items are shown in 
@tbl-Train-Goal-Fac-Bar-5R, @tbl-Train-Goal-Fac-Bar-8, and 
@tbl-Train-Goal-Fac-Bar-10. 

```{r}
#| label: tbl-Train-Goal-Fac-Bar-5R
#| tbl-cap: Train_Goal_Fac_Bar_5R Frequency Distribution Among Eligible Applicants

# Footnote text. 
FN <- paste("Item text: 'I have time in my schedule to focus on this course.'", 
            "Denominator for percents is total number of eligible applicants.")

Eligible_Applicants %>% 
xtabs(~as_factor(Train_Goal_Fac_Bar_5R), addNA = TRUE, data = .) %>% 
  addmargins() %>% 
  as.data.frame() %>% 
  rename(Train_Goal_Fac_Bar_5R = as_factor.Train_Goal_Fac_Bar_5R.) %>% 
  mutate(Percent = 100*Freq/nrow(Eligible_Applicants),
         Cumulative = if_else(Train_Goal_Fac_Bar_5R == "Sum", 
                              true = 100, 
                              false = cumsum(Percent))) %>% 
  kable(format = "latex", booktabs = TRUE, digits = 1,
        col.names = c("Train_Goal_Fac_Bar_5R", "Freq", "%", "Cumulative %")) %>% 
  kable_styling() %>% 
  row_spec(row = 6, italic = TRUE) %>% 
  footnote(kable_input = ., general = FN, footnote_as_chunk = TRUE, 
           threeparttable = TRUE)
```

```{r}
#| label: tbl-Train-Goal-Fac-Bar-8
#| tbl-cap: Train_Goal_Fac_Bar_8 Frequency Distribution Among Eligible Applicants

# Footnote text. 
FN <- paste("Item text: 'I have a lot of work responsibilities.'", 
            "Denominator for percents is total number of eligible applicants.")

Eligible_Applicants %>% 
xtabs(~as_factor(Train_Goal_Fac_Bar_8), addNA = TRUE, data = .) %>% 
  addmargins() %>% 
  as.data.frame() %>% 
  rename(Train_Goal_Fac_Bar_8 = as_factor.Train_Goal_Fac_Bar_8.) %>% 
  mutate(Percent = 100*Freq/nrow(Eligible_Applicants),
         Cumulative = if_else(Train_Goal_Fac_Bar_8 == "Sum", 
                              true = 100, 
                              false = cumsum(Percent))) %>% 
  kable(format = "latex", booktabs = TRUE, digits = 1,
        col.names = c("Train_Goal_Fac_Bar_8", "Freq", "%", "Cumulative %")) %>% 
  kable_styling() %>% 
  row_spec(row = 6, italic = TRUE) %>% 
  footnote(kable_input = ., general = FN, footnote_as_chunk = TRUE, 
           threeparttable = TRUE)
```

```{r}
#| label: tbl-Train-Goal-Fac-Bar-10
#| tbl-cap: Train_Goal_Fac_Bar_10 Frequency Distribution Among Eligible Applicants

# Footnote text. 
FN <- paste("Item text: 'I have a lot of family obligations right now.'", 
            "Denominator for percents is total number of eligible applicants.")

Eligible_Applicants %>% 
xtabs(~as_factor(Train_Goal_Fac_Bar_10), addNA = TRUE, data = .) %>% 
  addmargins() %>% 
  as.data.frame() %>% 
  rename(Train_Goal_Fac_Bar_10 = as_factor.Train_Goal_Fac_Bar_10.) %>% 
  mutate(Percent = 100*Freq/nrow(Eligible_Applicants),
         Cumulative = if_else(Train_Goal_Fac_Bar_10 == "Sum", 
                              true = 100, 
                              false = cumsum(Percent))) %>% 
  kable(format = "latex", booktabs = TRUE, digits = 1,
        col.names = c("Train_Goal_Fac_Bar_10", "Freq", "%", "Cumulative %")) %>% 
  kable_styling() %>% 
  row_spec(row = 6, italic = TRUE) %>% 
  footnote(kable_input = ., general = FN, footnote_as_chunk = TRUE, 
           threeparttable = TRUE)
```

### 3-Item Scale Reliability
Our first attempt at building this scale used all three items. 

```{r}
#| label: reliability-Barrier-TD-3item

Eligible_Applicants %>% 
  select(Train_Goal_Fac_Bar_5R, Train_Goal_Fac_Bar_8, Train_Goal_Fac_Bar_10) %>% 
  as.data.frame() %>% 
  alpha(x = ., cumulative = TRUE, discrete = TRUE)
```

The results above show poor to questionable reliability and that omitting 
`Train_Goal_Fac_Bar_5R` may increase the reliability by a very small amount. 
@tbl-Train-Goal-Fac-Bar-5R provides some clues about why that may be happening. 
The item has a very skewed distribution: almost none of the eligible applicants
disagreed with the idea that they had enough time in their schedule to focus on
this course. One concern is that applicants may have perceived this item to be a 
screening question where *expressing disagreement might prevent them from* 
*getting into the program*. It may have elicited less honest and accurate 
answers than the other two questions, which have more variability, less skew,
and wording less likely to be seen as a pure screening tool.

:::{.callout-note}
We decided to omit the problematic item `Train_Goal_Fac_Bar_5R` and just use the 
other two items. 
::: 

### 2-Item Scale Reliability
We know from basic psychometric theory that reliability tends to increase with
the number of items used to measure the construct. Scales with two items are
unlikely to have high reliability. The point estimate of Cronbach's alpha for
this reduced version of the scale is slightly better than the one for the
three-item version but still in the questionable range. The upper bound on the
95% CI is now just below the 0.70 threshold often used as a value considered
acceptable for research purposes.

```{r}
#| label: reliability-Barrier-TD-2item

Eligible_Applicants %>% 
  select(Train_Goal_Fac_Bar_8, Train_Goal_Fac_Bar_10) %>% 
  as.data.frame() %>% 
  alpha(x = ., cumulative = TRUE, discrete = TRUE)
```

:::{.callout-note}
We will use the two-item scale for `Barrier_TD` because that has higher
reliability than using either of those remaining items alone and helps keep the
number of predictors in the models manageable. It allows us to address a crucial
hypothesis better than other available options. We are relying here on the
strong face validity of the items being combined. We will recommend pursuing
better measurement of this construct in future studies.

One consequence of low reliability in a predictor should be a weaker regression 
coefficient relating it to an outcome. I suspect that we are more likely to 
underestimate the effect of barrier time demands on attrition than to 
overestimate it. 
::: 

## Predictor Distributions

\FloatBarrier

### Continuous Predictors
We plan to use the ProQual compassion (`ProQOL_CS`), burnout (`ProQOL_BO`), and 
secondary traumatic stress (`ProQOL_STS`) scale scores [@Stamm-RN8775] as 
predictors, along with a new, custom scale score measuring barriers to 
participation due to personal and professional demands on applicants' time 
(`Barrier_TD`). 

@tbl-continuous-vars-all shows descriptive statistics for each of these 
continuous predictors among all eligible applicants before application of 
listwise deletion, while @tbl-continuous-vars-cd shows descriptive statistics 
for each of these continuous predictors among eligible applicants with complete 
data on the variables to be used in modeling, along with corresponding 
mean-centered versions of each one. Histograms of the uncentered versions of the 
variables after listwise deletion are shown in @fig-ProQOL-BO, @fig-ProQOL-CS, 
@fig-ProQOL-STS, and @fig-Barrier-TD.

```{r}
#| label: tbl-continuous-vars-all
#| tbl-cap: Descriptive Statistics for Continuous Predictor Variables Among 
#|          Eligible Applicants (Before Listwise Deletion)

# Footnote text.
FN <- paste("N_m, number of missing values; N_o, number of observed values.")

VNames <- c("ProQOL_BO", "ProQOL_CS", "ProQOL_STS", "Barrier_TD",
            "CProQOL_BO", "CProQOL_CS", "CProQOL_STS", "CBarrier_TD")
VLabels <- rep(c("Burnout", "Compassion Satisfaction", 
                 "Secondary Traumatic Stress", "Time Demands"), times = 2)
CNames <- c("Variable", "Construct", "N", "N_m", "N_o", "Mean", "SD", 
            "Min", "Max")

Eligible_Applicants %>% 
  select(ID, ProQOL_BO, ProQOL_CS, ProQOL_STS, Barrier_TD) %>% 
  pivot_longer(cols = c(ProQOL_BO, ProQOL_CS, ProQOL_STS, Barrier_TD),
               names_to = "VarName", 
               values_to = "Value") %>% 
  mutate(VarName = factor(VarName, levels = VNames, labels = VNames),
         Construct = factor(VarName, levels = VNames, labels = VLabels)) %>% 
  relocate(ID, VarName, Construct) %>% 
  group_by(VarName, Construct) %>% 
  summarise(N = n(),
            N_missing = sum(is.na(Value)), 
            N_observed = sum(!is.na(Value)), 
            Mean = mean(Value, na.rm = TRUE),
            SD = sd(Value, na.rm = TRUE),
            Min = min(Value, na.rm = TRUE),
            Max = max(Value, na.rm = TRUE)) %>% 
  kable(., format = "latex", booktabs = TRUE, digits = 1, 
        col.names = CNames, row.names = FALSE) %>% 
  kable_styling() %>% 
  footnote(kable_input = ., general = FN, footnote_as_chunk = TRUE)
```

```{r}
#| label: tbl-continuous-vars-cd
#| tbl-cap: Descriptive Statistics for Continuous Predictor Variables Among 
#|          Eligible Applicants (After Listwise Deletion)

# Footnote text.
VNames <- c("ProQOL_BO", "ProQOL_CS", "ProQOL_STS", "Barrier_TD",
            "CProQOL_BO", "CProQOL_CS", "CProQOL_STS", "CBarrier_TD")
VLabels <- rep(c("Burnout", "Compassion Satisfaction", 
                 "Secondary Traumatic Stress", "Time Demands"), times = 2)
CNames <- c("Variable", "Construct", "N", "Mean", "SD", "Min", "Max")

Eligible_Applicants_CD %>% 
  select(ID, ProQOL_BO, ProQOL_CS, ProQOL_STS, Barrier_TD, CProQOL_BO,
         CProQOL_CS, CProQOL_STS, CBarrier_TD) %>% 
  pivot_longer(cols = c(ProQOL_BO, ProQOL_CS, ProQOL_STS, Barrier_TD, 
                        CProQOL_BO, CProQOL_CS, CProQOL_STS, CBarrier_TD),
               names_to = "VarName", 
               values_to = "Value") %>% 
  mutate(VarName = factor(VarName, levels = VNames, labels = VNames),
         Construct = factor(VarName, levels = VNames, labels = VLabels)) %>% 
  relocate(ID, VarName, Construct) %>% 
  group_by(VarName, Construct) %>% 
  summarise(N = n(),
            Mean = mean(Value, na.rm = TRUE),
            SD = sd(Value, na.rm = TRUE),
            Min = min(Value, na.rm = TRUE),
            Max = max(Value, na.rm = TRUE)) %>% 
  kable(., format = "latex", booktabs = TRUE, digits = 1, 
        col.names = CNames, row.names = FALSE) %>% 
  kable_styling() %>% 
  group_rows(., group_label = "Uncentered Scale Scores", start_row = 1, 
             end_row = 4, italic = TRUE) %>% 
  group_rows(., group_label = "Mean-Centered Scale Scores", start_row = 5, 
             end_row = 8, italic = TRUE) 
```

```{r}
#| label: fig-ProQOL-BO
#| fig-cap: Histogram of ProQOL Burnout Among Eligible Applicants (After 
#|          Listwise Deletion)
#| fig-width: 5
#| fig-height: 2.5
#| warning: false

ggplot(data = Eligible_Applicants_CD, aes(x = ProQOL_BO)) +
  geom_histogram(aes(y = after_stat(density)), binwidth = 1, color = "black", 
                 fill = "grey") +
  geom_density(alpha = .6, fill = "#FF6666") +
  geom_vline(aes(xintercept = mean(ProQOL_BO, na.rm = TRUE)), color = "blue", 
             linetype = "solid", linewidth = 1) +
  geom_vline(xintercept = c(22.5, 41.5), color = "black", linetype = "dashed", 
             linewidth = 1) +
  coord_cartesian(xlim = c(10, 50), ylim = c(0, 0.16)) + 
  scale_x_continuous(breaks = seq(from = 10, to = 50, by = 5)) +
  scale_y_continuous(breaks = seq(from = 0, to = 0.16, by = 0.02)) +
  labs(subtitle = "Low / Moderate / High Cutoffs (Dashed Lines)", 
       x = "ProQOL Burnout", 
       y = "Density")
```

```{r}
#| label: fig-ProQOL-CS
#| fig-cap: Histogram of ProQOL Compassion Satisfaction Among Eligible 
#|          Applicants (After Listwise Deletion)
#| fig-width: 5
#| fig-height: 2.5
#| warning: false

ggplot(data = Eligible_Applicants_CD, aes(x = ProQOL_CS)) +
  geom_histogram(aes(y = after_stat(density)), binwidth = 1, color = "black", 
                 fill = "grey") +
  geom_density(alpha = .6, fill = "#FF6666") +
  geom_vline(aes(xintercept = mean(ProQOL_CS, na.rm = TRUE)), color = "blue", 
             linetype = "solid", linewidth = 1) +
  geom_vline(xintercept = c(22.5, 41.5), color = "black", linetype = "dashed", 
             linewidth = 1) +
  coord_cartesian(xlim = c(10, 50), ylim = c(0, 0.16)) + 
  scale_x_continuous(breaks = seq(from = 10, to = 50, by = 5)) +
  scale_y_continuous(breaks = seq(from = 0, to = 0.16, by = 0.02)) +
  labs(subtitle = "Low / Moderate / High Cutoffs (Dashed Lines)", 
       x = "ProQOL Compassion Satisfaction", 
       y = "Density")
```

```{r}
#| label: fig-ProQOL-STS
#| fig-cap: Histogram of ProQOL Secondary Traumatic Stress Among Eligible 
#|          Applicants (After Listwise Deletion)
#| fig-width: 5
#| fig-height: 2.5
#| warning: false

ggplot(data = Eligible_Applicants_CD, aes(x = ProQOL_STS)) +
  geom_histogram(aes(y = after_stat(density)), binwidth = 1, color = "black", 
                 fill = "grey") +
  geom_density(alpha = .6, fill = "#FF6666") +
  geom_vline(aes(xintercept = mean(ProQOL_STS, na.rm = TRUE)), color = "blue", 
             linetype = "solid", linewidth = 1) +
  geom_vline(xintercept = c(22.5, 41.5), color = "black", linetype = "dashed", 
             linewidth = 1) +
  coord_cartesian(xlim = c(10, 50), ylim = c(0, 0.16)) + 
  scale_x_continuous(breaks = seq(from = 10, to = 50, by = 5)) +
  scale_y_continuous(breaks = seq(from = 0, to = 0.16, by = 0.02)) +
  labs(subtitle = "Low / Moderate / High Cutoffs (Dashed Lines)", 
       x = "ProQOL Secondary Traumatic Stress", 
       y = "Density")
```

```{r}
#| label: fig-Barrier-TD
#| fig-cap: Histogram of Barrier Time Demands Among Eligible Applicants (After 
#|          Listwise Deletion) 
#| fig-width: 5
#| fig-height: 2.5

ggplot(data = Eligible_Applicants_CD, aes(x = Barrier_TD)) +
  geom_histogram(aes(y = after_stat(density)), binwidth = 1, color = "black", 
                 fill = "grey") +
  geom_density(alpha = .6, fill = "#FF6666") +
  geom_vline(aes(xintercept = mean(Barrier_TD, na.rm = TRUE)), color = "blue", 
             linetype = "solid", linewidth = 1) +
  coord_cartesian(xlim = c(1, 11), ylim = c(0, 0.30)) + 
  scale_x_continuous(breaks = seq(from = 2, to = 10, by = 1)) +
  scale_y_continuous(breaks = seq(from = 0, to = 0.30, by = 0.05)) +
  labs(subtitle = "", 
       x = "Barrier Time Demands", 
       y = "Density")
```

```{r}
#| label: tbl-continuous-corr
#| tbl-cap: Pearson Correlation Matrix for Continuous Predictor Variables (After 
#|          Listwise Deletion)

N_used <- nrow(Eligible_Applicants_CD)
N_omit <- nrow(Eligible_Applicants) - N_used

FN <- paste0("N = ", N_used, " after listwise deletion of missing data (",
             N_omit, " observations).")

Eligible_Applicants_CD %>% 
  select(ProQOL_BO, ProQOL_CS, ProQOL_STS, Barrier_TD) %>% 
  cor(x = ., use = "complete.obs", method = "pearson") %>% 
  kable(format = "latex", booktabs = TRUE, digits = 2) %>% 
  kable_styling() %>% 
  footnote(kable_input = ., general = FN, footnote_as_chunk = TRUE)
```

\FloatBarrier

### Categorical Predictors
@tbl-Motivation-NeedSANE and @tbl-Motivation-PersonalConn respectively show the 
frequency distributions for `Motivation_NeedSANE` and `Motivation_PersonalConn`, 
which are both binary variables. 

```{r}
#| label: tbl-Motivation-NeedSANE
#| tbl-cap: Motivation_NeedSANE Frequency Distribution Among Eligible Applicants

# Footnote text. 
FN <- paste("Denominator for percents is total number of eligible applicants.")

Eligible_Applicants %>% 
xtabs(~as_factor(Motivation_NeedSANE), addNA = TRUE, data = .) %>% 
  addmargins() %>% 
  as.data.frame() %>% 
  rename(Motivation_NeedSANE = as_factor.Motivation_NeedSANE.) %>% 
  mutate(Percent = 100*Freq/nrow(Eligible_Applicants),
         Cumulative = if_else(Motivation_NeedSANE == "Sum", 
                              true = 100, 
                              false = cumsum(Percent))) %>% 
  kable(format = "latex", booktabs = TRUE, digits = 1,
        col.names = c("Motivation_NeedSANE", "Freq", "%", "Cumulative %")) %>% 
  kable_styling() %>% 
  row_spec(row = 3, italic = TRUE) %>% 
  footnote(kable_input = ., general = FN, footnote_as_chunk = TRUE, 
           threeparttable = TRUE)
```

```{r}
#| label: tbl-Motivation-PersonalConn
#| tbl-cap: Motivation_PersonalConn Frequency Distribution Among Eligible Applicants

# Footnote text. 
FN <- paste("Denominator for percents is total number of eligible applicants.")

Eligible_Applicants %>% 
xtabs(~as_factor(Motivation_PersonalConn), addNA = TRUE, data = .) %>% 
  addmargins() %>% 
  as.data.frame() %>% 
  rename(Motivation_PersonalConn = as_factor.Motivation_PersonalConn.) %>% 
  mutate(Percent = 100*Freq/nrow(Eligible_Applicants),
         Cumulative = if_else(Motivation_PersonalConn == "Sum", 
                              true = 100, 
                              false = cumsum(Percent))) %>% 
  kable(format = "latex", booktabs = TRUE, digits = 1,
        col.names = c("Motivation_PersonalConn", "Freq", "%", "Cumulative %")) %>% 
  kable_styling() %>% 
  row_spec(row = 3, italic = TRUE) %>% 
  footnote(kable_input = ., general = FN, footnote_as_chunk = TRUE, 
           threeparttable = TRUE)
```

@tbl-Setting-original shows the frequency distribution for the setting where 
eligible applicants practice in its original coding. It shows that the Tribal 
category is too small to model as a separate level,, so we need to combine it 
with another category. 

```{r}
#| label: tbl-Setting-original
#| tbl-cap: Original Practice Setting Frequency Distribution Among Eligible Applicants

# Footnote text. 
FN <- paste("Denominator for percents is total number of eligible applicants.")

xtabs(~as_factor(practicset_dem_num), addNA = TRUE, 
      data = Eligible_Applicants) %>% 
  addmargins() %>% 
  as.data.frame() %>% 
  rename(practicset_dem_num = as_factor.practicset_dem_num.) %>% 
  mutate(Percent = 100*Freq/nrow(Eligible_Applicants),
         Cumulative = if_else(practicset_dem_num == "Sum", 
                              true = 100, 
                              false = cumsum(Percent))) %>% 
  kable(format = "latex", booktabs = TRUE, digits = 1,
        col.names = c("practicset_dem_num", "Freq", "%", "Cumulative %")) %>% 
  kable_styling() %>% 
  row_spec(row = 5, italic = TRUE) %>% 
  footnote(kable_input = ., general = FN, footnote_as_chunk = TRUE, 
           threeparttable = TRUE)
```

@tbl-Setting-recoded shows the updated frequency distribution for setting after 
collapsing the Rural and Tribal categories together. This glosses over important 
cultural differences between those settings, but these two settings are similar 
in size. 
 
```{r}
#| label: tbl-Setting-recoded
#| tbl-cap: Recoded Practice Setting Frequency Distribution Among Eligible Applicants

# Footnote text. 
FN <- paste("Denominator for percents is total number of eligible applicants.")

xtabs(~as_factor(Setting), addNA = TRUE, data = Eligible_Applicants) %>% 
  addmargins() %>% 
  as.data.frame() %>% 
  rename(Setting = as_factor.Setting.) %>% 
  mutate(Percent = 100*Freq/nrow(Eligible_Applicants),
         Cumulative = if_else(Setting == "Sum", 
                              true = 100, 
                              false = cumsum(Percent))) %>% 
  kable(format = "latex", booktabs = TRUE, digits = 1,
        col.names = c("Setting (Recoded)", "Freq", "%", "Cumulative %")) %>% 
  kable_styling() %>% 
  row_spec(row = 4, italic = TRUE) %>% 
  footnote(kable_input = ., general = FN, footnote_as_chunk = TRUE, 
           threeparttable = TRUE)
```

\FloatBarrier

# Summaries of Thresholds Data
@fig-Stages shows the final set of stages and thresholds between them at which
attrition from the training program could occur. The arrows associated with each
threshold are labeled according to how the outcome variable is coded on the
corresponding person-threshold record, depending on whether the person
stopped participating at the current stage or moved on to the next stage.

```{dot}
//| label: fig-Stages
//| fig-cap: Stages, Thresholds (T1-T4), and Stopping Ratios (SR1-SR4) in the 
//|          SANE Training Program. CSW, clinical skills workshop; DT, didactic 
//|          training.
//| fig-width: 6
//| fig-height: 3

digraph StagesModeled {

graph [rankdir="LR"];

node [shape = "box", style= "filled", fillcolor = "Gray90", fontsize = "7"];
A1 [label = "Attrited 1\nNot Enrolled\nSR1"]
A2 [label = "Attrited 2\nBefore DT\nSR2"]
A3 [label = "Attrited 3\nDuring DT\nSR3"]
A4 [label = "Attrited 4\nBefore CSW\nSR4"]

S1 [label = "Stage 1\nEligible"]
S2 [label = "Stage 2\nEnrolled"]
S3 [label = "Stage 3\nStarted DT"]
S4 [label = "Stage 4\nFinished DT"]
S5 [label = "Stage 5\nFinished CSW"]

edge [fontsize = "7"];

S1 -> A1 [label = "T1\nAttrit = 1"]
S2 -> A2 [label = "T2\nAttrit = 1"]
S3 -> A3 [label = "T3\nAttrit = 1"]
S4 -> A4 [label = "T4\nAttrit = 1"]

S1 -> S2 [label = "Attrit = 0"]
S2 -> S3 [label = "Attrit = 0"]
S3 -> S4 [label = "Attrit = 0"]
S4 -> S5 [label = "Attrit = 0"]
}
```

```{r}
#| label: tbl-Threshold-Attrit
#| tbl-cap: Threshold by Attrit Contingency Table

# Footnote text. 
FN <- paste("Denominator for percents is row N.", 
            "CSW, clinical skills workshop; DT, didactic training; N, number",
            "of participants who reached the from stage.")

Thresholds %>% 
  mutate(Threshold = as_factor(Threshold),
         Attrit = as_factor(Attrit)) %>% 
  group_by(Threshold, Attrit) %>% 
  summarise(N = n()) %>% 
  pivot_wider(names_from = Attrit, values_from = N) %>% 
  mutate(N = No + Yes,
         Percent = 100*Yes/N) %>% 
  select(Threshold, N, No, Yes, Percent) %>% 
  kable(format = "latex", booktabs = TRUE, digits = 1, 
        col.names= c("Threshold (from/to)", "N", "No (0)", 
                     "Yes (1)", "%")) %>% 
  kable_styling() %>% 
  add_header_above(header = c(" " = 2, "Attrit" = 3)) %>% 
  footnote(kable_input = ., general = FN, footnote_as_chunk = TRUE, 
           threeparttable = TRUE)
```

\FloatBarrier

# References
::: {#refs}
:::

\FloatBarrier

# Software Information
This section documents information that is important for reproducibility. Most
users will not need to read it. It is primarily here for use by the statistician 
on the team if we need to troubleshoot reproducibility issues because someone 
else is unable to get the same results from the same code. Start by checking for 
differences in package versions. 

We used [R](https://www.r-project.org/) as our main computing environment and
[Quarto](https://quarto.org/) scripts to enhance reproducibility. We used
[RStudio](www.rstudio.org) as the editor to interface with R and Quarto.

- Software chain:
  **qmd file > RStudio > Quarto > R > knitr > md file > Pandoc > tex file > TinyTeX > PDF file**.
- Source file: \texttt{\detokenize{`r params$SourceFile`}} 
- Output file: \texttt{\detokenize{`r params$LogFile`}} 
- [Quarto `r quarto_version()`](https://quarto.org/) runs `*.qmd` files through 
  [R](https://www.r-project.org/) and [knitr](https://yihui.org/knitr/) to 
  produce `*.md` markdown files.
- [Pandoc `r rmarkdown::pandoc_version()`](https://pandoc.org) converts markdown 
  files (`*.md`) to other formats, including LaTeX (`*.tex`) and HTML (`*.html`) 
  among others.
- [TinyTeX](https://yihui.org/tinytex/) compiles LaTeX files (`*.tex`) into PDF 
  files. It should be viable to use [MiKTeX](https://miktex.org) or another 
  LaTeX distribution instead. 

\FloatBarrier

## Versions
This document was generated using the following computational environment and 
dependencies:

```{r}
#| label: show-version
#| echo: true

# Check and report whether we used TinyTex or other LaTeX software. 
which_latex()

# Get R and R package version numbers in use.
devtools::session_info()
```

\FloatBarrier

## Git Details
The current Git commit details and status are:

``` {r}
#| label: git-details
#| echo: true

git_report()
```

This is useful because it tells us exactly which commit in the Git history 
we would need to be using to make sure we are running the exact same code. 
Sometimes another person is not using the most current code, or has changed the 
code in some way since it was last committed.  

::: {.callout-tip}
* Untracked files are files located in the repository that Git has not been told 
  to entirely ignore, but have also not been committed into the version history. 
* Unstaged changes to files indicate that some of the contents have been 
  modified since the last time the file was committed to Git. In production 
  runs, we want the Git output to not show any unstaged changes to key files!

::: 
