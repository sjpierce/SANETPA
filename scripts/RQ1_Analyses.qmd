---
title: Research Question 1 Analyses for SANE Training Program Data
subtitle: | 
          | CSTAT Case: C1788
          | Clients: Rebecca Campbell, Autumn Ashley, & Katherine Dontje
author: 
  - name: Steven J. Pierce
    orcid: 0000-0002-0679-3019
    email: pierces1@msu.edu
    affil-id: 1 
affiliations: 
  - id: 1 
    name: Michigan State University
    department: Center for Statistical Training and Consulting
    url: "[https://cstat.msu.edu](https://cstat.msu.edu)"
bibliography: references.bib          # File holds BibTeX data for references
csl: apa.csl                          # File controls citation & reference list format
params:                               # Default values for parameters
  SourceDir: "scripts/"               # Relative path to folder holding this file
  SourceFile: "RQ1_Analyses.qmd"    # Name of this script file
  LogFile: "RQ1_Analyses_Draft.pdf" # Default name of rendered output file
format: 
  pdf:                                # Settings for PDF output
    output-file: "RQ1_Analyses_Draft.pdf" # Default output file name 
    output-ext: "pdf"                 # Default file name extension
    documentclass: scrartcl           # LaTeX document type
    papersize: letter
    geometry:                         # Control page margins
      - top=1in
      - bottom=1in
      - left=1in
      - right=1in
    number-sections: true           # Auto-number each section
    toc: true                       # Include table of contents (TOC)
    toc-depth: 3                    # Number of layers in TOC
    colorlinks: true
    template-partials: 
      - title.tex   # Controls author affiliation formatting
    include-in-header:
      - file: compact-title.tex    # Controls spacing around title. 
      - text: |
          \usepackage{fancyhdr}
          \usepackage[noblocks]{authblk}
          \renewcommand*{\Authsep}{, }
          \renewcommand*{\Authand}{, }
          \renewcommand*{\Authands}{, }
          \renewcommand\Affilfont{\small}
          \usepackage[yyyymmdd,hhmmss]{datetime}    %% for currenttime command
          \usepackage{lastpage}                     %% For pageref command
          \usepackage{fontspec}
          \defaultfontfeatures{Ligatures=TeX}
          \usepackage[font={small}, margin=1cm, skip=2pt]{caption}
          \usepackage{url}
          \usepackage{floatrow}                     %% For controlling float placement
          \floatsetup[table]{capposition=top}       %% Puts table caption at top.
          \floatsetup[longtable]{margins=centering} %% Centers longtable tables
          \floatplacement{figure}{!ht}              %% Control placement of figures
          \floatplacement{table}{!ht}               %% Control placement of tables
          \usepackage[labelfont=bf, textfont=bf]{caption}  %% For bolded table/figure captions
          \usepackage{placeins}                     %% For FloatBarrier command
          \usepackage{booktabs}                     %% Used by kableExtra
          \usepackage{longtable}                    %% Used by kableExtra
          \usepackage{array}                        %% Used by kableExtra
          \usepackage{multirow}                     %% Used by kableExtra
          \usepackage{wrapfig}                      %% Used by kableExtra
          \usepackage{colortbl}                     %% Used by kableExtra
          \usepackage{pdflscape}                    %% Used by kableExtra
          \usepackage{tabu}                         %% Used by kableExtra
          \usepackage[normalem]{ulem}               %% Used by kableExtra
          \usepackage{makecell}                     %% Used by kableExtra
          \usepackage{xcolor}                       %% Used by kableExtra
          \usepackage{dcolumn}                      %% Used by kableExtra
          \usepackage{threeparttable}               %% Used by kableExtra
          \usepackage{threeparttablex}              %% Used by kableExtra
          \usepackage{amsmath}                      %% for equation support. 
          \usepackage{titling}      
          \usepackage{verbatim}                     %% For comment command
          \pretitle{\begin{center}\LARGE\bfseries\sffamily}
          \posttitle{\end{center}}
          \pagestyle{fancy}
          \lhead{SANETPA RQ1 Analyses}
          \chead{\includegraphics[height=0.85cm]{../graphics/Combomark-Horiz_Pantone-567.eps}}
          \rhead{\today\ \currenttime}
          \cfoot{ }
          \fancyfoot[R]{\thepage\ of \pageref*{LastPage}}
          \renewcommand{\headrulewidth}{0.4pt}
          \renewcommand{\footrulewidth}{0.4pt}
          \fancypagestyle{plain}{\pagestyle{fancy}}
          \newcommand*\tocentryformat[1]{{\sffamily#1}}  %% Fix TOC font style
          \RedeclareSectionCommands                      %% Fix TOC font style
            [
              tocentryformat=\tocentryformat,
              tocpagenumberformat=\tocentryformat
            ]
            {section,subsection,subsubsection,paragraph,subparagraph}
execute:                              # Default Quarto chunk execution options
  eval: true
  echo: fenced                        # Show the code in the output file
  output: true
  warning: true
  error: true
  include: true
knitr:                                # Default R knitr package chunk options
  opts_chunk: 
    message: true
    cfsize: "tiny"  
---

\lfoot{\texttt{\small \detokenize{`r params$LogFile`}}}

\FloatBarrier

# Purpose
This file is part of a research compendium [@Pierce-RN8756] associated with a 
study about a sexual assault nurse examiner training program [@Dontje-RN8757]. 
It contains results from analyses that address RQ1.

# Research Question

* **RQ1.** What are the eligibility and enrollment rates for this program, and 
  do eligible vs. enrolled participants differ with respect to their background, 
  motivations, potential barriers, and emotional readiness for this kind of 
  work?

\FloatBarrier

# Setup
This section documents some setup tasks that are useful to the statistician on 
the team. Most readers of this document will probably want skip directly to 
@sec-Read-Data.

\FloatBarrier

## Define Global Options
Global R chunk options are defined in the YAML header but local chunk options
will over-ride global options. We can temporarily disable an individual chunk by
inserting `#| eval: false` on a line at the top of the chunk. The method for
creating a `cfsize` option that controls font size in code chunks and their text
output is based on an answer to a question posted on
[stackoverflow.com](https://stackoverflow.com/a/46526740).

``` {r}
#| label: global-options

# Create a custom chunk hook/option for controlling font size in chunk & output.
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$cfsize != "normalsize", 
         paste0("\n \\", options$cfsize,"\n\n", x, "\n\n \\normalsize"), 
         x)
  })
```

\FloatBarrier

## Load Packages
R packages usually add new functions to the base R software, allowing you to do 
more things. Here, we load the specific R packages required for this script to 
work.

```{r}
#| label: load-packages
library(devtools)       # for session_info()
library(here)           # for here(), i_am(), makes code more portable.
library(rmarkdown)      # for pandoc_version()
library(knitr)          # for kable()
library(dplyr)          # for %>%, filter(), group_by(), mutate(), rename(), etc.
library(broom)          # for broom()
library(effectsize)     # for hedges_g()
library(tidyverse)      # for map(), map_dfr(), map_chr(), rowid_to_column(), 
                        # unnest(), etc.
library(haven)          # for as_factor()
library(janitor)        # for adorn_totals()
options(kableExtra.latex.load_packages = FALSE)
library(kableExtra)     # for kable_styling(), add_header_above(), 
                        # column_spec(), row_spec() etc. 
library(piercer)        # for dc_summary(), file_details(), git_report(), 
                        # which_latex()
library(psych)          # for alpha()
library(quarto)         # for quarto_version()
library(SANETPA)        # for version info 
```

\FloatBarrier

## Declare Path
This next chunk declares the path to this script relative to the project-level 
root directory. If the file is not in the right location under the project root
you'll get a warning message. This helps ensure relative paths are all working 
as expected. The chunk below uses the `SourceDir` and `SourceFile` parameters 
set in the YAML header. 

``` {r}
#| label: declare-path

# Declare path to this script relative to the project root directory.
here::i_am(path = paste0(params$SourceDir, params$SourceFile))
```

\FloatBarrier

## Read Data {#sec-Read-Data}
We start by reading in the datafile, which contains the following datasets that 
we need for RQ1 analyses:

* `Applicants`. This is a person-level data file containing one row for every 
  applicant, regardless of eligibility status., 
* `Eligible_Applicants`. This is a person-level file containing one row for 
  every person who both applied and was eligible for the program. It omits 
   those who were ineligible. 

``` {r}
#| label: load-data
#| eval: true

# Store path to data file. 
DataFile <- here("data/Imported_SANETP_Data.RData")

load(file = DataFile)
```

@tbl-imported-data-file shows meta-data about the data file we just loaded and
@tbl-datasets shows the sizes of the datasets it contains. 

```{r}
#| label: tbl-imported-data-file
#| tbl-cap: "Meta-Data About the Data File Loaded"

file_details(DataFile) %>% 
  kable(, format = "latex", booktabs = TRUE, 
        col.names = c("File Name", "Size", "Last Modified")) %>% 
  kable_styling() 
```


```{r}
#| label: tbl-datasets
#| tbl-cap: "Sizes of the Datasets Used for RQ1"

data.frame(Dataset = c("Applicants", "Eligible_Applicants"),
           N_Rows = c(nrow(Applicants), nrow(Eligible_Applicants)),
           N_Cols = c(ncol(Applicants), ncol(Eligible_Applicants))) %>% 
  kable(, format = "latex", booktabs = TRUE, 
        col.names = c("Dataset", "N Rows", "N Columns")) %>% 
  kable_styling() 
```

\FloatBarrier

## Update Data {#sec-Update-Data}
Below, we just convert some variables to factors to improve output formatting 
later. 

``` {r}
#| label: update-Eligible-Applicants

Eligible_Applicants <- Eligible_Applicants %>% 
  mutate(Education = as_factor(Education),
         Education = fct_relevel(Education, c("Diploma", "Associates degree")),
         License = as_factor(License),
         Setting = as_factor(Setting),
         Employ_Status = as_factor(Employ_Status),
         Employ_Nurse = as_factor(Employ_Nurse),
         Prior_SANE = as_factor(Prior_SANE))
```

We will need to create tables that have both overall summaries for all eligible 
applicants regardless of `Enrolled` value, and breakdowns for `Enrolled = No` 
and `Enrolled = Yes`. Creating a copy of `Eligible_Applicants` called `Overall` 
where I've recoded to set `Enrolled = Both` for all cases and made that a 
factor with 3 levels (`Both`, `No`, and `Yes`) will allow me to bind 
`Overall` and `Eligible_Applicants` together then use the same code that already 
worked to get the breakdowns for `Enrolled = No` and `Enrolled = Yes` to also 
get the overall summary. 

``` {r}
#| label: create-Overall

Overall <- Eligible_Applicants %>% 
  mutate(Enrolled = "Overall",
         Enrolled = factor(Enrolled, levels = c("Overall", "No", "Yes")))
```

\FloatBarrier

# Methods {#sec-Methods}
This section describes the data sources, measures, and statistical methods used 
to answer RQ1. 

\FloatBarrier

## Data Sources
We rely on two different datasets for answering RQ1. The `Applicants` dataset 
has one row for every unique applicant regardless of eligibility or enrollment 
status ($N = `r nrow(Applicants)`$). Meanwhile, the `Eligible_Applicants` 
dataset contains the subset of applicants who met all eligibility criteria for 
participating in the program ($N = `r nrow(Eligible_Applicants)`$). Some, but 
not all, eligible applicants enrolled in the training program. 

## Measures {#sec-Measures}
The sections below describe the measures used to answer RQ1. 
\FloatBarrier

### Eligibility Status
We measured applicants' eligibility status with a binary variable (`Eligible`, 
coded 0 = *No*, 1 = *Yes*). This was the case selection variable for creating 
the `Eligible_Applicants` dataset from the `Applicants` dataset and the outcome 
variable for assessing eligibility rate. 

\FloatBarrier

### Enrollment Status
Both the eligible and enrolled applicants met the program eligibility criteria. 
The two groups are actually defined by the applicant's enrollment status, which
is a binary variable (`Enrolled`, coded 0 = *No*, 1 = *Yes*). We can therefore
also refer to these groups as unenrolled versus enrolled applicants for a bit
more clarity. Enrollment status is the outcome variable for estimating the 
enrollment rate, but becomes the independent variable when we compare unenrolled 
and enrolled groups of applicants.

\FloatBarrier

### Background Characteristics
We measured applicants' education via a categorical variable (`Education`) with 
four levels: *Diploma*, *Associates degree*, *Bachelors degree*, and 
*Graduate degree*. Their licensure or certification for practice was recorded in 
a categorical variable (`License`) with three levels: 
*Certified Nurse Midwife (CNM)*, *Nurse Practitioner (NP)*, and 
*Registered Nurse (RN)*. 

The primary setting where applicants practiced nursing (`Setting`) was measured 
by a catgegorical variable with three levels: *Urban*, *Rural/Tribal*, and 
*Suburban*. As noted in the data import script output, *Tribal* was initially 
a separate category but later combined with *Rural* because it was too small to 
be analyzed on its own and those categories represent settings most similar in 
size. This glosses over important cultural differences between rural and tribal 
settings, but it is better than omitting the applicants from tribal settings. 

Applicants' current employment status was measured by a categorical variable 
(`Employ_Status`) with three levels: *Full time*, *Part time*, and *Unemployed*. 
They were also asked whether they were currently employed as a nurse: 
`Employ_Nurse` was coded *No*, *Yes*, or *NA* (for missing data that were 
not available). We also treated that as a categorical variable with three 
levels. Applicants reported how many years they had been been practicing as a 
nurse since completing their initial nursing program, with `Nurse_Years` 
recorded as a continuous variable. 

Finally, applicants were asked whether they had attended any previous SANE 
training, with `Prior_SANE` recorded as a three level categorical variable coded 
*No training*, *Completed didactic training*, and 
*Completed didactic and clinical skills training*. 

\FloatBarrier

### Motivations
The two motivation measures are binary (coded 0 = *No*, 1 = *Yes*) and include 
whether the applicant was motivated to seek the training by (a) a need for SANE 
services in their community or organization (`Motivation_NeedSANE`), and (b) a 
personal connection to sexual assault (e.g., someone they know is a survivor)
(`Motivation_PersonalConn`). We refer to the proportions for these outcomes 
as endorsement rates because they reflect how often applicants endorsed having 
each of these motivations.

\FloatBarrier

### Potential Barriers
The potential barriers outcome variables are single-item measures of barriers to
participation due to family obligations (`Barrier_FO`) and work responsibilities
(`Barrier_WR`) as competing demands on applicants' time. While these are
technically ordinal items following a 5-point Likert-response format, that
should be enough categories to treat them as continuous variables for these
analyses.

\FloatBarrier

### Emotional Readiness
The emotional readiness measures are all continuous scores measured by ProQOL 
subscales for burnout (`ProQOL_BO`), compassion satisfaction (`ProQOL_CS`), and 
secondary traumatic stress (`ProQOL_STS`) [@Stamm-RN8775].

\FloatBarrier

## Planned Statistical Analyses {#sec-Planned-Analyses}
This section describes the statistical analysis methods used to answer RQ1. 

\FloatBarrier

### Eligibility and Enrollment Rates
Estimating the eligibility and enrollment rates was simple. We estimated the
means of relevant binary variables (`Eligible` and `Enrolled`). Starting from a 
dataset with the correct set of applicants ensures that we use the correct
denominator for each rate (the mean of a binary variable is the proportion of
observations that have a value of 1). The eligibility rate used data about all
applicants, whereas the enrollment rate used only data from eligible applicants.
We used Wilson score confidence intervals to quantify the uncertainty in both
rates [@Newcombe-RN2457; @Wilson-RN3223]. 

### Comparisons of Eligible vs Enrolled Applicants
The method used to compare groups of applicants depended on the type of outcome
measure involved. We used an extension of Fisher's exact test to examine whether
the distributions of nominal outcomes with 3 or more levels differed between
unenrolled versus enrolled applicants. The null hypothesis is that that 2
categorical variables representing rows and columns of a 2-way contingency table
are independent. This test does not produce a test statistic other than a
p-value. In the contingency tables, rows represent values of the outcome,
columns represent the unenrolled versus enrolled participants. We report column
percentages to emphasize the conditional distribution of the outcome within each
enrollment status group.

We estimated the the proportions of eligible applicants in each group who have a 
1 (*Yes*) on each binary outcome, along with corresponding Wilson score 
confidence intervals [@Newcombe-RN2457; @Wilson-RN3223]. Then, we estimated the 
difference in proportions ($p_1 -p_2$) to obtain an unstandardized effect size 
measure, conducted a score test with continuity correction to test for a 
difference between independent proportions (i.e., $H_0: p_1 - p_2 = 0$ or 
$H_0: p_1 = p_2$) and obtained a corresponding score confidence interval for the
difference in proportions [@Newcombe-RN8834; @Newcombe-RN2457].

For continuous outcomes, we estimated the mean and corresponding confidence 
interval for each group, then conducted Welch's t-tests to compare the means 
using a standard null hypothesis ($H_0: \mu_1 - \mu_2 = 0$ or 
$H_0: \mu_1 = \mu_2$). Welch's t-test does not assume equal variances between 
the groups and its degrees of freedom are a function of the group sizes and
standard deviations [@Delacre-RN8835]. The t-tests are supported by point
estimates and confidence intervals for two effect size measures: the raw mean
difference ($\bar{x_1} - \bar{x_2}$, an unstandardized measure in the units of 
the original variables) and Hedges' $g{^*_s}$. The latter measure is a 
bias-corrected, standardized mean difference in units of standard deviations 
that is better than Cohen's $d$ when variances are unequal, so it pairs well 
with Welch's t-test [@Delacre-RN8837].

\FloatBarrier

The eligibility and enrollment rates are summarized in @tbl-Rates. 

```{r}
#| label: tbl-Rates
#| tbl-cap: Eligibility and Enrollment Rates 

FN <- paste("CI, Wilson score confidence interval for a proportion.")

bind_rows(dc_summary(data = Applicants, vars = "Eligible"), 
          dc_summary(data = Eligible_Applicants, vars = "Enrolled")) %>% 
  bind_cols(Among = c("All applicants", "Eligible applicants")) %>% 
  mutate(No = as.character(No),
         Yes = as.character(Yes),
         Total = as.character(Total)) %>% 
  relocate(Variable, Among) %>% 
  kable(format = "latex", booktabs = TRUE, digits = 2, align = "llrrrrrr",
        format.args = list(nsmall = 2)) %>% 
  kable_styling() %>% 
  add_header_above(header = c(" " = 2,"Binary Variable (N)" = 3, " ", "95% CI" = 2)) %>% 
  footnote(kable_input = ., general = FN, footnote_as_chunk = TRUE, 
           threeparttable = TRUE)
```

\FloatBarrier

# Compare Eligible vs Enrolled Applicants

## Background 

## Motivations

## Potential Barriers

## Emotional Readiness


\FloatBarrier

# References
::: {#refs}
:::

\FloatBarrier

# Software Information
This section documents information that is important for reproducibility. Most
users will not need to read it. It is primarily here for use by the statistician 
on the team if we need to troubleshoot reproducibility issues because someone 
else is unable to get the same results from the same code. Start by checking for 
differences in package versions. 

We used [R](https://www.r-project.org/) as our main computing environment and
[Quarto](https://quarto.org/) scripts to enhance reproducibility. We used
[RStudio](www.rstudio.org) as the editor to interface with R and Quarto.

- Software chain:
  **qmd file > RStudio > Quarto > R > knitr > md file > Pandoc > tex file > TinyTeX > PDF file**.
- Source file: \texttt{\detokenize{`r params$SourceFile`}} 
- Output file: \texttt{\detokenize{`r params$LogFile`}} 
- [Quarto `r quarto_version()`](https://quarto.org/) runs `*.qmd` files through 
  [R](https://www.r-project.org/) and [knitr](https://yihui.org/knitr/) to 
  produce `*.md` markdown files.
- [Pandoc `r rmarkdown::pandoc_version()`](https://pandoc.org) converts markdown 
  files (`*.md`) to other formats, including LaTeX (`*.tex`) and HTML (`*.html`) 
  among others.
- [TinyTeX](https://yihui.org/tinytex/) compiles LaTeX files (`*.tex`) into PDF 
  files. It should be viable to use [MiKTeX](https://miktex.org) or another 
  LaTeX distribution instead. 

\FloatBarrier

## Versions
This document was generated using the following computational environment and 
dependencies:

```{r}
#| label: show-version
#| echo: true

# Check and report whether we used TinyTex or other LaTeX software. 
which_latex()

# Get R and R package version numbers in use.
devtools::session_info()
```

\FloatBarrier

## Git Details
The current Git commit details and status are:

``` {r}
#| label: git-details
#| echo: true

git_report()
```

This is useful because it tells us exactly which commit in the Git history 
we would need to be using to make sure we are running the exact same code. 
Sometimes another person is not using the most current code, or has changed the 
code in some way since it was last committed.  

::: {.callout-tip}
* Untracked files are files located in the repository that Git has not been told 
  to entirely ignore, but have also not been committed into the version history. 
* Unstaged changes to files indicate that some of the contents have been 
  modified since the last time the file was committed to Git. In production 
  runs, we want the Git output to not show any unstaged changes to key files!

::: 
