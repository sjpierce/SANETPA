---
title: Stopping-Ratio Modeling Results
subtitle: | 
          | CSTAT Case: C1788
          | Clients: Rebecca Campbell, Autumn Ashley, & Katherine Dontje
author: 
  - name: Steven J. Pierce
    orcid: 0000-0002-0679-3019
    email: pierces1@msu.edu
    affil-id: 1 
affiliations: 
  - id: 1 
    name: Michigan State University
    department: Center for Statistical Training and Consulting
    url: "[https://cstat.msu.edu](https://cstat.msu.edu)"
bibliography: references.bib          # File holds BibTeX data for references
csl: apa.csl                          # File controls citation & reference list format
params:                               # Default values for parameters
  SourceDir: "scripts/"               # Relative path to folder holding this file
  SourceFile: "SR_Model.qmd"          # Name of this script file
  LogFile: "SR_Model_Draft.pdf"       # Name of rendered output file
format: 
  pdf:                                # Settings for PDF output
    output-file: "SR_Model_Draft.pdf" # Default output file name 
    output-ext: "pdf"                 # Default file name extension
    documentclass: scrartcl           # LaTeX document type
    papersize: letter
    geometry:                         # Control page margins
      - top=1in
      - bottom=1in
      - left=1in
      - right=1in
    number-sections: true           # Auto-number each section
    toc: true                       # Include table of contents (TOC)
    toc-depth: 3                    # Number of layers in TOC
    colorlinks: true
    template-partials: 
      - title.tex   # Controls author affiliation formatting
    include-in-header:
      - file: compact-title.tex    # Controls spacing around title. 
      - text: |
          \usepackage{fancyhdr}
          \usepackage[noblocks]{authblk}
          \renewcommand*{\Authsep}{, }
          \renewcommand*{\Authand}{, }
          \renewcommand*{\Authands}{, }
          \renewcommand\Affilfont{\small}
          \usepackage[yyyymmdd,hhmmss]{datetime}    %% for currenttime command
          \usepackage{lastpage}                     %% For pageref command
          \usepackage{fontspec}
          \defaultfontfeatures{Ligatures=TeX}
          \usepackage[font={small}, margin=1cm, skip=2pt]{caption}
          \usepackage{url}
          \usepackage{floatrow}                     %% For controlling float placement
          \floatsetup[table]{capposition=top}       %% Puts table caption at top.
          \floatsetup[longtable]{margins=centering} %% Centers longtable tables
          \floatplacement{figure}{!ht}              %% Control placement of figures
          \floatplacement{table}{!ht}               %% Control placement of tables
          \usepackage[labelfont=bf, textfont=bf]{caption}  %% For bolded table/figure captions
          \usepackage{placeins}                     %% For FloatBarrier command
          \usepackage{booktabs}                     %% Used by kableExtra
          \usepackage{longtable}                    %% Used by kableExtra
          \usepackage{array}                        %% Used by kableExtra
          \usepackage{multirow}                     %% Used by kableExtra
          \usepackage{wrapfig}                      %% Used by kableExtra
          \usepackage{colortbl}                     %% Used by kableExtra
          \usepackage{pdflscape}                    %% Used by kableExtra
          \usepackage{tabu}                         %% Used by kableExtra
          \usepackage[normalem]{ulem}               %% Used by kableExtra
          \usepackage{makecell}                     %% Used by kableExtra
          \usepackage{xcolor}                       %% Used by kableExtra
          \usepackage{dcolumn}                      %% Used by kableExtra
          \usepackage{threeparttable}               %% Used by kableExtra
          \usepackage{threeparttablex}              %% Used by kableExtra
          \usepackage{amsmath}                      %% for equation support. 
          \usepackage{titling}      
          \usepackage{verbatim}                     %% For comment command
          \pretitle{\begin{center}\LARGE\bfseries\sffamily}
          \posttitle{\end{center}}
          \pagestyle{fancy}
          \lhead{SANETPA SR Models}
          \chead{\includegraphics[height=0.85cm]{../graphics/Combomark-Horiz_Pantone-567.eps}}
          \rhead{\today\ \currenttime}
          \cfoot{ }
          \fancyfoot[R]{\thepage\ of \pageref*{LastPage}}
          \renewcommand{\headrulewidth}{0.4pt}
          \renewcommand{\footrulewidth}{0.4pt}
          \fancypagestyle{plain}{\pagestyle{fancy}}
          \newcommand*\tocentryformat[1]{{\sffamily#1}}  %% Fix TOC font style
          \RedeclareSectionCommands                      %% Fix TOC font style
            [
              tocentryformat=\tocentryformat,
              tocpagenumberformat=\tocentryformat
            ]
            {section,subsection,subsubsection,paragraph,subparagraph}
execute:                              # Default Quarto chunk execution options
  eval: true
  echo: fenced                        # Show the code in the output file
  output: true
  warning: true
  error: true
  include: true
knitr:                                # Default R knitr package chunk options
  opts_chunk: 
    message: true
    cfsize: "scriptsize" 
---

\lfoot{\texttt{\small \detokenize{`r params$LogFile`}}}

\FloatBarrier

# Purpose
This file is part of a research compendium [@Pierce-RN8756] associated with a 
study about a sexual assault nurse examiner training program [@Dontje-RN8757]. 
The study aims to document rates of attrition at four points during the 
program and understand predictors of attrition at each of those points. 

This file reads an R data file created by another script in this compendium,
documents some methodology decisions and details, then runs the
stopping-ratio models that comprise the main analysis for the study. This
file also contains some narrative interpretation of the results and
supplementary output such as tables and graphs derived from the models.

# Research Questions
The research questions may be briefly stated as follows:

* **RQ1.** What are the attrition rates from the program at each of the four 
  thresholds representing transitions between stages of program participation?
* **RQ2.** Which focal predictors affect attrition rates? 
    * Burnout.
    * Compassion satisfaction.
    * Secondary traumatic stress.
    * Barrier time demands.
    * Primary setting where the trainee practices nursing.
    * Motivated to seek the training by a need for SANE services in their 
      community or organization.
    * Motivated to seek the training by a personal connection to sexual assault 
      (e.g., someone they know is a survivor). 
* **RQ3.** Which focal predictors have parallel effects (constant across 
  thresholds) on attrition and which ones have non-parallel (threshold-specific) 
  effects?
* **RQ4.** How strongly is starting each of specific modules in the didactic 
  training associated with attrition during the didactic training? 
* **RQ5.** Is starting the module on the physical exam of a sexual assault 
  survivor a particularly strong predictor of attrition during the didactic 
  training? Program staff think encountering the content of this module may be a 
  crucial event that drives trainees to attrit. 

::: {.callout-tip}
This file addresses research questions RQ1, RQ2, and RQ3 because those are best 
handled via stopping-ratio models. Research questions RQ4 and RQ5 will be 
answered in another file because they are better handled with different 
statistical methods. 
:::

::: {.callout-note}
The investigators and the program staff have explicitly decided that the 
following potential predictors are not of substantive interest and should not be
pursued in this paper.

* Trainee satisfaction with the training is not of interest because there is 
  such low variance that it would likely exhibit ceiling effects. 
* Trainee's learning scores in the didactic training and clinical skills 
  workshop are not of interest. 
* Trainee demographics (sex, age, race, etc.) are not of interest because the 
  team wants to focus on analyzing predictors that have more intrinsic meaning 
  and for which there are theoretical reasons to expect effects on attrition. 

:::

\FloatBarrier

# Setup
This section documents some setup tasks that are useful to the statistician on 
the team. Most readers of this document will probably want skip directly to 
@sec-SR-Modeling.

\FloatBarrier

## Define Global Options
Global R chunk options are defined in the YAML header but local chunk options
will over-ride global options. We can temporarily disable an individual chunk by
inserting `#| eval: false` on a line at the top of the chunk. The method for
creating a `cfsize` option that controls font size in code chunks and their text
output is based on an answer to a question posted on
[stackoverflow.com](https://stackoverflow.com/a/46526740).

``` {r}
#| label: global-options

# Create a custom chunk hook/option for controlling font size in chunk & output.
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$cfsize != "normalsize", 
         paste0("\n \\", options$cfsize,"\n\n", x, "\n\n \\normalsize"), 
         x)
  })
```

\FloatBarrier

## Load Packages
R packages usually add new functions to the base R software, allowing you to do 
more things. Here, we load the specific R packages required for this script to 
work.

```{r}
#| label: load-packages
library(here)           # for here(), i_am(), makes code more portable.
library(devtools)       # for session_info()
library(rmarkdown)      # for pandoc_version()
library(knitr)          # for kable()
library(dplyr)          # for %>%, filter(), group_by(), mutate(), rename(), etc.
library(tidyverse)      # for map_dfr(), map_chr(), rowid_to_column(), 
                        # rownames_to_column()
options(kableExtra.latex.load_packages = FALSE)
library(kableExtra)     # for kable_styling(), add_header_above(), 
                        # column_spec(), row_spec() etc. 
library(kableExtra)     # for add_header_above(), footnote(), kable_styling()
library(broom)          # for glance(), tidy()
library(car)            # for vif()
library(emmeans)        # for emmeans()
library(performance)    # for model_performance(), r2()
library(scales)         # for label_number()
library(piercer)        # for brier(), git_report(), R2Dev()
library(quarto)         # for quarto_version()
library(SANETPA)        # for version info 
```

\FloatBarrier

## Define Custom Functions
The function below will be used to format p-values later in the output. 

```{r}
#| label: display-num

display_num <- function(x) {
  case_when(x >= 1000000 ~ sprintf("%.2e", x),
            x < .001 ~ sprintf("%.2e", x),
            .default = sprintf("%.3f", x)) 
}
```

## Declare Path
This next chunk declares the path to this script relative to the project-level 
root directory. If the file is not in the right location under the project root
you'll get a warning message. This helps ensure relative paths are all working 
as expected. The chunk below uses the `SourceDir` and `SourceFile` parameters 
set in the YAML header. 

``` {r}
#| label: declare-path

# Declare path to this script relative to the project root directory.
here::i_am(path = paste0(params$SourceDir, params$SourceFile))
```

\FloatBarrier

## Load Data {#sec-Load-Data}
This subsection loads the data created by rendering `scripts/Import_Data.qmd`. 
The data is de-identified to preserve participant privacy and protect 
confidentiality. 

``` {r}
#| label: load-data
#| eval: true

# Store path to data file. 
DataFile <- here("data/Imported_SANETP_Data.RData")

load(file = DataFile)
```

@tbl-imported-data-file shows meta-data about the data file we just loaded and
@tbl-datasets shows the sizes of the datasets it contains. 

```{r}
#| label: tbl-imported-data-file
#| tbl-cap: "Meta-Data About the Data File Loaded"

file.info(DataFile, extra_cols = FALSE) %>% 
  rownames_to_column() %>% 
  mutate(rowname = basename(rowname)) %>% 
  select(-isdir, -mode) %>% 
  kable(, format = "latex", booktabs = TRUE, 
        col.names = c("File Name", "Size (Bytes)", "Modified", 
                      "Last Status Change", "Last Accessed")) %>% 
  kable_styling() %>% 
  column_spec(column = 3:5, width = "2cm")
```

```{r}
#| label: tbl-datasets
#| tbl-cap: "Sizes of the Datasets"

data.frame(Dataset = c("Applicants", "Eligible_Applicants", 
                       "Eligible_Applicants_CD", "Thresholds"),
           N_Rows = c(nrow(Applicants), nrow(Eligible_Applicants), 
                      nrow(Eligible_Applicants_CD), nrow(Thresholds)),
           N_Cols = c(ncol(Applicants), ncol(Eligible_Applicants),
                      ncol(Eligible_Applicants_CD), ncol(Thresholds))) %>% 
  kable(, format = "latex", booktabs = TRUE, 
        col.names = c("Dataset", "N Rows", "N Columns")) %>% 
  kable_styling() 
```

\FloatBarrier

# Overview of Stopping-Ratio Modeling {#sec-SR-Modeling}
Attrition from the training program can be conceptualized as a sequential 
filtering process. There are various threshold points between stages of program 
participation where a participant may either attrit or continue participating.
Each of those thresholds is a filter: participants that attrit at a given 
threshold are filtered out of the program. That reduces the number of
participants who reach the next stage of program participation and encounter the
next threshold.

That means an eligible applicant's progress through the training program can be
measured by an ordinal stage variable that records the maximum stage reached by
the applicant in that sequential filtering process. In this study, the ordinal 
variable is called `Stage_Reached`. It is a multinomial ordinal variable with 
$J = 5$ possible stages and observed values denoted by stage $j$, where 
$j \in \{1, 2, 3, 4, 5\}$. 

@fig-Stages shows the final set of stages and thresholds (T1 to T4) between them
at which attrition from the training program could occur. The arrows associated
with each threshold are labeled according to how the outcome variable is coded
on the corresponding person-threshold record, depending on whether the person
stopped participating at the current stage or moved on to the next stage. 

```{dot}
//| label: fig-Stages
//| fig-cap: Stages, Thresholds (T1-T4), and Stopping Ratios (SR1-SR4) in the 
//|          SANE Training Program. CSW, clinical skills workshop; DT, didactic 
//|          training.
//| fig-width: 6
//| fig-height: 3

digraph StagesModeled {

graph [rankdir="LR"];

node [shape = "box", style= "filled", fillcolor = "Gray90", fontsize = "7"];
A1 [label = "Attrited 1\nNot Enrolled\nSR1"]
A2 [label = "Attrited 2\nBefore DT\nSR2"]
A3 [label = "Attrited 3\nDuring DT\nSR3"]
A4 [label = "Attrited 4\nBefore CSW\nSR4"]

S1 [label = "Stage 1\nEligible\nj = 1"]
S2 [label = "Stage 2\nEnrolled\nj = 2"]
S3 [label = "Stage 3\nStarted DT\nj = 3"]
S4 [label = "Stage 4\nFinished DT\nj = 4"]
S5 [label = "Stage 5\nFinished CSW\nj = 5"]

edge [fontsize = "7"];

S1 -> A1 [label = "T1\nAttrit = 1"]
S2 -> A2 [label = "T2\nAttrit = 1"]
S3 -> A3 [label = "T3\nAttrit = 1"]
S4 -> A4 [label = "T4\nAttrit = 1"]

S1 -> S2 [label = "Attrit = 0"]
S2 -> S3 [label = "Attrit = 0"]
S3 -> S4 [label = "Attrit = 0"]
S4 -> S5 [label = "Attrit = 0"]
}
```

There are several variations of regression models designed to analyze ordinal
outcomes: they test different hypotheses, estimate different parameters, and
yield different insights [@Fullerton-RN8774]. The research questions for this
study are best aligned with a broad class of ordinal regression models usually
called continuation-ratio (CR) models, though they are also called 
stopping-ratio (SR) models or stage models 
[@Fullerton-RN8774; @Liu-RN8772; @Yee-RN3711]. The CR model is ideally suited
for ordinal outcome data generated from a sequential selection process where all
individuals start from the same initial stage, must pass through earlier stages
to reach later ones, and all stage transitions are irreversible
[@Fullerton-RN8774; @OConnell-RN8769]. 

One key to understanding CR models is that they divide the analysis of a single 
ordinal outcome into a series of binary outcomes regarding what happens at each 
of the thresholds between stages


a set of transitions between stages

@Liu-RN8772 distinguished between forward and backward types of CR models and 
emphasized that each type can be expressed in two different sub-models depending 
on which of the two complementary conditional probabilities for a binary event 
one wants to emphasize (odds versus inversed odds). Regression coefficients 
from the two sub-models of the same type of CR model (forward or backward) have 
the same magnitude but opposite signs. The sub-models for a given type (e.g., 
forward) will also have the same model fit. However, results and interpretation 
will differ between types: the forward and backward CR models are not equivalent 
because they test different hypotheses. 

Because our focus is on predicting attrition--which stops a trainee's 
progression to the next stage of program participation--we will use the SR 
nomenclature in most cases. 

The SR model is attractive because its parameters can be translated into 
additional estimates and graphs that are easy to interpret and meaningful for 
assessing the effects of predictors on program attrition.

[@Cole-RN8770]

[@Davidson-RN8773]

[@Fullerton-RN8774]

[@Liu-RN8772]

[@Liu-RN8771]

[@Smithson-RN2775]

The reference levels for categorical predictors will be: 

* `Threshold.`: `1`
* `Setting.`: `Urban`
* `Motivation_NeedSANE.`: `No`
* `Motivation_PersonalConn.`: `No`

\FloatBarrier

# Results
Below we fit and examine a series of stopping-ratio models using the 
`Thresholds` dataset and the `glm()` function. The modeling strategy aims to 
estimate the minimum number of models required to answer research questions 
RQ1, RQ2, and RQ3 and obtain a parsimonious final model. We examine model 
diagnostics and fit statistics, model comparisons, and other supplementary 
output (e.g., effect sizes, estimated marginal means, etc.) as needed. 

\FloatBarrier

## Model 1: Thresholds Alone
The modeling starts by first fitting a very simple model (`m1`) containing only 
a threshold main effect. This should allow is to see whether attrition rate 
varies across the thresholds. @tbl-params-m1 shows the model parameters and 
@tbl-fit-m1 shows its fit statistics. 

```{r}
#| label: tbl-params-m1
#| tbl-cap: "Model 1 Parameters"

m1 <- glm(Attrit ~ Threshold. + 1, 
          data = Thresholds, family = binomial(link = "logit"))

FN <- paste("Values shown are on the link function (logit) scale.")

tidy(m1) %>% 
  cbind(confint.default(m1)) %>% 
  as_tibble() %>% 
  rename(Parameter = term, Est = estimate, SE = std.error, z = statistic, 
         p = p.value, LL = `2.5 %`, UL = `97.5 %`) %>% 
  mutate(p = display_num(p),
         OR = exp(Est), 
         OR.LL = exp(LL), 
         OR.UL = exp(UL)) %>% 
  relocate(Parameter, Est, SE, LL, UL, OR, OR.LL, OR.UL, z, p) %>% 
  kable(format = "latex", booktabs = TRUE, digits = 2) %>% 
  kable_styling() %>% 
  add_header_above(header = c(" " = 3, "95% Wald CI" = 2, " " = 1, 
                              "OR 95% Wald CI" = 2, "Wald Test" =  2))
```

```{r}
#| label: tbl-fit-m1
#| tbl-cap: "Model 1 Fit Statistics"

glance(m1) %>% 
  kable(format = "latex", booktabs = TRUE, 
        digits = c(2, 0, 2, 2, 2, 2, 0, 0)) %>% 
  kable_styling()
```

\FloatBarrier

### Single Term Deletion Tests
@tbl-drop1-m1 shows the effect of deleting the threshold term from the model to 
determine whether doing so worsens model fit. A significant effect should be 
retained in the model because omitting it would damage the model fit.

```{r}
#| label: tbl-drop1-m1
#| tbl-cap: "Model 1 Single Term Deletion Tests (Type II SS)"
#| warning: false

m1 %>% 
  drop1(., test = "LRT") %>% 
  tidy() %>% 
  rename(p = p.value) %>% 
  mutate(p = display_num(p)) %>% 
  kable(format = "latex", booktabs = TRUE,
        digits = c(0, 0, 2, 2, 2, Inf),
        col.names = c("Term Deleted", "df", "Deviance", "AIC", "LRT", "p")) %>% 
  kable_styling() 
```

::: {.callout-tip}
The threshold main effect is integral to fitting a stopping-ratio model. It must
remain in the model to properly test for both parallel and non-parallel effects
of focal predictors. Removing the threshold main effect would also harm model
fit, so we will keep it in all subsequent models.
:::

\FloatBarrier

### Estimated Marginal Means
The presence of a threshold main effect means that the attrition rate varies
across thresholds. Next we compute estimated marginal means (EMMs) for each
threshold and back-transform them to the response (probability) scale to see the
attrition rate at each threshold. We expect these rates to agree with the simple
descriptive statistics for percent attrition at each threshold because threshold
is the sole predictor in Model 1. @tbl-emmeans-m1 shows the EMMs derived from
Model 1.

```{r}
#| label: tbl-emmeans-m1
#| tbl-cap: "Model 1 Conditional Attrition Rate by Threshold"

FN <- paste("Values are on the probability scale.",
            "EMM, estimated marginal mean.")

emmeans(m1, specs = ~ Threshold., regrid = "response") %>% 
  as_tibble() %>% 
  select(!df) %>% 
  kable(format = "latex", booktabs = TRUE, 
        digits = c(0, 3, 3, 3, 3),
        col.names = c("Threshold", "Rate (EMM)", "SE", "LL", "UL")) %>% 
  kable_styling() %>% 
  add_header_above(header = c(" " = 3, "95% Wald CI" = 2)) %>% 
  footnote(kable_input = ., general = FN, footnote_as_chunk = TRUE, 
           threeparttable = TRUE)
```

```{r}
#| label: fig-emmeans-m1
#| fig-cap: "Model 1 Conditional Attrition Rate by Threshold (Main Effect)"
#| fig-width: 4
#| fig-height: 2.5

emmeans(m1, specs = ~ Threshold., regrid = "response") %>% 
  plot(horizontal = FALSE) +
  xlab("Attrition Rate") + 
  ylab("Threshold") + 
  scale_x_continuous(lim = c(0.00, 0.50), labels = label_number(accuracy = 0.01))
```

\FloatBarrier

## Model 2: Thresholds & Parallel Effects for All Focal Predictors
In SR models, a predictor has a parallel effect when its regression coefficient 
is constrained equal across all thresholds. This is implemented by estimating 
only a main effect for the predictor (it cannot interact with the threshold). 
Model 2 (`m2`) uses parallel effects for the focal predictors. See 
@tbl-params-m2 for parameter estimates and @tbl-fit-m2 for the fit statistics. 

```{r}
#| label: tbl-params-m2
#| tbl-cap: "Model 2 Parameters"

m2 <- glm(Attrit ~ Threshold. + CBarrier_TD + CProQOL_BO + CProQOL_CS + 
            CProQOL_STS + Motivation_NeedSANE. + Motivation_PersonalConn. + 
            Setting. + 1, 
          data = Thresholds, family = binomial(link = "logit"))

FN <- paste("Values shown are on the link function (logit) scale.")

tidy(m2) %>% 
  cbind(confint.default(m2)) %>% 
  as_tibble() %>% 
  rename(Parameter = term, Est = estimate, SE = std.error, z = statistic, 
         p = p.value, LL = `2.5 %`, UL = `97.5 %`) %>% 
  mutate(p = display_num(p),
         OR = exp(Est), 
         OR.LL = exp(LL), 
         OR.UL = exp(UL)) %>% 
  relocate(Parameter, Est, SE, LL, UL, OR, OR.LL, OR.UL, z, p) %>% 
  kable(format = "latex", booktabs = TRUE, digits = 2) %>% 
  kable_styling() %>% 
  add_header_above(header = c(" " = 3, "95% Wald CI" = 2, " " = 1, 
                              "OR 95% Wald CI" = 2, "Wald Test" =  2))
```

```{r}
#| label: tbl-fit-m2
#| tbl-cap: "Model 2 Fit Statistics"

glance(m2) %>% 
  kable(format = "latex", booktabs = TRUE, 
        digits = c(2, 0, 2, 2, 2, 2, 0, 0)) %>% 
  kable_styling()
```

\FloatBarrier

### Check for Multicollinearity
We will check for multicollinearity problems by examining the generalized
variance inflation factor (GVIF) and a transformation of it that adjusts for
categorical terms that use multiple degrees of freedom [@Fox-RN3484]. In 
general, one can compare to $GVIF^{(1/(2*df))}$ to cutoffs defined for 
$\sqrt{VIF}$. Some suggested cutoffs indicating potential problems are 
$\sqrt{VIF} \ge 2$ or $\sqrt{VIF} \ge 3$. We are hoping to see 
$GVIF^{(1/(2*df))} < 3$. 

```{r}
#| label: tbl-GVIF-m2
#| tbl-cap: Model 2 Generalized Variance Inflation Factors for Predictors

FN <- paste("Values >= 3 in the last column indicate multicollinearity problems.")

car::vif(m2) %>% 
  as.data.frame() %>% 
  rownames_to_column(var = "Term") %>% 
  kable(format = "latex", booktabs = TRUE, digits = 2) %>% 
  kable_styling() %>% 
  footnote(kable_input = ., general = FN, footnote_as_chunk = TRUE, 
           threeparttable = TRUE)
```

::: {.callout-tip}
We do not appear to have any multicollinearity problems in Model 2.
:::

\FloatBarrier

### Compare Models 1 and 2
@tbl-lrt-m1-m2 shows a likelihood ratio test (LRT) comparing Models 1 and 2. 

```{r}
#| label: tbl-lrt-m1-m2
#| tbl-cap: "Likehood Ratio Test Comparing Models 1 and 2"

test_lrt(m1, m2) %>% 
  as_tibble() %>% 
  mutate(p = display_num(p),
         Model = if_else(Name == "m1", 
                         true = "Thesholds", 
                         false = "Thresholds + All Parallel Effects")) %>% 
  #select(-term) %>% 
  kable(format = "latex", booktabs = TRUE, digits = c(0, 0, 0, 0, 2, 3),
        col.names = c("Model", "Terms", "df", "df_diff", "LRT", "p")) %>% 
  kable_styling()
```

\FloatBarrier

::: {.callout-caution}
This is a simultaneous test of whether adding parallel effects for all of the
focal predictors as a block improved the model fit enough to justify adding that
many extra parameters. It did not. However, the Wald tests in @tbl-params-m2 
suggest that `Motivation_NeedSANE.` has an effect while none of the other
predictors do. We need to look more closely at the effects of individual
predictors via single-term deletion tests.
:::

\FloatBarrier

### Single Term Deletion Tests
@tbl-drop1-m2 shows the effect of deleting specific terms from the model to 
determine whether doing so worsens model fit. Each main effect term is tested 
after controlling for all the other main effects. This is a more focused test 
of individual predictors than the overall LRT comparing Models 1 and 2. 
Significant effects should be retained in the model because omitting them would 
damage the model fit. Non-significant effects can potentially be omitted. 

```{r}
#| label: tbl-drop1-m2
#| tbl-cap: "Model 2 Single Term Deletion Tests (Type II SS)"
#| warning: false

m2 %>% 
  drop1(., test = "LRT") %>% 
  tidy() %>% 
  rename(p = p.value) %>% 
  mutate(p = display_num(p)) %>% 
  kable(format = "latex", booktabs = TRUE,
        digits = c(0, 0, 2, 2, 2, Inf),
        col.names = c("Term Deleted", "df", "Deviance", "AIC", "LRT", "p")) %>% 
  kable_styling() 
```

\FloatBarrier

::: {.callout-tip}
Only `Threshold` and `Motivation_NeedSANE` have main effects the need to be 
retained. We could in theory remove all the other focal predictors. 
:::

\FloatBarrier

### Estimated Marginal Means
Next we compute estimated marginal means (EMMs) for each threshold and 
back-transform them to the response (probability) scale to see the attrition 
rate at each threshold. @tbl-emmeans-m2-Threshold and @fig-emmeans-m2-Threshold 
show the EMMs derived from Model 2 for each threshold, while 
@tbl-emmeans-m2-NeedSANE and @fig-emmeans-m2-NeedSANE show the EMMs for each 
level of `Motivation_NeedSANE`. @tbl-emmeans-m2-Both and @fig-emmeans-m2-Both 
show the combined result of the two main effects while averaging over the
results of all other predictors.

```{r}
#| label: tbl-emmeans-m2-Threshold
#| tbl-cap: Model 2 Conditional Attrition Rate by Threshold (Main Effect)

FN <- paste("Values are on the probability scale.", 
            "Results are averaged over the levels of all other categorical", 
            "predictors and assume values at the mean on continuous focal", 
            "predictors.",
            "EMM, estimated marginal mean.")

emmeans(m2, specs = ~ Threshold., regrid = "response") %>% 
  as_tibble() %>% 
  select(!df) %>% 
  kable(format = "latex", booktabs = TRUE, 
        digits = c(0, 3, 3, 3, 3),
        col.names = c("Threshold", "Rate (EMM)", "SE", "LL", "UL")) %>% 
  kable_styling() %>% 
  add_header_above(header = c(" " = 3, "95% Wald CI" = 2)) %>% 
  footnote(kable_input = ., general = FN, footnote_as_chunk = TRUE, 
           threeparttable = TRUE)
```

```{r}
#| label: fig-emmeans-m2-Threshold
#| fig-cap: Model 2 Conditional Attrition Rate by Threshold (Main Effect 
#|          Averaged Over All Other Predictors)
#| fig-width: 4
#| fig-height: 2.5

emmeans(m2, specs = ~ Threshold., regrid = "response") %>% 
  plot(horizontal = FALSE) +
  xlab("Attrition Rate") + 
  ylab("Threshold") + 
  scale_x_continuous(lim = c(0.00, 0.50), labels = label_number(accuracy = 0.01))
```

```{r}
#| label: tbl-emmeans-m2-NeedSANE
#| tbl-cap: Model 2 Conditional Attrition Rate by Motivation_NeedSANE (Main 
#|          Effect)

FN <- paste("Motivation_NeedSANE has a parallel effect on attrition.",
            "Values are on the probability scale.",
            "Results are averaged over the levels of all other categorical", 
            "predictors and assume values at the mean on continuous focal", 
            "predictors.",
            "EMM, estimated marginal mean.")

emmeans(m2, specs = ~ Motivation_NeedSANE., regrid = "response") %>% 
  as_tibble() %>% 
  select(!df) %>% 
  kable(format = "latex", booktabs = TRUE, 
        digits = c(0, 3, 3, 3, 3),
        col.names = c("Motivation_NeedSANE.", "Rate (EMM)", "SE", "LL", "UL")) %>% 
  kable_styling() %>% 
  add_header_above(header = c(" " = 3, "95% Wald CI" = 2)) %>% 
  footnote(kable_input = ., general = FN, footnote_as_chunk = TRUE, 
           threeparttable = TRUE)
```

```{r}
#| label: fig-emmeans-m2-NeedSANE
#| fig-cap: Model 2 Conditional Attrition Rate by Motivation_NeedSANE (Parallel 
#|          Main Effect Averaged Over All Other Predictors)
#| fig-width: 2
#| fig-height: 2.5

emmeans(m2, specs = ~ Motivation_NeedSANE., regrid = "response") %>% 
  plot(horizontal = FALSE) +
  xlab("Attrition Rate") + 
  ylab("Motivation_NeedSANE") + 
  scale_x_continuous(lim = c(0.00, 0.50), labels = label_number(accuracy = 0.01))
```

```{r}
#| label: tbl-emmeans-m2-Both
#| tbl-cap: Model 2 Conditional Attrition Rate by Threshold and 
#|          Motivation_NeedSANE (Main Effects)

FN <- paste("Motivation_NeedSANE has a parallel effect on attrition.",
            "Results are averaged over the levels of all other categorical", 
            "predictors and assume values at the mean on continuous focal", 
            "predictors.",
            "Values are on the probability scale.", 
            "EMM, estimated marginal mean.")

emmeans(m2, specs = ~ Threshold. | Motivation_NeedSANE., regrid = "response") %>% 
  as_tibble() %>% 
  arrange(Threshold., Motivation_NeedSANE.) %>% 
  select(!df) %>% 
  kable(format = "latex", booktabs = TRUE, 
        digits = c(0, 0, 3, 3, 3, 3),
        col.names = c("Threshold", "Motivation_NeedSANE.", "Rate (EMM)", "SE", 
                      "LL", "UL")) %>% 
  kable_styling() %>% 
  add_header_above(header = c(" " = 4, "95% Wald CI" = 2)) %>% 
  collapse_rows(columns = 1:2, valign = "top", latex_hline = "major", 
                custom_latex_hline = 1, headers_to_remove = 0,
                row_group_label_position = "stack") %>% 
  footnote(kable_input = ., general = FN, footnote_as_chunk = TRUE, 
           threeparttable = TRUE)
```

```{r}
#| label: fig-emmeans-m2-Both
#| fig-cap: Model 2 Conditional Attrition Rate by Threshold and 
#|          Motivation_NeedSANE (Main Effects, Averaged Over All Other 
#|          Predictors)
#| fig-width: 4.5
#| fig-height: 2.5

emmeans(m2, specs = ~ Motivation_NeedSANE. | Threshold., regrid = "response") %>% 
  plot(horizontal = FALSE) +
  facet_grid(cols = vars(Threshold.), labeller = label_both) +
  xlab("Attrition Rate") + 
  ylab("Motivation_NeedSANE") + 
  scale_x_continuous(lim = c(0.00, 0.50), labels = label_number(accuracy = 0.01))
```

\FloatBarrier

## Model 3: Thresholds & Non-Parallel Effects for All Focal Predictors
In SR models, a predictor has a non-parallel effect when its regression 
coefficient is allowed to vary across all thresholds. That is implemented by 
allowing the predictor to have both a main effect and an interaction with the 
threshold. Continuous predictors must be appropriately centered before model 
fitting as usual when testing interactions (i.e., moderator hypotheses). Model 3 
(`m3`) treats threshold as a moderator of the other predictors' effects. See 
@tbl-params-m3 for parameter estimates and @tbl-fit-m3 for fit statistics. 

We are continuing to include predictors that did not have significant main 
effects in Model 2 because it is possible that threshold moderates the effects 
of other predictors such that there are non-parallel (threshold-specific) 
effects that get canceled out when averaging across them to estimate a parallel 
main effect. Thus, our approach maximizes the chance that we detect any 
unusually nuanced non-parallel effects if they exist. 

::: {.callout-caution}
Model 3 is rather ambitious given the sample size we have available. It is
adding seven interaction effects: that yields many extra parameters. This poses
some risk for over-fitting the model, but testing for non-parallel effects
either requires fitting this one model, or fitting a set of seven other models
where we add only a single non-parallel effect at a time. Fitting this larger
model is more efficient and reduces the total amount of output we have to
review.
:::

```{r}
#| label: tbl-params-m3
#| tbl-cap: "Model 3 Parameters"

m3 <- glm(Attrit ~ Threshold. + CBarrier_TD + CProQOL_BO + CProQOL_CS + 
            CProQOL_STS + Motivation_NeedSANE. + Motivation_PersonalConn. + 
            Setting. + Threshold.:CBarrier_TD + Threshold.:CProQOL_BO + 
            Threshold.:CProQOL_CS + Threshold.:CProQOL_STS + 
            Threshold.:Motivation_NeedSANE. + 
            Threshold.:Motivation_PersonalConn. + Threshold.:Setting. + 1, 
          data = Thresholds, family = binomial(link = "logit"))

FN <- paste("Values shown are on the link function (logit) scale.")

tidy(m3) %>% 
  cbind(confint.default(m3)) %>% 
  as_tibble() %>% 
  rename(Parameter = term, Est = estimate, SE = std.error, z = statistic, 
         p = p.value, LL = `2.5 %`, UL = `97.5 %`) %>% 
  mutate(Parameter = str_replace(string = Parameter, pattern = ":", 
                                 replacement = " x "), 
         p = display_num(p),
         OR = exp(Est), 
         OR.LL = exp(LL), 
         OR.UL = exp(UL)) %>% 
  relocate(Parameter, Est, SE, LL, UL, OR, OR.LL, OR.UL, z, p) %>% 
  kable(format = "latex", booktabs = TRUE, digits = 2) %>% 
  kable_styling(font_size = 10) %>% 
  add_header_above(header = c(" " = 3, "95% Wald CI" = 2, " " = 1, 
                              "OR 95% Wald CI" = 2, "Wald Test" =  2)) %>% 
  column_spec(column = 1, width = "5.5cm")
```

```{r}
#| label: tbl-fit-m3
#| tbl-cap: "Model 3 Fit Statistics"

glance(m3) %>% 
  kable(format = "latex", booktabs = TRUE, 
        digits = c(2, 0, 2, 2, 2, 2, 0, 0)) %>% 
  kable_styling()
```

\FloatBarrier

### Check for Multicollinearity
@tbl-GVIF-m3 shows the generalized variance inflation factors (GVIF) for Model 
3. 

```{r}
#| label: tbl-GVIF-m3
#| tbl-cap: Model 3 Generalized Variance Inflation Factors for Predictors
#| warning: false

FN <- paste("Values >= 3 in the last column indicate multicollinearity problems.")

car::vif(m3) %>% 
  as.data.frame() %>% 
  rownames_to_column(var = "Term") %>% 
  mutate(Term = str_replace(string = Term, pattern = ":", 
                            replacement = " x ")) %>%  
  kable(format = "latex", booktabs = TRUE, digits = 2) %>% 
  kable_styling() %>% 
  footnote(kable_input = ., general = FN, footnote_as_chunk = TRUE, 
           threeparttable = TRUE)
```

::: {.callout-tip}
We do not appear to have any multicollinearity problems in Model 3
:::

\FloatBarrier

### Compare Models 2 and 3
@tbl-lrt-m2-m3 shows a likelihood ratio test (LRT) comparing Models 2 and 3. 

```{r}
#| label: tbl-lrt-m2-m3
#| tbl-cap: "Likehood Ratio Test Comparing Models 2 and 3"

test_lrt(m2, m3) %>% 
  as_tibble() %>% 
  mutate(p = display_num(p),
         Model = if_else(Name == "m2", 
                         true = "Thesholds + All Parallel Effects", 
                         false = "Thresholds + All Non-Parallel Effects")) %>% 
  #select(-term) %>% 
  kable(format = "latex", booktabs = TRUE, digits = c(0, 0, 0, 0, 2, 3),
        col.names = c("Model", "Terms", "df", "df_diff", "LRT", "p")) %>% 
  kable_styling()
```

::: {.callout-caution}
This is a simultaneous test of whether adding non-parallel effects for all of 
the focal predictors as a block improved the model fit enough to justify adding 
that many extra parameters. Apparently it did not. We should still look more 
closely at the effects of individual predictors via single-term deletion tests.
:::

\FloatBarrier

### Single Term Deletion Tests
@tbl-drop1-m3 shows the effect of deleting specific interaction terms from the 
model to determine whether doing so worsens model fit. Significant effects 
should be retained in the model because omitting them would damage the model 
fit. We do not test main effects for predictors involved in interactions because 
we need to respect the principle of marginality 
[@Fox-RN3484; @Hector-RN3472; @Langsrud-RN1287]. 

```{r}
#| label: tbl-drop1-m3
#| tbl-cap: "Model 3 Single Term Deletion Tests (Type II SS)"
#| warning: false

m3 %>% 
  drop1(., test = "LRT") %>% 
  tidy() %>% 
  rename(p = p.value) %>% 
  mutate(term = str_replace(string = term, pattern = ":", 
                            replacement = " x "), 
         p = display_num(p)) %>% 
  kable(format = "latex", booktabs = TRUE,
        digits = c(0, 0, 2, 2, 2, Inf),
        col.names = c("Term Deleted", "df", "Deviance", "AIC", "LRT", "p")) %>% 
  kable_styling() 
```

::: {.callout-tip}
We can safely drop all of the interaction effects from the model. None of them 
improve the model fit. It may be worth trying a final pair of models that are 
more parsimonious than Models 2 and 3: they should include models with threshold 
effect and just parallel and non-parallel effects of `Motivation_NeedSANE.` 
without other focal predictors. 
:::

\FloatBarrier

## Model 4: Thresholds & Parallel Effect for `Motivation_NeedSANE.`
Model 2 uses a parallel effect for `Motivation_NeedSANE.` without any of the 
other focal preddictors. @tbl-params-m4 shows the parameter estimates and 
@tbl-fit-m4 shows the fit indices. 

```{r}
#| label: tbl-params-m4
#| tbl-cap: "Model 4 Parameters"

m4 <- glm(Attrit ~ Threshold. + Motivation_NeedSANE. + 1 , 
          data = Thresholds, family = binomial(link = "logit"))

FN <- paste("Values shown are on the link function (logit) scale.")

tidy(m4) %>% 
  cbind(confint.default(m4)) %>% 
  as_tibble() %>% 
  rename(Parameter = term, Est = estimate, SE = std.error, z = statistic, 
         p = p.value, LL = `2.5 %`, UL = `97.5 %`) %>% 
  mutate(p = display_num(p),
         OR = exp(Est), 
         OR.LL = exp(LL), 
         OR.UL = exp(UL)) %>% 
  relocate(Parameter, Est, SE, LL, UL, OR, OR.LL, OR.UL, z, p) %>% 
  kable(format = "latex", booktabs = TRUE, digits = 2) %>% 
  kable_styling() %>% 
  add_header_above(header = c(" " = 3, "95% Wald CI" = 2, " " = 1, 
                              "OR 95% Wald CI" = 2, "Wald Test" =  2))
```

```{r}
#| label: tbl-fit-m4
#| tbl-cap: "Model 2 Fit Statistics"

glance(m4) %>% 
  kable(format = "latex", booktabs = TRUE, 
        digits = c(2, 0, 2, 2, 2, 2, 0, 0)) %>% 
  kable_styling()
```

### Compare Models 1 and 2
@tbl-lrt-m1-m2 shows a likelihood ratio test (LRT) comparing Models 1 and 4. 

```{r}
#| label: tbl-lrt-m1-m4
#| tbl-cap: "Likehood Ratio Test Comparing Models 1 and 4"

test_lrt(m1, m4) %>% 
  as_tibble() %>% 
  mutate(p = display_num(p),
         Model = if_else(Name == "m1", 
                         true = "Thesholds", 
                         false = "Thresholds + Parallel Motivation_NeedSANE Effect")) %>% 
  #select(-term) %>% 
  kable(format = "latex", booktabs = TRUE, digits = c(0, 0, 0, 0, 2, 3),
        col.names = c("Model", "Terms", "df", "df_diff", "LRT", "p")) %>% 
  kable_styling()
```

### Estimated Marginal Means
Next we compute estimated marginal means (EMMs) for each threshold and 
back-transform them to the response (probability) scale to see the attrition 
rate at each threshold. @tbl-emmeans-m4-Threshold and tbl-emmeans-m4-NeedSANE 
respectively show the EMMs derived from Model 4 for each threshold and each 
level of `Motivation_NeedSANE.`, while @tbl-emmeans-m4-Both shows the combined 
effect of the two main effects. 

```{r}
#| label: tbl-emmeans-m4-Threshold
#| tbl-cap: "Model 4 Conditional Attrition Rate by Threshold"

FN <- paste("Values are on the probability scale.", 
            "Reseults are averaged over the levels of Motivation_NeedSANE.",
            "EMM, estimated marginal mean.")

emmeans(m4, specs = ~ Threshold., regrid = "response") %>% 
  as_tibble() %>% 
  select(!df) %>% 
  kable(format = "latex", booktabs = TRUE, 
        digits = c(0, 3, 3, 3, 3),
        col.names = c("Threshold", "Rate (EMM)", "SE", "LL", "UL")) %>% 
  kable_styling() %>% 
  add_header_above(header = c(" " = 3, "95% Wald CI" = 2)) %>% 
  footnote(kable_input = ., general = FN, footnote_as_chunk = TRUE, 
           threeparttable = TRUE)
```

```{r}
#| label: tbl-emmeans-m4-NeedSANE
#| tbl-cap: "Model 4 Conditional Attrition Rate by Motivation_NeedSANE"

FN <- paste("Values are on the probability scale.",
            "Reseults are averaged over the levels of Threshold.",
            "EMM, estimated marginal mean.")

emmeans(m4, specs = ~ Motivation_NeedSANE., regrid = "response") %>% 
  as_tibble() %>% 
  select(!df) %>% 
  kable(format = "latex", booktabs = TRUE, 
        digits = c(0, 3, 3, 3, 3),
        col.names = c("Motivation_NeedSANE.", "Rate (EMM)", "SE", "LL", "UL")) %>% 
  kable_styling() %>% 
  add_header_above(header = c(" " = 3, "95% Wald CI" = 2)) %>% 
  footnote(kable_input = ., general = FN, footnote_as_chunk = TRUE, 
           threeparttable = TRUE)
```

```{r}
#| label: tbl-emmeans-m4-Both
#| tbl-cap: "Model 4 Conditional Attrition Rate by Threshold and Motivation_NeedSANE"

FN <- paste("Values are on the probability scale.", 
            "EMM, estimated marginal mean.")

emmeans(m4, specs = ~ Threshold. | Motivation_NeedSANE., regrid = "response") %>% 
  as_tibble() %>% 
  arrange(Threshold., Motivation_NeedSANE.) %>% 
  select(!df) %>% 
  kable(format = "latex", booktabs = TRUE, 
        digits = c(0, 0, 3, 3, 3, 3),
        col.names = c("Threshold", "Motivation_NeedSANE.", "Rate (EMM)", "SE", 
                      "LL", "UL")) %>% 
  kable_styling() %>% 
  add_header_above(header = c(" " = 4, "95% Wald CI" = 2)) %>% 
  collapse_rows(columns = 1:2, valign = "top", latex_hline = "major", 
                custom_latex_hline = 1, 
                row_group_label_position = "stack") %>% 
  footnote(kable_input = ., general = FN, footnote_as_chunk = TRUE, 
           threeparttable = TRUE)
```

```{r}
#| label: fig-emmeans-m4-Both
#| tbl-cap: "Model 4 Conditional Attrition Rate by Threshold and Motivation_NeedSANE"

emmeans(m4, specs = ~ Motivation_NeedSANE. | Threshold., regrid = "response") %>% 
  plot(horizontal = FALSE) +
  facet_grid(cols = vars(Threshold.), labeller = label_both) +
  xlab("Attrition Rate") + 
  scale_x_continuous(lim = c(0.00, 0.50), labels = label_number(accuracy = 0.01))
```

# References
::: {#refs}
:::

\FloatBarrier

# Software Information
This section documents information that is important for reproducibility. Most
users will not need to read it. It is primarily here for use by the statistician 
on the team if we need to troubleshoot reproducibility issues because someone 
else is unable to get the same results from the same code. Start by checking for 
differences in package versions. 

We used [R](https://www.r-project.org/) as our main computing environment and
[Quarto](https://quarto.org/) scripts to enhance reproducibility. We used
[RStudio](www.rstudio.org) as the editor to interface with R and Quarto.

- Software chain:
  **qmd file > RStudio > Quarto > R > knitr > md file > Pandoc > tex file > TinyTeX > PDF file**.
- Source file: \texttt{\detokenize{`r params$SourceFile`}} 
- Output file: \texttt{\detokenize{`r params$LogFile`}} 
- [Quarto `r quarto_version()`](https://quarto.org/) runs `*.qmd` files through 
  [R](https://www.r-project.org/) and [knitr](https://yihui.org/knitr/) to 
  produce `*.md` markdown files.
- [Pandoc `r rmarkdown::pandoc_version()`](https://pandoc.org) converts markdown 
  files (`*.md`) to other formats, including LaTeX (`*.tex`) and HTML (`*.html`) 
  among others.
- [TinyTeX](https://yihui.org/tinytex/) compiles LaTeX files (`*.tex`) into PDF 
  files. It should be viable to use [MiKTeX](https://miktex.org) or another 
  LaTeX distribution instead. 

\FloatBarrier

## Versions
This document was generated using the following computational environment and 
dependencies:

```{r}
#| label: show-version
#| echo: true

# Check and report whether we used TinyTex or other LaTeX software. 
which_latex()

# Get R and R package version numbers in use.
devtools::session_info()
```

\FloatBarrier

## Git Details
The current Git commit details and status are:

``` {r}
#| label: git-details
#| echo: true

git_report()
```

This is useful because it tells us exactly which commit in the Git history 
we would need to be using to make sure we are running the exact same code. 
Sometimes another person is not using the most current code, or has changed the 
code in some way since it was last committed.  

::: {.callout-tip}
* Untracked files are files located in the repository that Git has not been told 
  to entirely ignore, but have also not been committed into the version history. 
* Unstaged changes to files indicate that some of the contents have been 
  modified since the last time the file was committed to Git. In production 
  runs, we want the Git output to not show any unstaged changes to key files!
  
::: 
