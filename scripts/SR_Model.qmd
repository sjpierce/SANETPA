---
title: Stopping-Ratio Modeling Results
subtitle: | 
          | CSTAT Case: C1788
          | Clients: Rebecca Campbell, Autumn Ashley, & Katherine Dontje
author: 
  - name: Steven J. Pierce
    orcid: 0000-0002-0679-3019
    email: pierces1@msu.edu
    affil-id: 1 
affiliations: 
  - id: 1 
    name: Michigan State University
    department: Center for Statistical Training and Consulting
    url: "[https://cstat.msu.edu](https://cstat.msu.edu)"
bibliography: references.bib          # File holds BibTeX data for references
csl: apa.csl                          # File controls citation & reference list format
params:                               # Default values for parameters
  SourceDir: "scripts/"               # Relative path to folder holding this file
  SourceFile: "SR_Model.qmd"          # Name of this script file
  LogFile: "SR_Model_Draft.pdf"       # Name of rendered output file
format: 
  pdf:                                # Settings for PDF output
    output-file: "SR_Model_Draft.pdf" # Default output file name 
    output-ext: "pdf"                 # Default file name extension
    documentclass: scrartcl           # LaTeX document type
    papersize: letter
    geometry:                         # Control page margins
      - top=1in
      - bottom=1in
      - left=1in
      - right=1in
    number-sections: true           # Auto-number each section
    toc: true                       # Include table of contents (TOC)
    toc-depth: 3                    # Number of layers in TOC
    colorlinks: true
    template-partials: 
      - title.tex   # Controls author affiliation formatting
    include-in-header:
      - file: compact-title.tex    # Controls spacing around title. 
      - text: |
          \usepackage{fancyhdr}
          \usepackage[noblocks]{authblk}
          \renewcommand*{\Authsep}{, }
          \renewcommand*{\Authand}{, }
          \renewcommand*{\Authands}{, }
          \renewcommand\Affilfont{\small}
          \usepackage[yyyymmdd,hhmmss]{datetime}    %% for currenttime command
          \usepackage{lastpage}                     %% For pageref command
          \usepackage{fontspec}
          \defaultfontfeatures{Ligatures=TeX}
          \usepackage[font={small}, margin=1cm, skip=2pt]{caption}
          \usepackage{url}
          \usepackage{floatrow}                     %% For controlling float placement
          \floatsetup[table]{capposition=top}       %% Puts table caption at top.
          \floatsetup[longtable]{margins=centering} %% Centers longtable tables
          \floatplacement{figure}{!ht}              %% Control placement of figures
          \floatplacement{table}{!ht}               %% Control placement of tables
          \usepackage[labelfont=bf, textfont=bf]{caption}  %% For bolded table/figure captions
          \usepackage{placeins}                     %% For FloatBarrier command
          \usepackage{booktabs}                     %% Used by kableExtra
          \usepackage{longtable}                    %% Used by kableExtra
          \usepackage{array}                        %% Used by kableExtra
          \usepackage{multirow}                     %% Used by kableExtra
          \usepackage{wrapfig}                      %% Used by kableExtra
          \usepackage{colortbl}                     %% Used by kableExtra
          \usepackage{pdflscape}                    %% Used by kableExtra
          \usepackage{tabu}                         %% Used by kableExtra
          \usepackage[normalem]{ulem}               %% Used by kableExtra
          \usepackage{makecell}                     %% Used by kableExtra
          \usepackage{xcolor}                       %% Used by kableExtra
          \usepackage{dcolumn}                      %% Used by kableExtra
          \usepackage{threeparttable}               %% Used by kableExtra
          \usepackage{threeparttablex}              %% Used by kableExtra
          \usepackage{amsmath}                      %% for equation support. 
          \usepackage{titling}      
          \usepackage{verbatim}                     %% For comment command
          \pretitle{\begin{center}\LARGE\bfseries\sffamily}
          \posttitle{\end{center}}
          \pagestyle{fancy}
          \lhead{SANETPA SR Models}
          \chead{\includegraphics[height=0.85cm]{../graphics/Combomark-Horiz_Pantone-567.eps}}
          \rhead{\today\ \currenttime}
          \cfoot{ }
          \fancyfoot[R]{\thepage\ of \pageref*{LastPage}}
          \renewcommand{\headrulewidth}{0.4pt}
          \renewcommand{\footrulewidth}{0.4pt}
          \fancypagestyle{plain}{\pagestyle{fancy}}
          \newcommand*\tocentryformat[1]{{\sffamily#1}}  %% Fix TOC font style
          \RedeclareSectionCommands                      %% Fix TOC font style
            [
              tocentryformat=\tocentryformat,
              tocpagenumberformat=\tocentryformat
            ]
            {section,subsection,subsubsection,paragraph,subparagraph}
execute:                              # Default Quarto chunk execution options
  eval: true
  echo: fenced                        # Show the code in the output file
  output: true
  warning: true
  error: true
  include: true
knitr:                                # Default R knitr package chunk options
  opts_chunk: 
    message: true
    cfsize: "scriptsize" 
---

\lfoot{\texttt{\small \detokenize{`r params$LogFile`}}}

\FloatBarrier

# Purpose
This file is part of a research compendium [@Pierce-RN8756] associated with a 
study about a sexual assault nurse examiner training program [@Dontje-RN8757]. 
The study aims to document rates of attrition at four points during the 
program and understand predictors of attrition at each of those points. 

This file reads an R data file created by another script in this compendium,
documents some methodology decisions and details, then runs the
stopping-ratio models that comprise the main analysis for the study. This
file also contains some narrative interpretation of the results and
supplementary output such as tables and graphs derived from the models.

# Research Questions
The research questions may be briefly stated as follows:

* **RQ1.** What are the attrition rates from the program at each of the four 
  thresholds representing transitions between stages of program participation?
* **RQ2.** How well do the following factors predict attrition rates at each 
  those four thresholds? 
    * Burnout.
    * Compassion satisfaction.
    * Secondary traumatic stress.
    * Barrier time demands.
    * Primary setting where the trainee practices nursing.
    * Motivated to seek the training by a need for SANE services in their 
      community or organization.
    * Motivated to seek the training by a personal connection to sexual assault 
      (e.g., someone they know is a survivor). 
* **RQ3.** Which predictors have parallel effects (constant across thresholds) 
  on attrition and which ones have non-parallel (threshold-specific) effects?
* **RQ4.** How strongly is starting each of specific modules in the didactic 
  training associated with attrition during the didactic training? 
* **RQ5.** Is starting the module on the physical exam of a sexual assault 
  survivor a particularly strong predictor of attrition during the didactic 
  training? Program staff think encountering the content of this module may be a 
  crucial event that drives trainees to attrit. 

::: {.callout-tip}
This file addresses research questions RQ1, RQ2, and RQ3 because those are best 
handled via stopping-ratio models. Research questions RQ4 and RQ5 will be 
answered in another file because they are better handled with different 
statistical methods. 
:::

::: {.callout-note}
The investigators and the program staff have explicitly decided that the 
following potential predictors are not of substantive interest and should not be
pursued in this paper.

* Trainee satisfaction with the training is not of interest because there is 
  such low variance that it would likely exhibit ceiling effects. 
* Trainee's learning scores in the didactic training and clinical skills 
  workshop are not of interest. 
* Trainee demographics (sex, age, race, etc.) are not of interest because the 
  team wants to focus on analyzing predictors that have more intrinsic meaning 
  and for which there are theoretical reasons to expect effects on attrition. 

:::

\FloatBarrier

# Setup
This section documents some setup tasks that are useful to the statistician on 
the team. Most readers of this document will probably want skip directly to 
@sec-SR-Modeling.

\FloatBarrier

## Define Global Options
Global R chunk options are defined in the YAML header but local chunk options
will over-ride global options. We can temporarily disable an individual chunk by
inserting `#| eval: false` on a line at the top of the chunk. The method for
creating a `cfsize` option that controls font size in code chunks and their text
output is based on an answer to a question posted on
[stackoverflow.com](https://stackoverflow.com/a/46526740).

``` {r}
#| label: global-options

# Create a custom chunk hook/option for controlling font size in chunk & output.
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$cfsize != "normalsize", 
         paste0("\n \\", options$cfsize,"\n\n", x, "\n\n \\normalsize"), 
         x)
  })
```

\FloatBarrier

## Load Packages
R packages usually add new functions to the base R software, allowing you to do 
more things. Here, we load the specific R packages required for this script to 
work.

```{r}
#| label: load-packages
library(here)           # for here(), i_am(), makes code more portable.
library(devtools)       # for session_info()
library(rmarkdown)      # for pandoc_version()
library(knitr)          # for kable()
library(dplyr)          # for %>%, filter(), group_by(), mutate(), rename(), etc.
library(tidyverse)      # for map_dfr(), map_chr(), rowid_to_column(), 
                        # rownames_to_column()
options(kableExtra.latex.load_packages = FALSE)
library(kableExtra)     # for kable_styling(), add_header_above(), 
                        # column_spec(), row_spec() etc. 
library(kableExtra)     # for add_header_above(), footnote(), kable_styling()
library(broom)          # for glance(), tidy()
library(car)            # for vif()
library(emmeans)        # for emmeans()
library(performance)    # for model_performance(), r2()
library(scales)         # for label_number()
library(piercer)        # for brier(), git_report(), R2Dev()
library(quarto)         # for quarto_version()
library(SANETPA)        # for version info 
```

\FloatBarrier

## Define Custom Functions
The function below will be used to format p-values later in the output. 

```{r}
#| label: display-num

display_num <- function(x) {
  case_when(x >= 1000000 ~ sprintf("%.2e", x),
            x < .001 ~ sprintf("%.2e", x),
            .default = sprintf("%.3f", x)) 
}
```

## Declare Path
This next chunk declares the path to this script relative to the project-level 
root directory. If the file is not in the right location under the project root
you'll get a warning message. This helps ensure relative paths are all working 
as expected. The chunk below uses the `SourceDir` and `SourceFile` parameters 
set in the YAML header. 

``` {r}
#| label: declare-path

# Declare path to this script relative to the project root directory.
here::i_am(path = paste0(params$SourceDir, params$SourceFile))
```

\FloatBarrier

## Load Data {#sec-Load-Data}
This subsection loads the data created by rendering `scripts/Import_Data.qmd`. 
The data is de-identified to preserve participant privacy and protect 
confidentiality. 

``` {r}
#| label: load-data
#| eval: true

# Store path to data file. 
DataFile <- here("data/Imported_SANETP_Data.RData")

load(file = DataFile)
```

@tbl-imported-data-file shows meta-data about the data file we just loaded and
@tbl-datasets shows the sizes of the datasets it contains. 

```{r}
#| label: tbl-imported-data-file
#| tbl-cap: "Meta-Data About the Data File Loaded"

file.info(DataFile, extra_cols = FALSE) %>% 
  rownames_to_column() %>% 
  mutate(rowname = basename(rowname)) %>% 
  select(-isdir, -mode) %>% 
  kable(, format = "latex", booktabs = TRUE, 
        col.names = c("File Name", "Size (Bytes)", "Modified", 
                      "Last Status Change", "Last Accessed")) %>% 
  kable_styling() %>% 
  column_spec(column = 3:5, width = "2cm")
```

```{r}
#| label: tbl-datasets
#| tbl-cap: "Sizes of the Datasets"

data.frame(Dataset = c("Applicants", "Eligible_Applicants", 
                       "Eligible_Applicants_CD", "Thresholds"),
           N_Rows = c(nrow(Applicants), nrow(Eligible_Applicants), 
                      nrow(Eligible_Applicants_CD), nrow(Thresholds)),
           N_Cols = c(ncol(Applicants), ncol(Eligible_Applicants),
                      ncol(Eligible_Applicants_CD), ncol(Thresholds))) %>% 
  kable(, format = "latex", booktabs = TRUE, 
        col.names = c("Dataset", "N Rows", "N Columns")) %>% 
  kable_styling() 
```

\FloatBarrier

# Prepare Data

```{r}
#| label: prepare-data

Thresholds <- Thresholds %>% 
  # Convert variables to factors
  mutate(Threshold_T = factor(Threshold))
```

\FloatBarrier

# Overview of Stopping-Ratio Modeling {#sec-SR-Modeling}
Attrition from the training program can be conceptualized as a sequential 
filtering process. There are various threshold points between stages of program 
participation where a participant may either attrit or continue participating.
Each of those thresholds is a filter: participants that attrit at a given 
threshold are filtered out of the program. That reduces the number of
participants who reach the next stage of program participation and encounter the
next threshold.

That means an eligible applicant's progress through the training program can be
measured by an ordinal stage variable that records the maximum stage reached by
the applicant in that sequential filtering process. In this study, the ordinal 
variable is called `Stage_Reached`. It is a multinomial ordinal variable with 
$J = 5$ possible stages and observed values denoted by stage $j$, where 
$j \in \{1, 2, 3, 4, 5\}$. 

@fig-Stages shows the final set of stages and thresholds (T1 to T4) between them
at which attrition from the training program could occur. The arrows associated
with each threshold are labeled according to how the outcome variable is coded
on the corresponding person-threshold record, depending on whether the person
stopped participating at the current stage or moved on to the next stage. 

```{dot}
//| label: fig-Stages
//| fig-cap: Stages, Thresholds (T1-T4), and Stopping Ratios (SR1-SR4) in the 
//|          SANE Training Program. CSW, clinical skills workshop; DT, didactic 
//|          training.
//| fig-width: 6
//| fig-height: 3

digraph StagesModeled {

graph [rankdir="LR"];

node [shape = "box", style= "filled", fillcolor = "Gray90", fontsize = "7"];
A1 [label = "Attrited 1\nNot Enrolled\nSR1"]
A2 [label = "Attrited 2\nBefore DT\nSR2"]
A3 [label = "Attrited 3\nDuring DT\nSR3"]
A4 [label = "Attrited 4\nBefore CSW\nSR4"]

S1 [label = "Stage 1\nEligible\nj = 1"]
S2 [label = "Stage 2\nEnrolled\nj = 2"]
S3 [label = "Stage 3\nStarted DT\nj = 3"]
S4 [label = "Stage 4\nFinished DT\nj = 4"]
S5 [label = "Stage 5\nFinished CSW\nj = 5"]

edge [fontsize = "7"];

S1 -> A1 [label = "T1\nAttrit = 1"]
S2 -> A2 [label = "T2\nAttrit = 1"]
S3 -> A3 [label = "T3\nAttrit = 1"]
S4 -> A4 [label = "T4\nAttrit = 1"]

S1 -> S2 [label = "Attrit = 0"]
S2 -> S3 [label = "Attrit = 0"]
S3 -> S4 [label = "Attrit = 0"]
S4 -> S5 [label = "Attrit = 0"]
}
```

There are several variations of regression models designed to analyze ordinal
outcomes: they test different hypotheses, estimate different parameters, and
yield different insights [@Fullerton-RN8774]. The research questions for this
study are best aligned with a broad class of ordinal regression models usually
called continuation-ratio (CR) models, though they are also called 
stopping-ratio (SR) models or stage models 
[@Fullerton-RN8774; @Liu-RN8772; @Yee-RN3711]. The CR model is ideally suited
for ordinal outcome data generated from a sequential selection process where all
individuals start from the same initial stage, must pass through earlier stages
to reach later ones, and all stage transitions are irreversible
[@Fullerton-RN8774; @OConnell-RN8769]. 

One key to understanding CR models is that they divide the analysis of a single 
ordinal outcome into a series of binary outcomes regarding what happens at each 
of the thresholds between stages


a set of transitions between stages

@Liu-RN8772 distinguished between forward and backward types of CR models and 
emphasized that each type can be expressed in two different sub-models depending 
on which of the two complementary conditional probabilities for a binary event 
one wants to emphasize (odds versus inversed odds). Regression coefficients 
from the two sub-models of the same type of CR model (forward or backward) have 
the same magnitude but opposite signs. The sub-models for a given type (e.g., 
forward) will also have the same model fit. However, results and interpretation 
will differ between types: the forward and backward CR models are not equivalent 
because they test different hypotheses. 


Because our focus is on predicting attrition--which stops a trainee's 
progression to the next stage of program participation--we will use the SR 
nomenclature in most cases. 



The SR model is attractive because its parameters can be translated into 
additional estimates and graphs that are easy to interpret and meaningful for 
assessing the effects of predictors on program attrition.

[@Cole-RN8770]

[@Davidson-RN8773]

[@Fullerton-RN8774]

[@Liu-RN8772]

[@Liu-RN8771]

[@Smithson-RN2775]

\FloatBarrier

# Results
Below we fit and examine a series of stopping-ratio models using the 
`Thresholds` dataset and the `glm()` function. The modeling strategy aims to 
estimate the minimum number of models required to answer research questions 
RQ1, RQ2, and RQ3 and obtain a parsimonious final model. We examine model 
diagnostics and fit statistics, model comparisons, and other supplementary 
output (e.g., effect sizes, estimated marginal means, etc.) as needed. 

## Model 1: Thresholds Alone
The modeling starts by first fitting a very simple model (`m1`) containing only 
a threshold main effect. Using only `Threshold_T` as a predictor and omitting 
the normal intercept term allows us to estimate a separate intercept for each 
threshold. @tbl-params-m1 shows the the model parameters and @tbl-fit-m1 shows 
its fit statistics. 

```{r}
#| label: display-num

display_num <- function(x) {
  case_when(x >= 1000000 ~ sprintf("%.2e", x),
            x < .001 ~ sprintf("%.2e", x),
            .default = sprintf("%.3f", x)) 
}
```

```{r}
#| label: tbl-params-m1
#| tbl-cap: "Model 1 Parameters"

m1 <- glm(Attrit ~ Threshold_T - 1, data = Thresholds, 
          family = binomial(link = "logit"))
#summary(m1)

FN <- paste("Values shown are on the link function (logit) scale.",
            "Likelihood profile confidence intervals are reported.")

tidy(m1) %>% 
  cbind(confint.default(m1)) %>% 
  as_tibble() %>% 
  rename(Parameter = term, Est = estimate, SE = std.error, z = statistic, 
         p = p.value, LL = `2.5 %`, UL = `97.5 %`) %>% 
  mutate(p = display_num(p),
         OR = exp(Est), 
         OR.LL = exp(LL), 
         OR.UL = exp(UL)) %>% 
  relocate(Parameter, Est, SE, LL, UL, OR, OR.LL, OR.UL, z, p) %>% 
  kable(format = "latex", booktabs = TRUE, digits = 2) %>% 
  kable_styling() %>% 
  add_header_above(header = c(" " = 3, "95% Wald CI" = 2, " " = 1, 
                              "OR 95% Wald CI" = 2, "Wald Test" =  2))
```
```{r}
#| label: tbl-fit-m1
#| tbl-cap: "Model 1 Fit Statistics"

glance(m1) %>% 
  kable(format = "latex", booktabs = TRUE, 
        digits = c(2, 0, 2, 2, 2, 2, 0, 0)) %>% 
  kable_styling()
```

::: {.callout-tip}
* We can probably use either `emmeans()` or `glht()` to get contrasts that 
  clarify simple slopes for interactions. 
* We can probably use `emmeans()` or `predict()` to get conditional rates for 
  plotting effects. 
    
:::

### Single Term Deletion Tests
@tbl-anova-m1 shows the effect of deleting specific terms from the model to 
determine whether doing so worsens model fit. Significant effects should be 
retained in the model because omitting them would damage the model fit.

```{r}
#| label: tbl-anova-m1
#| tbl-cap: "Model 1 Single Term Deletion Tests (Type II SS)"
#| warning: false

m1 %>% 
  drop1(., test = "LRT") %>% 
  tidy() %>% 
  rename(p = p.value) %>% 
  mutate(p = display_num(p)) %>% 
  kable(format = "latex", booktabs = TRUE,
        digits = c(0, 0, 2, 2, 2, Inf),
        col.names = c("Term Deleted", "df", "Deviance", "AIC", "LRT", "p")) %>% 
  kable_styling() 
```

### Estimated Marginal Means
Because `Threshold_T` is the sole predictor, we get estimated marginal means 
(EMMs) based on the intercept parameters that can be back-transformed to the
response (probability) scale. These directly estimate the attrition rate at each
threshold and agree with the simple descriptive statistics for percent attrition
at each threshold. @tbl-emmeans-m1 shows the EMMs. 

```{r}
#| label: tbl-emmeans-m1
#| tbl-cap: "Model 1 Conditional Attrition Rate by Threshold"

FN <- paste("Values are on the probability scale.",
            "EMM, estimated marginal mean.")

emmeans(m1, specs = ~ Threshold_T, regrid = "response") %>% 
  as_tibble() %>% 
  select(!df) %>% 
  kable(format = "latex", booktabs = TRUE, 
        digits = c(0, 3, 3, 3, 3),
        col.names = c("Threshold", "Rate (EMM)", "SE", "LL", "UL")) %>% 
  kable_styling() %>% 
  add_header_above(header = c(" " = 3, "95% Wald CI" = 2)) %>% 
  footnote(kable_input = ., general = FN, footnote_as_chunk = TRUE, 
           threeparttable = TRUE)
```

## Model 2: Thresholds & Parallel Effects for Focal Predictors
In SR models, a predictor has a parallel effect when its regression coefficient 
is constrained equal across all thresholds. Thus, the predictor only has a 
main effect and does not interact with the threshold. 

::: {.callout-tip}
* We need all focal predictors to have only main effects in this model to get 
  parallel effects. 
* We can probably use `emmeans()` or `predict()` to get conditional rates for 
  plotting effects. 
    
:::

## Model 3: Thresholds & Non-Parallel Effects for Focal Predictors
In SR models, a predictor has a non-parallel effect when its regression 
coefficient is allowed to vary across all thresholds. Thus, the predictor has a 
main effect and an interaction with the threshold. 

::: {.callout-tip}
* We need all focal predictors to have both main effects and interactions with 
  threshold in this model to get non-parallel effects. Main effects are 
  required for proper estimation of the interaction. 
* Continuous predictors must be appropriately centered before model fitting.
* We can probably use either `emmeans()` or `glht()` to get contrasts that 
  clarify simple slopes for interactions. 
* We can probably use `emmeans()` or `predict()` to get conditional rates for 
  plotting effects. 
    
:::

# References
::: {#refs}
:::

\FloatBarrier

# Software Information
This section documents information that is important for reproducibility. Most
users will not need to read it. It is primarily here for use by the statistician 
on the team if we need to troubleshoot reproducibility issues because someone 
else is unable to get the same results from the same code. Start by checking for 
differences in package versions. 

We used [R](https://www.r-project.org/) as our main computing environment and
[Quarto](https://quarto.org/) scripts to enhance reproducibility. We used
[RStudio](www.rstudio.org) as the editor to interface with R and Quarto.

- Software chain:
  **qmd file > RStudio > Quarto > R > knitr > md file > Pandoc > tex file > TinyTeX > PDF file**.
- Source file: \texttt{\detokenize{`r params$SourceFile`}} 
- Output file: \texttt{\detokenize{`r params$LogFile`}} 
- [Quarto `r quarto_version()`](https://quarto.org/) runs `*.qmd` files through 
  [R](https://www.r-project.org/) and [knitr](https://yihui.org/knitr/) to 
  produce `*.md` markdown files.
- [Pandoc `r rmarkdown::pandoc_version()`](https://pandoc.org) converts markdown 
  files (`*.md`) to other formats, including LaTeX (`*.tex`) and HTML (`*.html`) 
  among others.
- [TinyTeX](https://yihui.org/tinytex/) compiles LaTeX files (`*.tex`) into PDF 
  files. It should be viable to use [MiKTeX](https://miktex.org) or another 
  LaTeX distribution instead. 

\FloatBarrier

## Versions
This document was generated using the following computational environment and 
dependencies:

```{r}
#| label: show-version
#| echo: true

# Check and report whether we used TinyTex or other LaTeX software. 
which_latex()

# Get R and R package version numbers in use.
devtools::session_info()
```

\FloatBarrier

## Git Details
The current Git commit details and status are:

``` {r}
#| label: git-details
#| echo: true

git_report()
```

This is useful because it tells us exactly which commit in the Git history 
we would need to be using to make sure we are running the exact same code. 
Sometimes another person is not using the most current code, or has changed the 
code in some way since it was last committed.  

::: {.callout-tip}
* Untracked files are files located in the repository that Git has not been told 
  to entirely ignore, but have also not been committed into the version history. 
* Unstaged changes to files indicate that some of the contents have been 
  modified since the last time the file was committed to Git. In production 
  runs, we want the Git output to not show any unstaged changes to key files!
  
::: 
